---
title: "R Notebook"
output:
  html_document:
    df_print: paged
---

Setup & Import

```{r}
library(tidyverse)
library(lme4)
library(lmerTest)
library(sjPlot)
library(data.table)
library(dplyr)
library(plyr)
library(tidyr)
library(ggplot2)
library(stringr)
library(readr)
library(psych)
library(performance)
library(corrr)
library(purrr)
library(corrplot)
library(multilevel)
library(emmeans)
library(tibble)
library(rmcorr)

data <- read.csv("otree_cleaned1.csv")
data_old <- read.csv("flow_reports_exp1.csv")
data_old_rounds <- read.csv("round_reports_exp1.csv")
data_old_final <- read.csv("final_reports_exp1.csv")
```

Data quality check

```{r}
# Datenqualitäts-Check für unaufmerksame Antworten
# ================================================================================
# STRAIGHT-LINING DETECTION - BASE R ANSATZ (FUNKTIONIERT GARANTIERT)
# ================================================================================

print("\n=== STRAIGHT-LINING DETECTION ===")

# FSS-Spalten finden
fss_columns <- names(data)[grep("fss\\d+", names(data), ignore.case = TRUE)]
print(paste("Arbeite mit", length(fss_columns), "FSS-Spalten"))

# Funktion zur Berechnung der Antwort-Variabilität
calculate_response_variability <- function(values) {
  # Nur numerische Werte extrahieren
  numeric_values <- as.numeric(values)
  numeric_values <- numeric_values[!is.na(numeric_values)]
  
  if(length(numeric_values) < 2) {
    return(list(
      n_responses = length(numeric_values),
      sd = NA, 
      n_unique = length(numeric_values), 
      straightline = FALSE,
      min_val = ifelse(length(numeric_values) > 0, min(numeric_values), NA),
      max_val = ifelse(length(numeric_values) > 0, max(numeric_values), NA)
    ))
  }
  
  # Statistiken berechnen
  sd_responses <- sd(numeric_values, na.rm = TRUE)
  n_unique <- length(unique(numeric_values))
  min_val <- min(numeric_values)
  max_val <- max(numeric_values)
  
  # Straight-lining: SD = 0 oder nur ein einzigartiger Wert
  straightline <- (sd_responses == 0 | n_unique == 1) & length(numeric_values) > 1
  
  return(list(
    n_responses = length(numeric_values),
    sd = sd_responses, 
    n_unique = n_unique, 
    straightline = straightline,
    min_val = min_val,
    max_val = max_val
  ))
}

# Erstelle leeren data.frame für Ergebnisse
fss_variability <- data.frame(
  participant_code = character(),
  n_fss_responses = numeric(),
  fss_sd = numeric(),
  fss_n_unique = numeric(),
  fss_min = numeric(),
  fss_max = numeric(),
  fss_straightline = logical(),
  stringsAsFactors = FALSE
)

# Gehe durch jeden Teilnehmer
unique_participants <- unique(data$participant.code)
print(paste("Analysiere", length(unique_participants), "Teilnehmer"))

for(i in 1:length(unique_participants)) {
  participant <- unique_participants[i]
  
  # Hole alle FSS-Daten für diesen Teilnehmer
  participant_data <- data[data$participant.code == participant, fss_columns, drop = FALSE]
  
  # Alle FSS-Werte für diesen Teilnehmer sammeln
  all_fss_values <- unlist(participant_data)
  
  # Berechne Variabilität
  variability <- calculate_response_variability(all_fss_values)
  
  # Füge zu Ergebnissen hinzu
  fss_variability <- rbind(fss_variability, data.frame(
    participant_code = participant,
    n_fss_responses = variability$n_responses,
    fss_sd = variability$sd,
    fss_n_unique = variability$n_unique,
    fss_min = variability$min_val,
    fss_max = variability$max_val,
    fss_straightline = variability$straightline,
    stringsAsFactors = FALSE
  ))
  
  # Fortschritt anzeigen
  if(i %% 20 == 0) {
    print(paste("Verarbeitet:", i, "von", length(unique_participants)))
  }
}

print("\n--- ERGEBNISSE ---")

# Zeige Teilnehmer mit Straight-Lining
straightliners <- fss_variability[fss_variability$fss_straightline == TRUE, ]
print(paste("Teilnehmer mit Straight-Lining gefunden:", nrow(straightliners)))

if(nrow(straightliners) > 0) {
  print("\nTeilnehmer mit Straight-Lining bei FSS-Items:")
  print(straightliners)
} else {
  print("Keine Straight-Liner gefunden.")
}

# Zeige Teilnehmer mit sehr niedriger Variabilität (potentielle Probleme)
low_variability <- fss_variability[!is.na(fss_variability$fss_sd) & 
                                  fss_variability$fss_sd < 0.5 & 
                                  fss_variability$n_fss_responses > 5, ]

print(paste("\nTeilnehmer mit sehr niedriger Variabilität (SD < 0.5):", nrow(low_variability)))
if(nrow(low_variability) > 0) {
  print(low_variability)
}

# ================================================================================
# DESKRIPTIVE STATISTIKEN
# ================================================================================

print("\n--- DESKRIPTIVE STATISTIKEN ---")

# Übersicht über Antwort-Variabilität
print("Verteilung der Standardabweichungen:")
print(summary(fss_variability$fss_sd))

print("\nVerteilung der Anzahl eindeutiger Antworten:")
print(summary(fss_variability$fss_n_unique))

print("\nVerteilung der Anzahl Antworten pro Person:")
print(summary(fss_variability$n_fss_responses))

# Histogramm der Standardabweichungen (falls möglich)
if(require(ggplot2, quietly = TRUE)) {
  p <- ggplot(fss_variability, aes(x = fss_sd)) +
    geom_histogram(bins = 20, fill = "skyblue", alpha = 0.7) +
    geom_vline(xintercept = 0.5, color = "red", linetype = "dashed") +
    labs(title = "Verteilung der FSS-Antwort-Variabilität",
         x = "Standardabweichung der FSS-Antworten",
         y = "Anzahl Teilnehmer") +
    theme_minimal()
  
  print(p)
}

# ================================================================================
# ZUSÄTZLICHE QUALITÄTSCHECKS
# ================================================================================

print("\n--- ZUSÄTZLICHE QUALITÄTSCHECKS ---")

# 1. Fehlende Daten pro FSS-Item
missing_per_item <- sapply(fss_columns, function(col) {
  sum(is.na(data[[col]]))
})

items_with_missing <- data.frame(
  item = names(missing_per_item),
  missing_count = missing_per_item,
  missing_percent = round(100 * missing_per_item / nrow(data), 2)
)

# Zeige Items mit viel fehlenden Daten
high_missing <- items_with_missing[items_with_missing$missing_percent > 50, ]
if(nrow(high_missing) > 0) {
  print("\nFSS-Items mit >50% fehlenden Daten:")
  print(high_missing)
} else {
  print("\nKeine FSS-Items mit kritisch vielen fehlenden Daten gefunden.")
}

# 2. Extreme Werte
extreme_low <- fss_variability[!is.na(fss_variability$fss_sd) & 
                              fss_variability$fss_sd < 0.1 & 
                              fss_variability$n_fss_responses > 10, ]

if(nrow(extreme_low) > 0) {
  print(paste("\nTeilnehmer mit extrem niedriger Variabilität (SD < 0.1):", nrow(extreme_low)))
  print(extreme_low)
}

# 3. Speichere Ergebnisse für weitere Verwendung
fss_quality_results <- fss_variability
print(paste("\nErgebnisse in 'fss_quality_results' gespeichert (", nrow(fss_quality_results), " Teilnehmer)"))

# 4. Empfehlungen für Ausschluss
exclusion_candidates <- fss_variability[
  (fss_variability$fss_straightline == TRUE) |
  (!is.na(fss_variability$fss_sd) & fss_variability$fss_sd < 0.1 & fss_variability$n_fss_responses > 10),
]

print(paste("\nEmpfohlene Ausschluss-Kandidaten:", nrow(exclusion_candidates)))
if(nrow(exclusion_candidates) > 0) {
  print("Teilnehmer zur Überprüfung:")
  print(exclusion_candidates[, c("participant_code", "fss_sd", "fss_n_unique", "fss_straightline")])
}

print("\n=== STRAIGHT-LINING DETECTION ABGESCHLOSSEN ===")
```

Descriptive statistics

```{r}
# Demografische Übersicht
demographics <- data %>%
  summarise(
    # Geschlecht
    female_pct = mean(Intro.1.player.gender == "Female", na.rm = TRUE) * 100,
    male_pct = mean(Intro.1.player.gender == "Male", na.rm = TRUE) * 100,
    # Alter
    age_mean = mean(Intro.1.player.age, na.rm = TRUE),
    age_sd = sd(Intro.1.player.age, na.rm = TRUE),
    # Händigkeit
    right_handed_pct = mean(Intro.1.player.dominant_hand == "Right", na.rm = TRUE) * 100
  )

print(round(demographics, 1))

# Englischkenntnisse detailliert
cat("\nEnglischkenntnisse:\n")
english_table <- prop.table(table(data$Intro.1.player.english)) * 100
print(round(english_table, 1))

# Occupation und Field of Study - nur Top 5
cat("\nTop 5 Occupations:\n")
head(sort(table(data$Intro.1.player.occupation), decreasing = TRUE), 5)

cat("\nTop 5 Fields of Study:\n")
head(sort(table(data$Intro.1.player.field_of_study), decreasing = TRUE), 5)
```

Manipulation checks for team goal, team member independence, and ability to coordinate work

```{r}
library(dplyr)
library(psych)

# mathChat - Interdependence
int_mathChat <- data %>%
  dplyr::select(mathChat.6.player.int1, mathChat.6.player.int2, mathChat.6.player.int3)
psych::alpha(int_mathChat, check.keys=TRUE)

# mathChat - Common Goal
cg_mathChat <- data %>%
  dplyr::select(mathChat.6.player.cg1, mathChat.6.player.cg2, mathChat.6.player.cg3, 
         mathChat.6.player.cg4, mathChat.6.player.cg5, mathChat.6.player.cg6)
psych::alpha(cg_mathChat, check.keys=TRUE)

# mathChat - Means for Coordination
mc_mathChat <- data %>%
  dplyr::select(mathChat.6.player.mc1, mathChat.6.player.mc2)
psych::alpha(mc_mathChat, check.keys=TRUE) 

# mathJitsi - Interdependence
int_mathJitsi <- data %>%
  dplyr::select(mathJitsi.6.player.int1, mathJitsi.6.player.int2, mathJitsi.6.player.int3)
psych::alpha(int_mathJitsi, check.keys=TRUE)

# mathJitsi - Common Goal
cg_mathJitsi <- data %>%
  dplyr::select(mathJitsi.6.player.cg1, mathJitsi.6.player.cg2, mathJitsi.6.player.cg3, 
         mathJitsi.6.player.cg4, mathJitsi.6.player.cg5, mathJitsi.6.player.cg6)
psych::alpha(cg_mathJitsi, check.keys=TRUE)

# mathJitsi - Means for Coordination
mc_mathJitsi <- data %>%
  dplyr::select(mathJitsi.6.player.mc1, mathJitsi.6.player.mc2)
psych::alpha(mc_mathJitsi, check.keys=TRUE) 

# HiddenProfile_Chat - Interdependence
int_HiddenProfile_Chat <- data %>%
  dplyr::select(HiddenProfile_Chat.3.player.int1, HiddenProfile_Chat.3.player.int2, HiddenProfile_Chat.3.player.int3)
psych::alpha(int_HiddenProfile_Chat, check.keys=TRUE)

# HiddenProfile_Chat - Common Goal
cg_HiddenProfile_Chat <- data %>%
  dplyr::select(HiddenProfile_Chat.3.player.cg1, HiddenProfile_Chat.3.player.cg2, HiddenProfile_Chat.3.player.cg3, 
         HiddenProfile_Chat.3.player.cg4, HiddenProfile_Chat.3.player.cg5, HiddenProfile_Chat.3.player.cg6)
psych::alpha(cg_HiddenProfile_Chat, check.keys=TRUE)

# HiddenProfile_Chat - Means for Coordination
mc_HiddenProfile_Chat <- data %>%
  dplyr::select(HiddenProfile_Chat.3.player.mc1, HiddenProfile_Chat.3.player.mc2)
psych::alpha(mc_HiddenProfile_Chat, check.keys=TRUE) 

# HiddenProfile_Jitsi - Interdependence
int_HiddenProfile_Jitsi <- data %>%
  dplyr::select(HiddenProfile_Jitsi.3.player.int1, HiddenProfile_Jitsi.3.player.int2, HiddenProfile_Jitsi.3.player.int3)
psych::alpha(int_HiddenProfile_Jitsi, check.keys=TRUE)

# HiddenProfile_Jitsi - Common Goal
cg_HiddenProfile_Jitsi <- data %>%
  dplyr::select(HiddenProfile_Jitsi.3.player.cg1, HiddenProfile_Jitsi.3.player.cg2, HiddenProfile_Jitsi.3.player.cg3, 
         HiddenProfile_Jitsi.3.player.cg4, HiddenProfile_Jitsi.3.player.cg5, HiddenProfile_Jitsi.3.player.cg6)
psych::alpha(cg_HiddenProfile_Jitsi, check.keys=TRUE)

# HiddenProfile_Jitsi - Means for Coordination
mc_HiddenProfile_Jitsi <- data %>%
  dplyr::select(HiddenProfile_Jitsi.3.player.mc1, HiddenProfile_Jitsi.3.player.mc2)
psych::alpha(mc_HiddenProfile_Jitsi, check.keys=TRUE) 

# Items umpolen (nur die mit negativem Vorzeichen aus der Alpha-Analyse)
data <- data %>%
  mutate(
    # mathChat Items umpolen:
    mathChat.6.player.int1_rev = 8 - mathChat.6.player.int1,
    mathChat.6.player.cg1_rev = 8 - mathChat.6.player.cg1,
    mathChat.6.player.cg3_rev = 8 - mathChat.6.player.cg3,
    mathChat.6.player.cg5_rev = 8 - mathChat.6.player.cg5,
    mathChat.6.player.mc1_rev = 8 - mathChat.6.player.mc1
  )

# Skalenmittelwerte je Konstrukt pro Treatment
data <- data %>%
  mutate(
    mc_mathChat = rowMeans(dplyr::select(., mathChat.6.player.mc1_rev, mathChat.6.player.mc2), na.rm = TRUE),
    mc_mathJitsi = rowMeans(dplyr::select(., mathJitsi.6.player.mc1, mathJitsi.6.player.mc2), na.rm = TRUE),
    mc_hpChat = rowMeans(dplyr::select(., HiddenProfile_Chat.3.player.mc1, HiddenProfile_Chat.3.player.mc2), na.rm = TRUE),
    mc_hpJitsi = rowMeans(dplyr::select(., HiddenProfile_Jitsi.3.player.mc1, HiddenProfile_Jitsi.3.player.mc2), na.rm = TRUE),

    int_mathChat = rowMeans(dplyr::select(., mathChat.6.player.int1_rev, mathChat.6.player.int2, mathChat.6.player.int3), na.rm = TRUE),
    int_mathJitsi = rowMeans(dplyr::select(., mathJitsi.6.player.int1, mathJitsi.6.player.int2, mathJitsi.6.player.int3), na.rm = TRUE),
    int_hpChat = rowMeans(dplyr::select(., HiddenProfile_Chat.3.player.int1, HiddenProfile_Chat.3.player.int2, HiddenProfile_Chat.3.player.int3), na.rm = TRUE),
    int_hpJitsi = rowMeans(dplyr::select(., HiddenProfile_Jitsi.3.player.int1, HiddenProfile_Jitsi.3.player.int2, HiddenProfile_Jitsi.3.player.int3), na.rm = TRUE),

    cg_mathChat = rowMeans(dplyr::select(., mathChat.6.player.cg1_rev, mathChat.6.player.cg2, mathChat.6.player.cg3_rev, 
                                  mathChat.6.player.cg4, mathChat.6.player.cg5_rev, mathChat.6.player.cg6), na.rm = TRUE),
    cg_mathJitsi = rowMeans(dplyr::select(., starts_with("mathJitsi.6.player.cg")), na.rm = TRUE),
    cg_hpChat = rowMeans(dplyr::select(., starts_with("HiddenProfile_Chat.3.player.cg")), na.rm = TRUE),
    cg_hpJitsi = rowMeans(dplyr::select(., starts_with("HiddenProfile_Jitsi.3.player.cg")), na.rm = TRUE)
  )

mc_long <- data %>%
  dplyr::select(mc_mathChat, mc_mathJitsi, mc_hpChat, mc_hpJitsi) %>%
  pivot_longer(cols = everything(), names_to = "Treatment", values_to = "Score") %>%
  mutate(Treatment = dplyr::recode(Treatment,
                            mc_mathChat = "Math – Chat",
                            mc_mathJitsi = "Math – Jitsi",
                            mc_hpChat = "HiddenProfile – Chat",
                            mc_hpJitsi = "HiddenProfile – Jitsi"))

ggplot(mc_long, aes(x = Treatment, y = Score)) +
  geom_boxplot(fill = "skyblue", alpha = 0.7) +
  theme_minimal() +
  labs(title = "Means for Coordination (MC) – nach Treatment",
       y = "Skalenwert (1–7)", x = NULL) +
  ylim(1, 7)

int_long <- data %>%
  dplyr::select(int_mathChat, int_mathJitsi, int_hpChat, int_hpJitsi) %>%
  pivot_longer(cols = everything(), names_to = "Treatment", values_to = "Score") %>%
  mutate(Treatment = dplyr::recode(Treatment,
                            int_mathChat = "Math – Chat",
                            int_mathJitsi = "Math – Jitsi",
                            int_hpChat = "HiddenProfile – Chat",
                            int_hpJitsi = "HiddenProfile – Jitsi"))

ggplot(int_long, aes(x = Treatment, y = Score)) +
  geom_boxplot(fill = "orchid", alpha = 0.7) +
  theme_minimal() +
  labs(title = "Team Member Interdependence (INT) – nach Treatment",
       y = "Skalenwert (1–7)", x = NULL) +
  ylim(1, 7)

cg_long <- data %>%
  dplyr::select(cg_mathChat, cg_mathJitsi, cg_hpChat, cg_hpJitsi) %>%
  pivot_longer(cols = everything(), names_to = "Treatment", values_to = "Score") %>%
  mutate(Treatment = dplyr::recode(Treatment,
                            cg_mathChat = "Math – Chat",
                            cg_mathJitsi = "Math – Jitsi",
                            cg_hpChat = "HiddenProfile – Chat",
                            cg_hpJitsi = "HiddenProfile – Jitsi"))

ggplot(cg_long, aes(x = Treatment, y = Score)) +
  geom_boxplot(fill = "seagreen3", alpha = 0.7) +
  theme_minimal() +
  labs(title = "Common Goal (CG) – nach Treatment",
       y = "Skalenwert (1–7)", x = NULL) +
  ylim(1, 7)

```

Manipulation check for difficulty

```{r}
# Funktion um z.B. "['A', 'O', 'F', 'B']" in echten Vektor zu verwandeln
parse_order_string <- function(s) {
  s %>%
    str_remove_all("\\[|\\]|'|\"") %>%
    str_split(",\\s*") %>%
    unlist()
}

# Mapping Math-Codes zu Labels
map_math_difficulty <- function(code) {
  dplyr::recode(code,
         "B" = "Easy",
         "A" = "Optimal_Selected",
         "F" = "Optimal_Calibrated",
         "O" = "Hard")
}

data <- data %>%
  mutate(
    math_order = map(as.character(participant.condition_order), parse_order_string) %>%
                   map(~ map_chr(.x, map_math_difficulty)),
    hp_order   = map(as.character(participant.hp_condition_order), parse_order_string) %>%
                   map(str_to_title)
  )

# MATH TASK
math_difficulty_long <- data %>%
  dplyr::select(participant.code, math_order,
         starts_with("mathChat.3.player.csb"),
         starts_with("mathChat.4.player.csb"),
         starts_with("mathChat.5.player.csb"),
         starts_with("mathChat.6.player.csb"),
         starts_with("mathJitsi.3.player.csb"),
         starts_with("mathJitsi.4.player.csb"),
         starts_with("mathJitsi.5.player.csb"),
         starts_with("mathJitsi.6.player.csb")) %>%
  pivot_longer(cols = -c(participant.code, math_order),
               names_to = "var", values_to = "csb") %>%
  mutate(
    round = str_extract(var, "\\d+"),
    comm = ifelse(str_detect(var, "Chat"), "Chat", "Jitsi"),
    index = as.integer(round) - 2,  # weil math.3 = erste relevante Runde
    difficulty = map2_chr(math_order, index, ~ .x[.y])
  ) %>%
  drop_na(csb)

# HP TASK
hp_difficulty_long <- data %>%
  dplyr::select(participant.code, hp_order,
         starts_with("HiddenProfile_Chat."),
         starts_with("HiddenProfile_Jitsi.")) %>%
  pivot_longer(cols = matches("HiddenProfile_.*\\.player\\.csb[12]"),
               names_to = "var", values_to = "csb") %>%
  mutate(
    round = str_extract(var, "(?<=\\.)\\d+"),
    comm = ifelse(str_detect(var, "Chat"), "Chat", "Jitsi"),
    index = as.integer(round),  # hier ist Runde = Index
    difficulty = map2_chr(hp_order, index, ~ .x[.y])
  ) %>%
  drop_na(csb)

# X-Achse splitten in zwei ästhetischere Achsen:
ggplot(math_difficulty_long, aes(x = difficulty, y = csb, fill = comm)) +
  geom_boxplot(position = position_dodge(width = 0.75)) +
  labs(title = "Math Task", x = "Difficulty", y = "Subjective Difficulty") +
  theme_minimal()

ggplot(hp_difficulty_long, aes(x = difficulty, y = csb, fill = comm)) +
  geom_boxplot(position = position_dodge(width = 0.75)) +
  labs(title = "Hidden Profile Task", x = "Difficulty", y = "Subjective Difficulty") +
  theme_minimal()

```

Internal consistency check for flow construct and flow score calculation

```{r}
# Reihenfolge-Parsing-Helfer
parse_order_string <- function(s) {
  s %>%
    str_remove_all("\\[|\\]|'|\"") %>%
    str_split(",\\s*") %>%
    unlist()
}

# Reihenfolgen extrahieren
data <- data %>%
  mutate(
    math_order = map(participant.condition_order, parse_order_string),
    hp_order   = map(participant.hp_condition_order, parse_order_string)
  )

# Funktion zum Remappen der Items von Runde -> Schwierigkeitsstufe
remap_fss_items <- function(df, prefix, rounds, difficulty_map) {
  out <- list()
  for (i in seq_along(rounds)) {
    r <- rounds[i]
    diff_code <- difficulty_map[i]
    for (j in 1:9) {
      old_name <- sprintf("%s.%d.player.fss%02d", prefix, r, j)
      new_name <- sprintf("%s.%s.player.fss%02d", prefix, diff_code, j)
      out[[new_name]] <- if (old_name %in% names(df)) df[[old_name]][1] else NA
    }
  }
  # Eine Zeile mit vielen Spalten zurückgeben
  return(as_tibble(out))
}

# Spaltennamen für Mathe-Items extrahieren
math_cols <- names(data)[startsWith(names(data), "math")]

# Mathe-Daten remappen
math_data <- data %>%
  mutate(math_items = pmap(
    c(list(math_order), dplyr::select(., all_of(math_cols))),
    function(order, ...) {
      df <- tibble(...)
      bind_cols(
        remap_fss_items(df, "mathJitsi", 3:6, order),
        remap_fss_items(df, "mathChat", 3:6, order)
      )
    }
  ))

# Spaltennamen für Hidden Profile-Items extrahieren
hp_cols <- names(data)[startsWith(names(data), "HiddenProfile_")]

# HP-Daten remappen
hp_data <- data %>%
  mutate(hp_items = pmap(
    c(list(hp_order), dplyr::select(., all_of(hp_cols))),
    function(order, ...) {
      df <- tibble(...)
      bind_cols(
        remap_fss_items(df, "HiddenProfile_Jitsi", 1:3, order),
        remap_fss_items(df, "HiddenProfile_Chat", 1:3, order)
      )
    }
  ))

# Funktion für Cronbach's Alpha und Mittelwert
aggregate_flow <- function(df, prefix, difficulties) {
  results <- list()
  
  # NEU: Alpha-Ausgabe Header
  cat("\n=== Cronbach's Alpha für", prefix, "===\n")
  
  for (d in difficulties) {
    for (comm in c("Chat", "Jitsi")) {
      # Prefix korrekt setzen – für HiddenProfile mit Unterstrich
      full_prefix <- if (prefix == "HiddenProfile") {
        paste0(prefix, "_", comm)
      } else {
        paste0(prefix, comm)
      }
      
      items <- sprintf("%s.%s.player.fss%02d", full_prefix, d, 1:10)
      valid_items <- items[items %in% names(df)]
      
      if (length(valid_items) >= 2) {
        item_df <- df[valid_items]
        alpha_val <- tryCatch(psych::alpha(item_df)$total$raw_alpha, error = function(e) NA)
        scale_mean <- rowMeans(item_df, na.rm = TRUE)
        
        # NEU: Alpha-Wert ausgeben
        scale_name <- paste0(prefix, "_", d, "_", comm)
        if (!is.na(alpha_val)) {
          cat(sprintf("%-20s: α = %.3f\n", scale_name, alpha_val))
        } else {
          cat(sprintf("%-20s: α = NA\n", scale_name))
        }
        
      } else {
        alpha_val <- NA
        scale_mean <- rep(NA, nrow(df))
        
        # NEU: Ausgabe für zu wenige Items
        scale_name <- paste0(prefix, "_", d, "_", comm)
        cat(sprintf("%-20s: α = NA (nur %d Items)\n", scale_name, length(valid_items)))
      }
      
      col_name <- paste0("fss_", prefix, "_", d, "_", comm)
      results[[col_name]] <- scale_mean
    }
  }
  as.data.frame(results)
}


full_items <- bind_cols(
  data["participant.code"],
  map_dfr(math_data$math_items, identity),
  map_dfr(hp_data$hp_items, identity)
)

# Skalen berechnen
math_scores <- aggregate_flow(full_items, "math", c("A", "O", "F", "B"))
hp_scores   <- aggregate_flow(full_items, "HiddenProfile", c("EASY", "MED", "HARD"))

# Enddatensatz mit allen Skalen
flow_scores <- bind_cols(full_items["participant.code"], math_scores, hp_scores)

# Wide → Long
flow_scores_long <- flow_scores %>%
  pivot_longer(
    cols = -participant.code,
    names_to = "scale_name",
    values_to = "flow_score"
  )

# Zerlegen von scale_name in task, difficulty, comm
flow_scores_long <- flow_scores_long %>%
  separate(scale_name, into = c("fss", "task", "difficulty", "comm"), sep = "_", remove = TRUE) %>%
  dplyr::select(-fss)

# NaN-Zeilen rausfiltern: nur tatsächliche Kommunikationsbedingung behalten
flow_scores_long <- flow_scores_long %>%
  filter(!is.na(flow_score))

data <- data %>%
  mutate(
    math_order = map(participant.condition_order, parse_order_string),
    hp_order   = map(participant.hp_condition_order, parse_order_string)
  )

# condition_order ergänzen
flow_scores_long <- flow_scores_long %>%
  left_join(data %>% dplyr::select(participant.code, participant.condition_order), by = "participant.code") %>%
  mutate(condition_order = participant.condition_order) %>%
  dplyr::select(-participant.condition_order)

# condition_order ergänzen
flow_scores_long <- flow_scores_long %>%
  left_join(data %>% dplyr::select(participant.code, participant.hp_condition_order), by = "participant.code") %>%
  mutate(hp_condition_order = participant.hp_condition_order) %>%
  dplyr::select(-participant.hp_condition_order)

# Team-ID erzeugen (falls noch nicht erfolgt)
data <- data %>%
  mutate(team_id = paste(session.code, Intro.1.group.custom_group_id, sep = "_"))

# Team-ID ergänzen
flow_scores_long <- flow_scores_long %>%
  left_join(data %>% dplyr::select(participant.code, team_id), by = "participant.code")

# Einheitliche Schreibweise für spätere Filter
flow_scores_long <- flow_scores_long %>%
  mutate(
    task = dplyr::recode(task,
                  "math" = "Math",
                  "HiddenProfile" = "HP"),
    difficulty = dplyr::recode(difficulty,
                        "B" = "Easy",
                        "A" = "Optimal_Selected",
                        "F" = "Optimal_Calibrated",
                        "O" = "Hard",
                        "EASY" = "Easy",
                        "MED" = "Medium",
                        "HARD" = "Hard")
  )

# Jetzt den Long-Datensatz als neuen flow_scores verwenden
flow_scores <- flow_scores_long

flow_scores <- flow_scores %>%
  mutate(
    order = case_when(
      task == "Math" ~ condition_order,
      task == "HP"   ~ hp_condition_order,
      TRUE           ~ NA_character_
    )
  ) %>%
  dplyr::select(-condition_order, -hp_condition_order)

# Boxplot erstellen
ggplot(flow_scores, aes(x = interaction(task, comm, sep = " - "), y = flow_score, fill = task)) +
  geom_boxplot(outlier.shape = NA, alpha = 0.7) +
  geom_jitter(width = 0.2, alpha = 0.4, color = "black", size = 1) +
  labs(
    title = "Flow-Scores nach Experimentalbedingung",
    x = "Bedingung (Task - Medium)",
    y = "Flow-Score"
  ) +
  scale_fill_brewer(palette = "Set2") +
  theme_minimal(base_size = 14) +
  theme(legend.position = "none")

```

Outlier check

```{r}
# Ausreißer-Analyse für Flow-Scores
# ================================================================================

# 1. Ausreißer identifizieren (gruppenweise)
flow_scores_outlier <- flow_scores %>%
  group_by(task, comm) %>%
  mutate(
    mean_flow = mean(flow_score, na.rm = TRUE),
    sd_flow = sd(flow_score, na.rm = TRUE),
    z_score = (flow_score - mean_flow) / sd_flow,
    is_outlier = abs(z_score) > 2,
    outlier_direction = case_when(
      z_score > 2 ~ "high",
      z_score < -2 ~ "low",
      TRUE ~ "normal"
    )
  ) %>%
  ungroup()

# 2. Zusammenfassung der Ausreißer
outlier_summary <- flow_scores_outlier %>%
  group_by(task, comm) %>%
  dplyr::summarise(
    n_total = n(),
    n_outliers = sum(is_outlier),
    n_high = sum(outlier_direction == "high"),
    n_low = sum(outlier_direction == "low"),
    pct_outliers = round(mean(is_outlier) * 100, 2),
    mean_flow = round(mean(flow_score, na.rm = TRUE), 3),
    sd_flow = round(sd(flow_score, na.rm = TRUE), 3),
    .groups = "drop"
  )

print("Ausreißer-Zusammenfassung nach Bedingung:")
print(outlier_summary)

# 3. Gesamtübersicht
total_outliers <- flow_scores_outlier %>%
  dplyr::summarise(
    total_observations = n(),
    total_outliers = sum(is_outlier),
    pct_outliers = round(mean(is_outlier) * 100, 2)
  )

print("\nGesamtanzahl Ausreißer:")
print(total_outliers)

# 4. Details zu den Ausreißern
outlier_details <- flow_scores_outlier %>%
  filter(is_outlier) %>%
  dplyr::select(participant.code, task, comm, difficulty, flow_score, z_score, outlier_direction) %>%
  arrange(desc(abs(z_score)))

print("\nTop 10 extremste Ausreißer:")
print(head(outlier_details, 10))

# 5. Visualisierung der Ausreißer
library(ggplot2)

# Boxplot mit Ausreißern markiert
p1 <- ggplot(flow_scores_outlier, aes(x = interaction(task, comm), y = flow_score)) +
  geom_boxplot(aes(fill = task), alpha = 0.7) +
  geom_point(data = filter(flow_scores_outlier, is_outlier), 
             aes(color = outlier_direction), size = 3) +
  scale_color_manual(values = c("high" = "red", "low" = "blue")) +
  labs(title = "Flow-Scores mit markierten Ausreißern (>2 SD)",
       x = "Bedingung", y = "Flow Score",
       color = "Ausreißer-Typ") +
  theme_minimal()

print(p1)

# Z-Score Verteilung
p2 <- ggplot(flow_scores_outlier, aes(x = z_score)) +
  geom_histogram(bins = 30, fill = "lightblue", color = "black", alpha = 0.7) +
  geom_vline(xintercept = c(-2, 2), color = "red", linetype = "dashed") +
  facet_wrap(~ interaction(task, comm)) +
  labs(title = "Z-Score Verteilung der Flow-Werte",
       subtitle = "Rote Linien = ±2 SD Grenze",
       x = "Z-Score", y = "Häufigkeit") +
  theme_minimal()

print(p2)

# 6. Ausreißer nach Schwierigkeit untersuchen
outlier_by_difficulty <- flow_scores_outlier %>%
  group_by(difficulty, task) %>%
  dplyr::summarise(
    n_total = n(),
    n_outliers = sum(is_outlier),
    pct_outliers = round(mean(is_outlier) * 100, 2),
    outlier_types = paste(
      "High:", sum(outlier_direction == "high"),
      "Low:", sum(outlier_direction == "low")
    ),
    .groups = "drop"
  )

print("\nAusreißer nach Schwierigkeitsstufe:")
print(outlier_by_difficulty)

# 7. Prüfen ob bestimmte Teilnehmer häufig Ausreißer sind
participant_outlier_freq <- flow_scores_outlier %>%
  group_by(participant.code) %>%
  dplyr::summarise(
    n_measurements = n(),
    n_outlier = sum(is_outlier),
    pct_outlier = round(mean(is_outlier) * 100, 2)
  ) %>%
  filter(n_outlier > 0) %>%
  arrange(desc(n_outlier))

print("\nTeilnehmer mit Ausreißer-Messungen:")
print(head(participant_outlier_freq, 10))

# 8. Team-Level Ausreißer prüfen (für Shared Flow)
team_flow_outliers <- flow_scores_outlier %>%
  group_by(team_id, task, comm) %>%
  dplyr::summarise(
    team_mean_flow = mean(flow_score, na.rm = TRUE),
    team_sd_flow = sd(flow_score, na.rm = TRUE),
    n_members = n(),
    n_outlier_members = sum(is_outlier),
    .groups = "drop"
  ) %>%
  group_by(task, comm) %>%
  mutate(
    grand_mean = mean(team_mean_flow, na.rm = TRUE),
    grand_sd = sd(team_mean_flow, na.rm = TRUE),
    team_z_score = (team_mean_flow - grand_mean) / grand_sd,
    is_team_outlier = abs(team_z_score) > 2
  ) %>%
  filter(is_team_outlier)

print("\nTeams mit extremen Flow-Werten:")
print(team_flow_outliers)

flow_clean <- flow_scores_outlier %>%
  dplyr::filter(!is_outlier) %>%
  # Entferne die Ausreißer-Analyse-Spalten (optional, falls du sie nicht brauchst)
  dplyr::select(-mean_flow, -sd_flow, -z_score, -is_outlier, -outlier_direction)
```


Flow proneness consistency check and score calculation

```{r}
# Flow Proneness Items
flowp_items <- data %>%
  dplyr::select(participant.code,
         starts_with("Outro.1.player.fpw"),
         starts_with("Outro.1.player.fph"),
         starts_with("Outro.1.player.fpl"))

flowp_items <- flowp_items %>%
  mutate(
    `Outro.1.player.fpl1` = 6 - `Outro.1.player.fpl1`,
    `Outro.1.player.fph1` = 6 - `Outro.1.player.fph1`,
    `Outro.1.player.fpw1` = 6 - `Outro.1.player.fpw1`
  )

# Prüfe interne Konsistenz pro Dimension
alpha_work <- psych::alpha(flowp_items %>% dplyr::select(starts_with("Outro.1.player.fpw"))); alpha_work
alpha_household <- psych::alpha(flowp_items %>% dplyr::select(starts_with("Outro.1.player.fph"))); alpha_household
alpha_leisure <- psych::alpha(flowp_items %>% dplyr::select(starts_with("Outro.1.player.fpl"))); alpha_leisure

# Aggregiere zu drei Scores + Gesamtwert
flow_proneness_scores <- flowp_items %>%
  mutate(
    fp_work = rowMeans(dplyr::select(., starts_with("Outro.1.player.fpw")), na.rm = TRUE),
    fp_household = rowMeans(dplyr::select(., starts_with("Outro.1.player.fph")), na.rm = TRUE),
    fp_leisure = rowMeans(dplyr::select(., starts_with("Outro.1.player.fpl")), na.rm = TRUE)
  ) %>%
  mutate(fp_total = rowMeans(dplyr::select(., fp_work, fp_household, fp_leisure), na.rm = TRUE)) %>%
  dplyr::select(participant.code, fp_total)

flow_scores <- flow_scores %>%
  left_join(flow_proneness_scores, by = "participant.code")

flow_clean <- flow_clean %>%
  left_join(flow_proneness_scores, by = "participant.code")
```

Linear mixed model for flow with individual-level variables (level-1) nested within teams (level-2), Calculation of Goodness-of-Fit criteria AIC, BIC, Marginal R2 and Conditional R2

```{r}
# Erweiterte Regressionsanalyse mit emmeans Post-Hoc Tests

library(lme4)
library(performance)
library(emmeans)
library(dplyr)
library(tibble)

# ================================================================================
# TEIL 1: MATH TASK ANALYSE
# ================================================================================

print("=== MATH TASK REGRESSIONSANALYSE ===")

# Filter: Nur Mathe-Task
flow_scores_math <- flow_clean %>% 
  filter(task == "Math")

# Modell-Datensatz vorbereiten
model_data_math <- flow_scores_math %>%
  mutate(
    synchronicity = ifelse(comm == "Jitsi", "High", "Low"),
    synchronicity = factor(synchronicity, levels = c("Low", "High")),
    difficulty = factor(difficulty, levels = c("Easy", "Optimal_Selected", "Optimal_Calibrated", "Hard"))
  )

print(sprintf("Math Task: %d Beobachtungen, %d Teams, %d Teilnehmer", 
              nrow(model_data_math),
              length(unique(model_data_math$team_id)),
              length(unique(model_data_math$participant.code))))

# Modell 1: Synchronicity + Difficulty
print("\n--- MATH MODELL 1: Haupteffekte ---")
model_math_1 <- lmer(
  flow_score ~ synchronicity + difficulty + 
    (1 | team_id) + (1 | participant.code),
  data = model_data_math
)
summary(model_math_1)

# Modell 2: Interaktion hinzufügen
print("\n--- MATH MODELL 2: Mit Interaktion ---")
model_math_2 <- lmer(
  flow_score ~ synchronicity * difficulty + 
    (1 | team_id) + (1 | participant.code),
  data = model_data_math
)
summary(model_math_2)

# Modell 3: Zusätzlich Flow Proneness & Condition Order
print("\n--- MATH MODELL 3: Vollständiges Modell ---")
model_math_3 <- lmer(
  flow_score ~ synchronicity * difficulty + 
    fp_total + order +
    (1 | team_id) + (1 | participant.code),
  data = model_data_math
)
summary(model_math_3)
anova(model_math_3)

# Modellvergleich
print("\n--- MATH MODELLVERGLEICH ---")
aic_comparison_math <- AIC(model_math_1, model_math_2, model_math_3)
bic_comparison_math <- BIC(model_math_1, model_math_2, model_math_3)
print("AIC Vergleich:")
print(aic_comparison_math)
print("BIC Vergleich:")
print(bic_comparison_math)

# R² Vergleich
r2_math_1 <- r2(model_math_1)
r2_math_2 <- r2(model_math_2)
r2_math_3 <- r2(model_math_3)

print("\nR² Vergleich:")
print(paste("Modell 1 - Marginal R²:", round(r2_math_1$R2_marginal, 4), 
            "Conditional R²:", round(r2_math_1$R2_conditional, 4)))
print(paste("Modell 2 - Marginal R²:", round(r2_math_2$R2_marginal, 4), 
            "Conditional R²:", round(r2_math_2$R2_conditional, 4)))
print(paste("Modell 3 - Marginal R²:", round(r2_math_3$R2_marginal, 4), 
            "Conditional R²:", round(r2_math_3$R2_conditional, 4)))

# ================================================================================
# TEIL 1b: MATH TASK - EMMEANS POST-HOC TESTS
# ================================================================================

print("\n=== MATH TASK - EMMEANS POST-HOC ANALYSEN ===")

# Wähle das beste Modell für Post-Hoc Tests (basierend auf AIC/BIC)
best_math_model <- model_math_3  # Anpassbar je nach Ergebnissen

# Between-Subjects Tests: Synchronicity Unterschiede für jede Difficulty
print("\n--- Between-Subjects Tests: Synchronicity|Difficulty ---")
bs_tests_math <- emmeans(best_math_model, specs = pairwise ~ synchronicity|difficulty, adjust = "none")$contrasts %>%
  as_tibble() %>%
  # Manuelle BH Korrektur
  mutate(p.adj = p.adjust(p.value, "BH")) %>%
  # Difficulty Labels anpassen (falls gewünscht)
  mutate(difficulty = dplyr::recode(difficulty, 
                                   "Easy" = "Easy",
                                   "Optimal_Selected" = "Optimal\n(Selected)",
                                   "Optimal_Calibrated" = "Optimal\n(Calibrated)",
                                   "Hard" = "Hard")) %>%
  # Numerische Werte runden (neue Syntax)
  mutate(across(where(is.numeric), ~ round(.x, 4)))

print("Between-Subjects Tests (Synchronicity Vergleiche pro Difficulty):")
print(bs_tests_math)

# Within-Subjects Tests: Difficulty Unterschiede für jede Synchronicity
print("\n--- Within-Subjects Tests: Difficulty|Synchronicity ---")
ws_tests_math <- emmeans(best_math_model, specs = pairwise ~ difficulty|synchronicity, adjust = "none")$contrasts %>%
  as_tibble() %>%
  # Manuelle BH Korrektur
  mutate(p.adj = p.adjust(p.value, "BH")) %>%
  # Numerische Werte runden (neue Syntax)
  mutate(across(where(is.numeric), ~ round(.x, 4)))

print("Within-Subjects Tests (Difficulty Vergleiche pro Synchronicity):")
print(ws_tests_math)

# Marginal Means zur Interpretation
print("\n--- Marginal Means für Math Task ---")
marginal_means_math <- emmeans(best_math_model, ~ synchronicity * difficulty) %>%
  as_tibble() %>%
  mutate(across(where(is.numeric), ~ round(.x, 4)))
print(marginal_means_math)

# ================================================================================
# TEIL 2: HIDDEN PROFILE TASK ANALYSE
# ================================================================================

print("\n\n=== HIDDEN PROFILE TASK REGRESSIONSANALYSE ===")

# Filter: Nur HP-Task
flow_scores_hp <- flow_clean %>% 
  filter(task == "HP")

# Modell-Datensatz vorbereiten
model_data_hp <- flow_scores_hp %>%
  mutate(
    synchronicity = ifelse(comm == "Jitsi", "High", "Low"),
    synchronicity = factor(synchronicity, levels = c("Low", "High")),
    difficulty = factor(difficulty, levels = c("Easy", "Medium", "Hard"))  # HP hat nur 3 Stufen
  )

print(sprintf("HP Task: %d Beobachtungen, %d Teams, %d Teilnehmer", 
              nrow(model_data_hp),
              length(unique(model_data_hp$team_id)),
              length(unique(model_data_hp$participant.code))))

# Modell 1: Synchronicity + Difficulty
print("\n--- HP MODELL 1: Haupteffekte ---")
model_hp_1 <- lmer(
  flow_score ~ synchronicity + difficulty + 
    (1 | team_id) + (1 | participant.code),
  data = model_data_hp
)
summary(model_hp_1)

# Modell 2: Interaktion hinzufügen
print("\n--- HP MODELL 2: Mit Interaktion ---")
model_hp_2 <- lmer(
  flow_score ~ synchronicity * difficulty + 
    (1 | team_id) + (1 | participant.code),
  data = model_data_hp
)
summary(model_hp_2)

# Modell 3: Zusätzlich Flow Proneness & Condition Order
print("\n--- HP MODELL 3: Vollständiges Modell ---")
model_hp_3 <- lmer(
  flow_score ~ synchronicity * difficulty + 
    fp_total + order +
    (1 | team_id) + (1 | participant.code),
  data = model_data_hp
)
summary(model_hp_3)
anova(model_hp_3)

# Modellvergleich
print("\n--- HP MODELLVERGLEICH ---")
aic_comparison_hp <- AIC(model_hp_1, model_hp_2, model_hp_3)
bic_comparison_hp <- BIC(model_hp_1, model_hp_2, model_hp_3)
print("AIC Vergleich:")
print(aic_comparison_hp)
print("BIC Vergleich:")
print(bic_comparison_hp)

# R² Vergleich
r2_hp_1 <- r2(model_hp_1)
r2_hp_2 <- r2(model_hp_2)
r2_hp_3 <- r2(model_hp_3)

print("\nR² Vergleich:")
print(paste("Modell 1 - Marginal R²:", round(r2_hp_1$R2_marginal, 4), 
            "Conditional R²:", round(r2_hp_1$R2_conditional, 4)))
print(paste("Modell 2 - Marginal R²:", round(r2_hp_2$R2_marginal, 4), 
            "Conditional R²:", round(r2_hp_2$R2_conditional, 4)))
print(paste("Modell 3 - Marginal R²:", round(r2_hp_3$R2_marginal, 4), 
            "Conditional R²:", round(r2_hp_3$R2_conditional, 4)))

# ================================================================================
# TEIL 2b: HIDDEN PROFILE TASK - EMMEANS POST-HOC TESTS
# ================================================================================

print("\n=== HIDDEN PROFILE TASK - EMMEANS POST-HOC ANALYSEN ===")

# Wähle das beste Modell für Post-Hoc Tests
best_hp_model <- model_hp_3  # Anpassbar je nach Ergebnissen

# Between-Subjects Tests: Synchronicity Unterschiede für jede Difficulty
print("\n--- Between-Subjects Tests: Synchronicity|Difficulty ---")
bs_tests_hp <- emmeans(best_hp_model, specs = pairwise ~ synchronicity|difficulty, adjust = "none")$contrasts %>%
  as_tibble() %>%
  # Manuelle BH Korrektur
  mutate(p.adj = p.adjust(p.value, "BH")) %>%
  # Numerische Werte runden (neue Syntax)
  mutate(across(where(is.numeric), ~ round(.x, 4)))

print("Between-Subjects Tests (Synchronicity Vergleiche pro Difficulty):")
print(bs_tests_hp)

# Within-Subjects Tests: Difficulty Unterschiede für jede Synchronicity
print("\n--- Within-Subjects Tests: Difficulty|Synchronicity ---")
ws_tests_hp <- emmeans(best_hp_model, specs = pairwise ~ difficulty|synchronicity, adjust = "none")$contrasts %>%
  as_tibble() %>%
  # Manuelle BH Korrektur
  mutate(p.adj = p.adjust(p.value, "BH")) %>%
  # Numerische Werte runden (neue Syntax)
  mutate(across(where(is.numeric), ~ round(.x, 4)))

print("Within-Subjects Tests (Difficulty Vergleiche pro Synchronicity):")
print(ws_tests_hp)

# Marginal Means zur Interpretation
print("\n--- Marginal Means für HP Task ---")
marginal_means_hp <- emmeans(best_hp_model, ~ synchronicity * difficulty) %>%
  as_tibble() %>%
  mutate(across(where(is.numeric), ~ round(.x, 4)))
print(marginal_means_hp)

# ================================================================================
# TEIL 3: ÜBERGREIFENDE ZUSAMMENFASSUNG
# ================================================================================

print("\n\n=== ÜBERGREIFENDE ZUSAMMENFASSUNG ===")

# Sammle signifikante Ergebnisse
print("\n--- Signifikante Between-Subjects Effekte (Synchronicity) ---")

# Math Task signifikante BS Effekte
math_significant_bs <- bs_tests_math %>%
  filter(p.adj < 0.05) %>%
  mutate(Task = "Math")

# HP Task signifikante BS Effekte  
hp_significant_bs <- bs_tests_hp %>%
  filter(p.adj < 0.05) %>%
  mutate(Task = "HP")

# Kombiniere signifikante Ergebnisse
all_significant_bs <- bind_rows(math_significant_bs, hp_significant_bs)

if (nrow(all_significant_bs) > 0) {
  print("Signifikante Synchronicity Unterschiede:")
  print(all_significant_bs %>% dplyr::select(Task, difficulty, estimate, p.value, p.adj))
} else {
  print("Keine signifikanten Synchronicity Unterschiede gefunden.")
}

print("\n--- Signifikante Within-Subjects Effekte (Difficulty) ---")

# Math Task signifikante WS Effekte
math_significant_ws <- ws_tests_math %>%
  filter(p.adj < 0.05) %>%
  mutate(Task = "Math")

# HP Task signifikante WS Effekte
hp_significant_ws <- ws_tests_hp %>%
  filter(p.adj < 0.05) %>%
  mutate(Task = "HP")

# Kombiniere signifikante Ergebnisse
all_significant_ws <- bind_rows(math_significant_ws, hp_significant_ws)

if (nrow(all_significant_ws) > 0) {
  print("Signifikante Difficulty Unterschiede:")
  print(all_significant_ws %>% 
         dplyr::select(Task, synchronicity, contrast, estimate, p.value, p.adj) %>%
         head(10))  # Zeige nur die ersten 10 wegen der Vielzahl an Paarvergleichen
} else {
  print("Keine signifikanten Difficulty Unterschiede gefunden.")
}

# Interaction Plots für Estimated Marginal Means
# ================================================================================

library(ggplot2)
library(emmeans)

print("=== INTERACTION PLOTS FÜR ESTIMATED MARGINAL MEANS ===")

# ================================================================================
# TEIL 1: MATH TASK INTERACTION PLOT
# ================================================================================

print("--- MATH TASK INTERACTION PLOT ---")

# Erstelle ggplot-kompatible Daten für Math Task
math_plot_data <- marginal_means_math %>%
  mutate(
    # Kommunikationslabel anpassen
    communication = case_when(
      synchronicity == "Low" ~ "Chat",
      synchronicity == "High" ~ "Jitsi"
    ),
    # Schwierigkeitslabel anpassen für bessere Darstellung
    difficulty_label = case_when(
      difficulty == "Easy" ~ "Easy",
      difficulty == "Optimal_Selected" ~ "Optimal\n(Selected)",
      difficulty == "Optimal_Calibrated" ~ "Optimal\n(Calibrated)", 
      difficulty == "Hard" ~ "Hard"
    ),
    # Ordne Schwierigkeitsgrade
    difficulty_ordered = factor(difficulty_label, 
                               levels = c("Easy", "Optimal\n(Selected)", 
                                        "Optimal\n(Calibrated)", "Hard"))
  )

# Math Task Plot
p_math <- ggplot(math_plot_data, aes(x = difficulty_ordered, y = emmean, 
                                    color = communication, group = communication)) +
  geom_line(size = 1.2, alpha = 0.8) +
  geom_point(size = 3, alpha = 0.9) +
  geom_errorbar(aes(ymin = emmean - SE, ymax = emmean + SE), 
                width = 0.1, alpha = 0.7) +
  scale_color_manual(values = c("Chat" = "#E31A1C", "Jitsi" = "#1F78B4")) +
  labs(
    title = "Math Task: Flow Score by Communication and Difficulty",
    subtitle = "Estimated Marginal Means with Standard Errors",
    x = "Difficulty Level",
    y = "Estimated Flow Score",
    color = "Communication"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(size = 14, face = "bold"),
    plot.subtitle = element_text(size = 12),
    axis.title = element_text(size = 12),
    axis.text = element_text(size = 10),
    legend.title = element_text(size = 12),
    legend.text = element_text(size = 11),
    panel.grid.minor = element_blank(),
    panel.grid.major.x = element_blank()
  ) +
  # Y-Achse anpassen
  scale_y_continuous(limits = c(
    min(math_plot_data$emmean - math_plot_data$SE) * 0.95,
    max(math_plot_data$emmean + math_plot_data$SE) * 1.05
  ))

print(p_math)

# ================================================================================
# TEIL 2: HIDDEN PROFILE TASK INTERACTION PLOT
# ================================================================================

print("--- HIDDEN PROFILE TASK INTERACTION PLOT ---")

# Erstelle ggplot-kompatible Daten für HP Task
hp_plot_data <- marginal_means_hp %>%
  mutate(
    # Kommunikationslabel anpassen
    communication = case_when(
      synchronicity == "Low" ~ "Chat",
      synchronicity == "High" ~ "Jitsi"
    ),
    # Schwierigkeitslabel für HP Task (normalerweise Easy, Medium, Hard)
    difficulty_ordered = factor(difficulty, levels = unique(difficulty))
  )

# HP Task Plot
p_hp <- ggplot(hp_plot_data, aes(x = difficulty_ordered, y = emmean, 
                                color = communication, group = communication)) +
  geom_line(size = 1.2, alpha = 0.8) +
  geom_point(size = 3, alpha = 0.9) +
  geom_errorbar(aes(ymin = emmean - SE, ymax = emmean + SE), 
                width = 0.1, alpha = 0.7) +
  scale_color_manual(values = c("Chat" = "#E31A1C", "Jitsi" = "#1F78B4")) +
  labs(
    title = "Hidden Profile Task: Flow Score by Communication and Difficulty",
    subtitle = "Estimated Marginal Means with Standard Errors",
    x = "Difficulty Level",
    y = "Estimated Flow Score",
    color = "Communication"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(size = 14, face = "bold"),
    plot.subtitle = element_text(size = 12),
    axis.title = element_text(size = 12),
    axis.text = element_text(size = 10),
    legend.title = element_text(size = 12),
    legend.text = element_text(size = 11),
    panel.grid.minor = element_blank(),
    panel.grid.major.x = element_blank()
  ) +
  # Y-Achse anpassen
  scale_y_continuous(limits = c(
    min(hp_plot_data$emmean - hp_plot_data$SE) * 0.95,
    max(hp_plot_data$emmean + hp_plot_data$SE) * 1.05
  ))

print(p_hp)

# ================================================================================
# TEIL 3: KOMBINIERTER PLOT (BEIDE TASKS)
# ================================================================================

print("--- KOMBINIERTER PLOT: BEIDE TASKS ---")

# Kombiniere beide Datensätze
combined_plot_data <- bind_rows(
  math_plot_data %>% mutate(task = "Math Task"),
  hp_plot_data %>% 
    mutate(task = "Hidden Profile Task",
           difficulty_label = as.character(difficulty),
           difficulty_ordered = factor(difficulty))
)

# Kombinierter Plot mit Facets
p_combined <- ggplot(combined_plot_data, aes(x = difficulty_ordered, y = emmean, 
                                           color = communication, group = communication)) +
  geom_line(size = 1.2, alpha = 0.8) +
  geom_point(size = 3, alpha = 0.9) +
  geom_errorbar(aes(ymin = emmean - SE, ymax = emmean + SE), 
                width = 0.1, alpha = 0.7) +
  facet_wrap(~ task, scales = "free_x") +
  scale_color_manual(values = c("Chat" = "#E31A1C", "Jitsi" = "#1F78B4")) +
  labs(
    title = "Flow Score by Communication and Difficulty Across Tasks",
    subtitle = "Estimated Marginal Means with Standard Errors",
    x = "Difficulty Level",
    y = "Estimated Flow Score",
    color = "Communication"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(size = 14, face = "bold"),
    plot.subtitle = element_text(size = 12),
    axis.title = element_text(size = 12),
    axis.text = element_text(size = 10),
    axis.text.x = element_text(angle = 45, hjust = 1),
    legend.title = element_text(size = 12),
    legend.text = element_text(size = 11),
    strip.text = element_text(size = 12, face = "bold"),
    panel.grid.minor = element_blank(),
    panel.grid.major.x = element_blank()
  )

print(p_combined)

# ================================================================================
# TEIL 4: ALTERNATIVE DARSTELLUNG - PUNKTE MIT KONFIDENZINTERVALLEN
# ================================================================================

print("--- ALTERNATIVE: KONFIDENZINTERVALL-PLOT ---")

# Math Task mit Konfidenzintervallen
p_math_ci <- ggplot(math_plot_data, aes(x = difficulty_ordered, y = emmean, 
                                       color = communication)) +
  geom_pointrange(aes(ymin = lower.CL, ymax = upper.CL), 
                  position = position_dodge(width = 0.3), size = 0.8) +
  geom_point(position = position_dodge(width = 0.3), size = 2.5) +
  scale_color_manual(values = c("Chat" = "#E31A1C", "Jitsi" = "#1F78B4")) +
  labs(
    title = "Math Task: Flow Score with 95% Confidence Intervals",
    x = "Difficulty Level",
    y = "Estimated Flow Score",
    color = "Communication"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(size = 14, face = "bold"),
    axis.title = element_text(size = 12),
    axis.text = element_text(size = 10),
    legend.title = element_text(size = 12),
    legend.text = element_text(size = 11),
    panel.grid.minor = element_blank(),
    panel.grid.major.x = element_blank()
  )

print(p_math_ci)

# ================================================================================
# TEIL 5: INTERPRETATION HELPER
# ================================================================================

print("\n=== INTERPRETATION DER PLOTS ===")

# Berechne Unterschiede zwischen Chat und Jitsi für jede Schwierigkeitsstufe
print("--- Math Task: Chat vs. Jitsi Unterschiede pro Schwierigkeitsstufe ---")
math_differences <- math_plot_data %>%
  dplyr::select(difficulty_ordered, communication, emmean) %>%
  pivot_wider(names_from = communication, values_from = emmean) %>%
  mutate(
    difference = Jitsi - Chat,
    interpretation = case_when(
      difference > 0.2 ~ "Jitsi deutlich höher",
      difference > 0.05 ~ "Jitsi leicht höher", 
      difference < -0.2 ~ "Chat deutlich höher",
      difference < -0.05 ~ "Chat leicht höher",
      TRUE ~ "Etwa gleich"
    )
  )

print(math_differences)

print("\n--- Hidden Profile Task: Chat vs. Jitsi Unterschiede pro Schwierigkeitsstufe ---")
hp_differences <- hp_plot_data %>%
  dplyr::select(difficulty_ordered, communication, emmean) %>%
  pivot_wider(names_from = communication, values_from = emmean) %>%
  mutate(
    difference = Jitsi - Chat,
    interpretation = case_when(
      difference > 0.2 ~ "Jitsi deutlich höher",
      difference > 0.05 ~ "Jitsi leicht höher",
      difference < -0.2 ~ "Chat deutlich höher", 
      difference < -0.05 ~ "Chat leicht höher",
      TRUE ~ "Etwa gleich"
    )
  )

print(hp_differences)

# Speichere Plots (optional)
# ggsave("math_task_interaction_plot.png", p_math, width = 10, height = 6, dpi = 300)
# ggsave("hp_task_interaction_plot.png", p_hp, width = 10, height = 6, dpi = 300)
# ggsave("combined_tasks_interaction_plot.png", p_combined, width = 12, height = 6, dpi = 300)

print("\n=== PLOTS ERSTELLT ===")
print("Verfügbare Plot-Objekte:")
print("- p_math: Math Task Interaction Plot")
print("- p_hp: Hidden Profile Task Interaction Plot") 
print("- p_combined: Beide Tasks kombiniert")
print("- p_math_ci: Math Task mit Konfidenzintervallen")
```

Comparison of communication media (NONE/CHAT/JITSI)

```{r}
# ================================================================================
# TEIL 1: DATENAUFBEREITUNG UND -ZUSAMMENFÜHRUNG
# ================================================================================

# Aktuelle Daten: Nur Math Task
current_data <- flow_clean %>%
  filter(task == "Math") %>%
  dplyr::select(participant.code, team_id, difficulty, comm, flow_score, order, fp_total) %>%
  # Spaltennamen für Konsistenz anpassen
  dplyr::rename(
    participant_id = participant.code,
    session_id = team_id
  ) %>%
  # Communication Medium als kategoriale Variable
  mutate(
    comm_type = case_when(
      comm == "Jitsi" ~ "Video",
      comm == "Chat" ~ "Chat"
    ),
    data_source = "Current"
  ) %>%
  dplyr::select(-comm)  # Original comm Spalte entfernen

print(sprintf("Aktuelle Daten: %d Beobachtungen, %d Teams, %d Teilnehmer",
              nrow(current_data),
              length(unique(current_data$session_id)),
              length(unique(current_data$participant_id))))

# Historische Daten: Nur MP Treatment
historical_data_prep <- data_old %>%
  filter(Treatment == "MP") %>%  # Nur Multi-Player
  dplyr::select(SessionID, SubjectID, Condition, Order, flowFKS_9, flowProne.General)

# Erstelle Order-Strings für historische Daten (analog zu flow_clean)
print("Erstelle Order-Strings für historische Daten...")

historical_order_mapping <- historical_data_prep %>%
  dplyr::select(SessionID, Condition, Order) %>%
  distinct() %>%
  # Condition zu Difficulty-Buchstaben mapping (entsprechend deinem Recode)
  mutate(
    difficulty_code = case_when(
      Condition == 1 ~ "B",  # Easy
      Condition == 2 ~ "A",  # Optimal_Selected
      Condition == 3 ~ "F",  # Optimal_Calibrated  
      Condition == 4 ~ "O"   # Hard
    )
  ) %>%
  # Sortiere nach Order um die richtige Reihenfolge zu bekommen
  arrange(SessionID, Order) %>%
  # Erstelle Order-String für jedes Team
  group_by(SessionID) %>%
  dplyr::summarise(
    order_string = paste0("['", paste(difficulty_code, collapse = "', '"), "']"),
    .groups = "drop"
  )
  # WICHTIG: Behalte SessionID hier bei!

print("Beispiel Order-Mappings:")
print(head(historical_order_mapping, 5))

# Jetzt die historischen Daten mit Order-Strings verknüpfen
historical_data <- historical_data_prep %>%
  # ERST das Join BEVOR du umbenennst!
  left_join(historical_order_mapping, by = "SessionID") %>%
  # DANN erst umbenennen
  dplyr::rename(
    session_id = SessionID,
    participant_id = SubjectID,
    condition_num = Condition,
    order_position = Order,
    flow_score = flowFKS_9,
    fp_total = flowProne.General
  ) %>%
  # Condition Numbers zu Difficulty Labels konvertieren (entsprechend deinem Mapping)
  mutate(
    difficulty = case_when(
      condition_num == 1 ~ "Easy",           # B
      condition_num == 2 ~ "Optimal_Selected",  # A
      condition_num == 3 ~ "Optimal_Calibrated", # F
      condition_num == 4 ~ "Hard"            # O
    ),
    comm_type = "None",  # Keine Kommunikation im alten Experiment
    data_source = "Historical"
  ) %>%
  # Order-String als order-Spalte verwenden (analog zu aktuellen Daten)
  dplyr::rename(order = order_string) %>%
  dplyr::select(-condition_num, -order_position)

print(sprintf("Historische Daten: %d Beobachtungen, %d Teams, %d Teilnehmer",
              nrow(historical_data),
              length(unique(historical_data$session_id)),
              length(unique(historical_data$participant_id))))

# Kombiniere beide Datensätze
combined_data <- bind_rows(current_data, historical_data) %>%
  # Faktoren für Modellierung erstellen
  mutate(
    difficulty = factor(difficulty, levels = c("Easy", "Optimal_Selected", "Optimal_Calibrated", "Hard")),
    comm_type = factor(comm_type, levels = c("None", "Chat", "Video")),
    data_source = factor(data_source, levels = c("Historical", "Current"))
  )

print(sprintf("Kombinierte Daten: %d Beobachtungen gesamt",
              nrow(combined_data)))

# Überblick über die Datenverteilung
print("\n--- Datenverteilung nach Communication Type ---")
print(table(combined_data$comm_type, combined_data$data_source))

print("\n--- Datenverteilung nach Difficulty ---")
print(table(combined_data$difficulty, combined_data$comm_type))

# ================================================================================
# TEIL 2: DESKRIPTIVE STATISTIKEN
# ================================================================================

print("\n=== DESKRIPTIVE STATISTIKEN ===")

# Grundstatistiken nach Communication Type
descriptive_stats <- combined_data %>%
  group_by(comm_type, data_source) %>%
  dplyr::summarise(
    n_obs = n(),
    n_teams = length(unique(session_id)),
    n_participants = length(unique(participant_id)),
    mean_flow = mean(flow_score, na.rm = TRUE),
    sd_flow = sd(flow_score, na.rm = TRUE),
    mean_fp = mean(fp_total, na.rm = TRUE),
    sd_fp = sd(fp_total, na.rm = TRUE),
    .groups = "drop"
  ) %>%
  mutate(across(where(is.numeric), ~ round(.x, 3)))

print("Deskriptive Statistiken nach Communication Type:")
print(descriptive_stats)

# Detaillierte Statistiken nach Difficulty
detailed_stats <- combined_data %>%
  group_by(comm_type, difficulty) %>%
  dplyr::summarise(
    n_obs = n(),
    mean_flow = mean(flow_score, na.rm = TRUE),
    sd_flow = sd(flow_score, na.rm = TRUE),
    .groups = "drop"
  ) %>%
  mutate(across(where(is.numeric), ~ round(.x, 3)))

print("\n--- Flow Scores nach Communication Type und Difficulty ---")
print(detailed_stats)

# ================================================================================
# TEIL 3: REGRESSIONSMODELLE FÜR VERGLEICH
# ================================================================================

print("\n=== REGRESSIONSANALYSE - HISTORISCHER VERGLEICH ===")

# Modell 1: Nur Communication Type (Haupteffekt)
print("\n--- MODELL 1: Communication Type Haupteffekt ---")
model_historical_1 <- lmer(
  flow_score ~ comm_type + 
    (1 | session_id) + (1 | participant_id),
  data = combined_data
)
summary(model_historical_1)

# Modell 2: Communication Type + Difficulty
print("\n--- MODELL 2: Communication Type + Difficulty ---")
model_historical_2 <- lmer(
  flow_score ~ comm_type + difficulty + 
    (1 | session_id) + (1 | participant_id),
  data = combined_data
)
summary(model_historical_2)

# Modell 3: Mit Interaktion
print("\n--- MODELL 3: Communication Type × Difficulty Interaktion ---")
model_historical_3 <- lmer(
  flow_score ~ comm_type * difficulty + 
    (1 | session_id) + (1 | participant_id),
  data = combined_data
)
summary(model_historical_3)

# Modell 4: Vollständiges Modell mit Flow Proneness
print("\n--- MODELL 4: Vollständiges Modell mit Covariaten ---")
model_historical_4 <- lmer(
  flow_score ~ comm_type * difficulty + fp_total +
    (1 | session_id) + (1 | participant_id),
  data = combined_data
)
summary(model_historical_4)

# Modellvergleich
print("\n--- MODELLVERGLEICH ---")
historical_aic <- AIC(model_historical_1, model_historical_2, model_historical_3, model_historical_4)
historical_bic <- BIC(model_historical_1, model_historical_2, model_historical_3, model_historical_4)

print("AIC Vergleich:")
print(historical_aic)
print("BIC Vergleich:")
print(historical_bic)

# ================================================================================
# TEIL 4: EMMEANS POST-HOC TESTS
# ================================================================================

print("\n=== EMMEANS POST-HOC ANALYSEN - HISTORISCHER VERGLEICH ===")

# Bestes Modell für Post-Hoc Tests verwenden (anpassbar)
best_historical_model <- model_historical_4

# Communication Type Vergleiche (Paarweise)
print("\n--- Communication Type Paarvergleiche ---")
comm_comparisons <- emmeans(best_historical_model, specs = pairwise ~ comm_type, adjust = "tukey")$contrasts %>%
  as_tibble() %>%
  mutate(across(where(is.numeric), ~ round(.x, 4)))

print("Communication Type Vergleiche:")
print(comm_comparisons)

# Communication Type Vergleiche für jede Difficulty
print("\n--- Communication Type Vergleiche pro Difficulty ---")
comm_by_difficulty <- emmeans(best_historical_model, specs = pairwise ~ comm_type|difficulty, adjust = "tukey")$contrasts %>%
  as_tibble() %>%
  mutate(across(where(is.numeric), ~ round(.x, 4)))

print("Communication Type Vergleiche nach Difficulty:")
print(comm_by_difficulty)

# Marginal Means für Interpretation
print("\n--- Marginal Means: Communication Type × Difficulty ---")
historical_marginal_means <- emmeans(best_historical_model, ~ comm_type * difficulty) %>%
  as_tibble() %>%
  mutate(across(where(is.numeric), ~ round(.x, 4)))
print(historical_marginal_means)

# ================================================================================
# TEIL 5: SPEZIFISCHE VERGLEICHE
# ================================================================================

print("\n=== SPEZIFISCHE HISTORISCHE VERGLEICHE ===")

# 1. None vs. Current Communication (Chat + Video combined)
print("\n--- None vs. Current Communication (kombiniert) ---")

# Erstelle eine neue Gruppierungsvariable
combined_data_grouped <- combined_data %>%
  mutate(
    comm_era = case_when(
      comm_type == "None" ~ "Historical_NoComm",
      comm_type %in% c("Chat", "Video") ~ "Current_WithComm"
    )
  )

model_era_comparison <- lmer(
  flow_score ~ comm_era * difficulty + fp_total +
    (1 | session_id) + (1 | participant_id),
  data = combined_data_grouped
)

era_comparisons <- emmeans(model_era_comparison, specs = pairwise ~ comm_era, adjust = "none")$contrasts %>%
  as_tibble() %>%
  mutate(across(where(is.numeric), ~ round(.x, 4)))

print("Historical vs. Current Era Vergleich:")
print(era_comparisons)

# 2. Specific Focus: None vs Video, None vs Chat
print("\n--- Spezifische Paarvergleiche: None vs Chat vs Video ---")

# Filtere für spezielle Vergleiche
specific_comparisons <- comm_comparisons %>%
  filter(
    grepl("None.*Chat|Chat.*None|None.*Video|Video.*None", contrast)
  )

if (nrow(specific_comparisons) > 0) {
  print("Wichtige Vergleiche (None vs. Kommunikationsmedien):")
  print(specific_comparisons)
}

# ================================================================================
# TEIL 6: ZUSAMMENFASSUNG UND INTERPRETATION
# ================================================================================

print("\n=== ZUSAMMENFASSUNG HISTORISCHER VERGLEICH ===")

# Signifikante Communication Type Effekte
significant_comm_effects <- comm_comparisons %>%
  filter(p.value < 0.05)

if (nrow(significant_comm_effects) > 0) {
  print("Signifikante Communication Type Unterschiede:")
  print(significant_comm_effects %>% dplyr::select(contrast, estimate, p.value))
} else {
  print("Keine signifikanten Communication Type Unterschiede gefunden.")
}

# Effect Sizes für Interpretation
print("\n--- Effect Sizes (Cohen's d approximation) ---")
pooled_sd <- sd(combined_data$flow_score, na.rm = TRUE)

effect_sizes <- comm_comparisons %>%
  mutate(
    cohens_d = abs(estimate) / pooled_sd,
    effect_magnitude = case_when(
      cohens_d < 0.2 ~ "Negligible",
      cohens_d < 0.5 ~ "Small", 
      cohens_d < 0.8 ~ "Medium",
      TRUE ~ "Large"
    )
  ) %>%
  dplyr::select(contrast, estimate, cohens_d, effect_magnitude)

print("Effect Sizes für Communication Type Vergleiche:")
print(effect_sizes)
```

Comparision to single player treatment

```{r}
# Vollständiger historischer Vergleich: Single Player vs Multi Player vs Current (Chat/Video)
# Vier-Weg Vergleich: Allein vs Zusammen (ohne Kommunikation) vs Chat vs Video

library(dplyr)
library(lme4)
library(emmeans)
library(tibble)

print("=== VOLLSTÄNDIGER HISTORISCHER VERGLEICH ===")
print("Single Player vs Multi Player vs Current Communication")

# ================================================================================
# TEIL 1: ERWEITERTE DATENAUFBEREITUNG
# ================================================================================

# Aktuelle Daten: Nur Math Task (bereits vorbereitet, aber nochmal für Vollständigkeit)
current_data_extended <- flow_clean %>%
  filter(task == "Math") %>%
  dplyr::select(participant.code, team_id, difficulty, comm, flow_score, order, fp_total) %>%
  dplyr::rename(
    participant_id = participant.code,
    session_id = team_id
  ) %>%
  mutate(
    communication_condition = case_when(
      comm == "Jitsi" ~ "Together_Video",
      comm == "Chat" ~ "Together_Chat"
    ),
    data_source = "Current"
  ) %>%
  dplyr::select(-comm)

print(sprintf("Aktuelle Daten: %d Beobachtungen, %d Teams, %d Teilnehmer",
              nrow(current_data_extended),
              length(unique(current_data_extended$session_id)),
              length(unique(current_data_extended$participant_id))))

# Historische Daten: ALLE Treatments (SP + MP)
historical_data_prep_all <- data_old %>%
  dplyr::select(SessionID, SubjectID, Treatment, Condition, Order, flowFKS_9, flowProne.General)

# Order-Strings für ALLE historischen Teams erstellen
historical_order_mapping_all <- historical_data_prep_all %>%
  dplyr::select(SessionID, Condition, Order) %>%
  distinct() %>%
  mutate(
    difficulty_code = case_when(
      Condition == 1 ~ "B",  # Easy
      Condition == 2 ~ "A",  # Optimal_Selected
      Condition == 3 ~ "F",  # Optimal_Calibrated  
      Condition == 4 ~ "O"   # Hard
    )
  ) %>%
  arrange(SessionID, Order) %>%
  group_by(SessionID) %>%
  dplyr::summarise(
    order_string = paste0("['", paste(difficulty_code, collapse = "', '"), "']"),
    .groups = "drop"
  )

# Historische Daten mit beiden Treatments
historical_data_extended <- historical_data_prep_all %>%
  dplyr::rename(
    session_id = SessionID,
    participant_id = SubjectID,
    treatment = Treatment,
    condition_num = Condition,
    order_position = Order,
    flow_score = flowFKS_9,
    fp_total = flowProne.General
  ) %>%
  left_join(historical_order_mapping_all, by = c("session_id" = "SessionID")) %>%
  mutate(
    difficulty = case_when(
      condition_num == 1 ~ "Easy",
      condition_num == 2 ~ "Optimal_Selected", 
      condition_num == 3 ~ "Optimal_Calibrated",
      condition_num == 4 ~ "Hard"
    ),
    communication_condition = case_when(
      treatment == "SP" ~ "Alone",
      treatment == "MP" ~ "Together_None"
    ),
    data_source = "Historical"
  ) %>%
  dplyr::rename(order = order_string) %>%
  dplyr::select(-condition_num, -order_position, -treatment)

print(sprintf("Historische Daten: %d Beobachtungen, %d Teams, %d Teilnehmer",
              nrow(historical_data_extended),
              length(unique(historical_data_extended$session_id)),
              length(unique(historical_data_extended$participant_id))))

# Kombiniere ALLE Daten
comprehensive_data <- bind_rows(current_data_extended, historical_data_extended) %>%
  mutate(
    difficulty = factor(difficulty, levels = c("Easy", "Optimal_Selected", "Optimal_Calibrated", "Hard")),
    communication_condition = factor(communication_condition, 
                                   levels = c("Alone", "Together_None", "Together_Chat", "Together_Video")),
    data_source = factor(data_source, levels = c("Historical", "Current"))
  )

print(sprintf("Kombinierte Daten: %d Beobachtungen gesamt", nrow(comprehensive_data)))

# ================================================================================
# TEIL 2: UMFASSENDE DESKRIPTIVE STATISTIKEN
# ================================================================================

print("\n=== UMFASSENDE DESKRIPTIVE STATISTIKEN ===")

# Grundstatistiken nach Communication Condition
comprehensive_stats <- comprehensive_data %>%
  group_by(communication_condition, data_source) %>%
  dplyr::summarise(
    n_obs = n(),
    n_sessions = length(unique(session_id)),
    n_participants = length(unique(participant_id)),
    mean_flow = mean(flow_score, na.rm = TRUE),
    sd_flow = sd(flow_score, na.rm = TRUE),
    median_flow = median(flow_score, na.rm = TRUE),
    mean_fp = mean(fp_total, na.rm = TRUE),
    sd_fp = sd(fp_total, na.rm = TRUE),
    .groups = "drop"
  ) %>%
  mutate(across(where(is.numeric), ~ round(.x, 3)))

print("Umfassende Statistiken nach Communication Condition:")
print(comprehensive_stats)

# Vereinfachte Übersicht (kombiniert über data_source)
simple_stats <- comprehensive_data %>%
  group_by(communication_condition) %>%
  dplyr::summarise(
    n_total = n(),
    mean_flow = mean(flow_score, na.rm = TRUE),
    sd_flow = sd(flow_score, na.rm = TRUE),
    ci_lower = mean_flow - 1.96 * sd_flow / sqrt(n()),
    ci_upper = mean_flow + 1.96 * sd_flow / sqrt(n()),
    .groups = "drop"
  ) %>%
  mutate(across(where(is.numeric), ~ round(.x, 3)))

print("\nVereinfachte Übersicht (alle Conditions):")
print(simple_stats)

# Datenverteilung prüfen
print("\n--- Datenverteilung ---")
print("Nach Communication Condition:")
print(table(comprehensive_data$communication_condition))

print("\nNach Communication Condition und Data Source:")
print(table(comprehensive_data$communication_condition, comprehensive_data$data_source))

print("\nNach Difficulty und Communication Condition:")
difficulty_table <- table(comprehensive_data$difficulty, comprehensive_data$communication_condition)
print(difficulty_table)

# ================================================================================
# TEIL 3: UMFASSENDE REGRESSIONSANALYSE
# ================================================================================

print("\n=== UMFASSENDE REGRESSIONSANALYSE ===")

# Modell 1: Nur Communication Condition
print("\n--- MODELL 1: Communication Condition Haupteffekt ---")
model_comprehensive_1 <- lmer(
  flow_score ~ communication_condition + 
    (1 | session_id) + (1 | participant_id),
  data = comprehensive_data
)
summary(model_comprehensive_1)

# Modell 2: Communication Condition + Difficulty
print("\n--- MODELL 2: Communication Condition + Difficulty ---")
model_comprehensive_2 <- lmer(
  flow_score ~ communication_condition + difficulty + 
    (1 | session_id) + (1 | participant_id),
  data = comprehensive_data
)
summary(model_comprehensive_2)

# Modell 3: Mit Interaktion
print("\n--- MODELL 3: Communication Condition × Difficulty ---")
model_comprehensive_3 <- lmer(
  flow_score ~ communication_condition * difficulty + 
    (1 | session_id) + (1 | participant_id),
  data = comprehensive_data
)
summary(model_comprehensive_3)

# Modell 4: Vollständiges Modell mit Flow Proneness
print("\n--- MODELL 4: Vollständiges Modell ---")
model_comprehensive_4 <- lmer(
  flow_score ~ communication_condition * difficulty + fp_total +
    (1 | session_id) + (1 | participant_id),
  data = comprehensive_data
)
summary(model_comprehensive_4)

# Modellvergleich
print("\n--- MODELLVERGLEICH ---")
comprehensive_aic <- AIC(model_comprehensive_1, model_comprehensive_2, model_comprehensive_3, model_comprehensive_4)
comprehensive_bic <- BIC(model_comprehensive_1, model_comprehensive_2, model_comprehensive_3, model_comprehensive_4)

print("AIC Vergleich:")
print(comprehensive_aic)
print("BIC Vergleich:")
print(comprehensive_bic)

# ================================================================================
# TEIL 4: EMMEANS PAARVERGLEICHE
# ================================================================================

print("\n=== EMMEANS PAARVERGLEICHE - ALLE CONDITIONS ===")

# Bestes Modell verwenden
best_comprehensive_model <- model_comprehensive_4

# Alle paarweisen Vergleiche zwischen Communication Conditions
print("\n--- Alle Communication Condition Paarvergleiche ---")
all_comm_comparisons <- emmeans(best_comprehensive_model, specs = pairwise ~ communication_condition, adjust = "tukey")$contrasts %>%
  as_tibble() %>%
  mutate(across(where(is.numeric), ~ round(.x, 4)))

print("Alle Communication Condition Vergleiche:")
print(all_comm_comparisons)

# Spezifische Vergleiche von Interesse
print("\n--- Spezifische Vergleiche von Interesse ---")

key_comparisons <- all_comm_comparisons %>%
  filter(
    grepl("Alone.*Together", contrast) |
    grepl("Together_None.*Together_Chat", contrast) |
    grepl("Together_None.*Together_Video", contrast) |
    grepl("Together_Chat.*Together_Video", contrast)
  )

if (nrow(key_comparisons) > 0) {
  print("Wichtige Vergleiche:")
  print(key_comparisons %>% dplyr::select(contrast, estimate, p.value))
}

# Marginal Means für alle Conditions
print("\n--- Marginal Means: Communication Conditions ---")
comprehensive_marginal_means <- emmeans(best_comprehensive_model, ~ communication_condition) %>%
  as_tibble() %>%
  mutate(across(where(is.numeric), ~ round(.x, 4)))
print(comprehensive_marginal_means)

# Communication Condition × Difficulty Marginal Means
print("\n--- Marginal Means: Communication × Difficulty ---")
interaction_marginal_means <- emmeans(best_comprehensive_model, ~ communication_condition * difficulty) %>%
  as_tibble() %>%
  mutate(across(where(is.numeric), ~ round(.x, 4)))
print(interaction_marginal_means)

# ================================================================================
# TEIL 5: EFFEKTGRÖSSEN UND PRAKTISCHE BEDEUTSAMKEIT
# ================================================================================

print("\n=== EFFEKTGRÖSSEN UND PRAKTISCHE BEDEUTSAMKEIT ===")

# Berechne Effect Sizes (Cohen's d approximation)
pooled_sd_comprehensive <- sd(comprehensive_data$flow_score, na.rm = TRUE)

effect_sizes_comprehensive <- all_comm_comparisons %>%
  mutate(
    cohens_d = abs(estimate) / pooled_sd_comprehensive,
    effect_magnitude = case_when(
      cohens_d < 0.2 ~ "Vernachlässigbar",
      cohens_d < 0.5 ~ "Klein", 
      cohens_d < 0.8 ~ "Mittel",
      TRUE ~ "Groß"
    ),
    practical_significance = case_when(
      p.value < 0.001 & cohens_d >= 0.5 ~ "Hoch signifikant + praktisch relevant",
      p.value < 0.05 & cohens_d >= 0.5 ~ "Signifikant + praktisch relevant",
      p.value < 0.05 & cohens_d >= 0.2 ~ "Signifikant + kleiner Effekt",
      p.value >= 0.05 ~ "Nicht signifikant",
      TRUE ~ "Signifikant aber vernachlässigbare Effektgröße"
    )
  ) %>%
  dplyr::select(contrast, estimate, p.value, cohens_d, effect_magnitude, practical_significance)

print("Effect Sizes für alle Communication Condition Vergleiche:")
print(effect_sizes_comprehensive)

# ================================================================================
# TEIL 6: ZUSAMMENFASSUNG UND INTERPRETATION
# ================================================================================

print("\n=== ZUSAMMENFASSUNG: VIER-WEG VERGLEICH ===")

# Flow Score Ranking
flow_ranking <- comprehensive_marginal_means %>%
  arrange(desc(emmean)) %>%
  dplyr::select(communication_condition, emmean, SE) %>%
  dplyr::mutate(
    rank = row_number(),
    condition_german = case_when(
      communication_condition == "Alone" ~ "Allein",
      communication_condition == "Together_None" ~ "Zusammen (keine Kommunikation)",
      communication_condition == "Together_Chat" ~ "Zusammen (Chat)",
      communication_condition == "Together_Video" ~ "Zusammen (Video)"
    )
  )

print("Flow Score Ranking (höchste zu niedrigste):")
print(flow_ranking %>% dplyr::select(rank, condition_german, emmean, SE))

# Signifikante Unterschiede zusammenfassen
significant_comparisons <- effect_sizes_comprehensive %>%
  filter(p.value < 0.05) %>%
  arrange(p.value)

print("\nSignifikante Unterschiede (nach p-Wert sortiert):")
if (nrow(significant_comparisons) > 0) {
  print(significant_comparisons %>% dplyr::select(contrast, estimate, p.value, effect_magnitude))
} else {
  print("Keine signifikanten Unterschiede gefunden.")
}

# Interaction Plots für Vollständigen Historischen Vergleich
# Vier-Weg Vergleich: Allein vs Zusammen (ohne Kommunikation) vs Chat vs Video
# ================================================================================

library(ggplot2)
library(emmeans)
library(RColorBrewer)

print("=== INTERACTION PLOTS FÜR VIER-WEG-VERGLEICH ===")

# ================================================================================
# TEIL 1: HAUPTINTERAKTIONSPLOT - ALLE VIER CONDITIONS
# ================================================================================

print("--- HAUPTINTERAKTIONSPLOT: Alle Vier Communication Conditions ---")

# Erstelle ggplot-kompatible Daten für den vollständigen Vergleich
comprehensive_plot_data <- interaction_marginal_means %>%
  mutate(
    # Kommunikationslabel anpassen
    communication_label = case_when(
      communication_condition == "Alone" ~ "Allein",
      communication_condition == "Together_None" ~ "Zusammen\n(keine Komm.)",
      communication_condition == "Together_Chat" ~ "Zusammen\n(Chat)",
      communication_condition == "Together_Video" ~ "Zusammen\n(Video)"
    ),
    # Schwierigkeitslabel anpassen für bessere Darstellung
    difficulty_label = case_when(
      difficulty == "Easy" ~ "Easy",
      difficulty == "Optimal_Selected" ~ "Optimal\n(Selected)",
      difficulty == "Optimal_Calibrated" ~ "Optimal\n(Calibrated)", 
      difficulty == "Hard" ~ "Hard"
    ),
    # Ordne Schwierigkeitsgrade
    difficulty_ordered = factor(difficulty_label, 
                               levels = c("Easy", "Optimal\n(Selected)", 
                                        "Optimal\n(Calibrated)", "Hard")),
    # Ordne Communication Conditions
    communication_ordered = factor(communication_label,
                                 levels = c("Allein", "Zusammen\n(keine Komm.)", 
                                          "Zusammen\n(Chat)", "Zusammen\n(Video)"))
  )

# Farbpalette für vier Bedingungen
color_palette <- c(
  "Allein" = "#E31A1C",                    # Rot
  "Zusammen\n(keine Komm.)" = "#FF7F00",  # Orange  
  "Zusammen\n(Chat)" = "#1F78B4",         # Blau
  "Zusammen\n(Video)" = "#33A02C"         # Grün
)

# Hauptplot: Alle vier Bedingungen
p_comprehensive <- ggplot(comprehensive_plot_data, 
                         aes(x = difficulty_ordered, y = emmean, 
                            color = communication_ordered, group = communication_ordered)) +
  geom_line(size = 1.3, alpha = 0.9) +
  geom_point(size = 3.5, alpha = 0.9) +
  geom_errorbar(aes(ymin = emmean - SE, ymax = emmean + SE), 
                width = 0.15, alpha = 0.7, size = 0.8) +
  scale_color_manual(values = color_palette) +
  labs(
    title = "Flow Score Across Communication Conditions and Difficulty Levels",
    subtitle = "Historical (Allein, Zusammen ohne Kommunikation) vs. Current (Chat, Video)\nEstimated Marginal Means with Standard Errors",
    x = "Difficulty Level",
    y = "Estimated Flow Score",
    color = "Communication\nCondition"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(size = 16, face = "bold", hjust = 0.5),
    plot.subtitle = element_text(size = 12, hjust = 0.5),
    axis.title = element_text(size = 13),
    axis.text = element_text(size = 11),
    axis.text.x = element_text(size = 10),
    legend.title = element_text(size = 12, face = "bold"),
    legend.text = element_text(size = 10),
    panel.grid.minor = element_blank(),
    panel.grid.major.x = element_blank(),
    legend.position = "right"
  ) +
  # Y-Achse anpassen für bessere Sichtbarkeit
  scale_y_continuous(
    limits = c(
      min(comprehensive_plot_data$emmean - comprehensive_plot_data$SE) * 0.95,
      max(comprehensive_plot_data$emmean + comprehensive_plot_data$SE) * 1.05
    ),
    breaks = scales::pretty_breaks(n = 6)
  )

print(p_comprehensive)

```

ANOVA for treatment effects

```{r}
# ================================================================================
   # UMFASSENDE ANOVA-ANALYSE
# ================================================================================

library(car)        # Für Levene-Test und Typ II/III ANOVA
library(effectsize) # Für Effektgrößen (eta-squared, omega-squared)
library(multcomp)   # Für erweiterte Post-hoc Tests
library(nortest)    # Für erweiterte Normalitätstests

print("\n=== UMFASSENDE ANOVA-ANALYSE ===")

# ================================================================================
# SCHRITT 1: ANNAHMEN-ÜBERPRÜFUNG
# ================================================================================

print("\n--- ANNAHMEN-ÜBERPRÜFUNG ---")

# 1. Normalitätstest
print("\n1. NORMALITÄTSTEST")

# Shapiro-Wilk Test (für kleinere Stichproben pro Gruppe)
normality_by_group <- comprehensive_data %>%
  group_by(communication_condition) %>%
  dplyr::summarise(
    n = n(),
    shapiro_w = ifelse(n >= 3 & n <= 5000, shapiro.test(flow_score)$statistic, NA),
    shapiro_p = ifelse(n >= 3 & n <= 5000, shapiro.test(flow_score)$p.value, NA),
    .groups = "drop"
  )

print("Normalitätstest pro Communication Condition:")
print(normality_by_group)

# Anderson-Darling Test für größere Gruppen
print("\nAnderson-Darling Normalitätstest (gesamt):")
ad_test <- nortest::ad.test(comprehensive_data$flow_score)
print(paste("A =", round(ad_test$statistic, 4), ", p =", round(ad_test$p.value, 4)))

# QQ-Plot Daten für visuelle Inspektion vorbereiten
qq_data <- comprehensive_data %>%
  group_by(communication_condition) %>%
  arrange(flow_score) %>%
  dplyr::mutate(
    theoretical_quantile = qnorm(ppoints(n())),
    sample_quantile = flow_score
  ) %>%
  ungroup()

print("QQ-Plot Daten bereit für visuelle Inspektion")

# 2. Homogenität der Varianzen
print("\n2. HOMOGENITÄT DER VARIANZEN")

# Levene-Test
levene_test <- leveneTest(flow_score ~ communication_condition, data = comprehensive_data)
print("Levene-Test für Varianzhomogenität:")
print(levene_test)

# Bartlett-Test (sensitiver für Normalitätsabweichungen)
bartlett_test <- bartlett.test(flow_score ~ communication_condition, data = comprehensive_data)
print("Bartlett-Test für Varianzhomogenität:")
print(paste("Chi-squared =", round(bartlett_test$statistic, 4), 
           ", df =", bartlett_test$parameter, 
           ", p =", round(bartlett_test$p.value, 4)))

# Deskriptive Statistiken pro Gruppe
variance_stats <- comprehensive_data %>%
  group_by(communication_condition) %>%
  dplyr::summarise(
    n = n(),
    mean = mean(flow_score, na.rm = TRUE),
    sd = sd(flow_score, na.rm = TRUE),
    variance = var(flow_score, na.rm = TRUE),
    min_val = min(flow_score, na.rm = TRUE),
    max_val = max(flow_score, na.rm = TRUE),
    .groups = "drop"
  ) %>%
  mutate(across(where(is.numeric) & !matches("n"), ~ round(.x, 3)))

print("\nDeskriptive Statistiken pro Communication Condition:")
print(variance_stats)

# Varianzenverhältnis prüfen (Faustregel: größte/kleinste Varianz < 4)
variance_ratio <- max(variance_stats$variance) / min(variance_stats$variance)
print(paste("Varianzenverhältnis (max/min):", round(variance_ratio, 3)))
print(paste("Homogenitätsannahme erfüllt (< 4):", variance_ratio < 4))

# ================================================================================
# SCHRITT 2: EINFAKTORIELLE ANOVA - COMMUNICATION CONDITION
# ================================================================================

print("\n--- EINFAKTORIELLE ANOVA: COMMUNICATION CONDITION ---")

# Standard ANOVA
anova_comm <- aov(flow_score ~ communication_condition, data = comprehensive_data)
anova_comm_summary <- summary(anova_comm)
print("Einfaktorielle ANOVA - Communication Condition:")
print(anova_comm_summary)

# Typ II ANOVA (robuster bei unbalancierten Designs)
anova_comm_type2 <- Anova(anova_comm, type = "II")
print("\nTyp II ANOVA - Communication Condition:")
print(anova_comm_type2)

# Effektgrößen
eta_squared_comm <- eta_squared(anova_comm, partial = TRUE)
omega_squared_comm <- omega_squared(anova_comm, partial = TRUE)

print("\nEffektgrößen - Communication Condition:")
print("Eta-squared (partiell):")
print(eta_squared_comm)
print("Omega-squared (partiell):")
print(omega_squared_comm)

# ================================================================================
# SCHRITT 3: ZWEIFAKTORIELLE ANOVA - COMMUNICATION × DIFFICULTY  
# ================================================================================

print("\n--- ZWEIFAKTORIELLE ANOVA: COMMUNICATION × DIFFICULTY ---")

# Überprüfe Zellenbesetzung
cell_counts <- table(comprehensive_data$communication_condition, comprehensive_data$difficulty)
print("Zellenbesetzung (Communication × Difficulty):")
print(cell_counts)

# Identifiziere leere Zellen
empty_cells <- which(cell_counts == 0, arr.ind = TRUE)
if(nrow(empty_cells) > 0) {
  print("WARNUNG: Leere Zellen gefunden!")
  print(empty_cells)
} else {
  print("Keine leeren Zellen - Design ist balanciert genug für ANOVA")
}

# Zweifaktorielle ANOVA
anova_full <- aov(flow_score ~ communication_condition * difficulty, data = comprehensive_data)
anova_full_summary <- summary(anova_full)
print("\nZweifaktorielle ANOVA (Communication × Difficulty):")
print(anova_full_summary)

# Typ III ANOVA (für unbalancierte Designs mit Interaktionen)
anova_full_type3 <- Anova(anova_full, type = "III")
print("\nTyp III ANOVA - Communication × Difficulty:")
print(anova_full_type3)

# Effektgrößen für alle Faktoren
eta_squared_full <- eta_squared(anova_full, partial = TRUE)
omega_squared_full <- omega_squared(anova_full, partial = TRUE)

print("\nEffektgrößen - Vollständiges Modell:")
print("Eta-squared (partiell):")
print(eta_squared_full)
print("Omega-squared (partiell):")
print(omega_squared_full)

# ================================================================================
# SCHRITT 4: ANCOVA - MIT FLOW PRONENESS
# ================================================================================

print("\n--- ANCOVA: COMMUNICATION × DIFFICULTY + FLOW PRONENESS ---")

# ANCOVA mit Flow Proneness als Kovariate
ancova_model <- aov(flow_score ~ communication_condition * difficulty + fp_total, 
                   data = comprehensive_data)
ancova_summary <- summary(ancova_model)
print("ANCOVA mit Flow Proneness:")
print(ancova_summary)

# Typ III ANCOVA
ancova_type3 <- Anova(ancova_model, type = "III")
print("\nTyp III ANCOVA:")
print(ancova_type3)

# Effektgrößen ANCOVA
eta_squared_ancova <- eta_squared(ancova_model, partial = TRUE)
print("\nEffektgrößen ANCOVA:")
print(eta_squared_ancova)

# ================================================================================
# SCHRITT 5: POST-HOC TESTS
# ================================================================================

print("\n--- POST-HOC TESTS ---")

# Tukey HSD für Communication Condition
print("\n1. TUKEY HSD - COMMUNICATION CONDITION")
tukey_comm <- TukeyHSD(anova_comm)
print("Tukey HSD Ergebnisse:")
print(tukey_comm)

# Tukey HSD für vollständiges Modell (falls Interaktion signifikant)
if(anova_full_summary[[1]][3, 5] < 0.05) {  # Interaktion p-Wert
  print("\n2. TUKEY HSD - COMMUNICATION × DIFFICULTY (da Interaktion signifikant)")
  tukey_full <- TukeyHSD(anova_full, which = "communication_condition:difficulty")
  print(tukey_full)
} else {
  print("\n2. Interaktion nicht signifikant - keine Post-hoc Tests für Interaktion nötig")
}

# Bonferroni-korrigierte paarweise t-Tests als Alternative
print("\n3. BONFERRONI-KORRIGIERTE PAARWEISE T-TESTS")
pairwise_t <- pairwise.t.test(comprehensive_data$flow_score, 
                             comprehensive_data$communication_condition, 
                             p.adjust.method = "bonferroni")
print("Bonferroni-korrigierte paarweise t-Tests:")
print(pairwise_t)

# ================================================================================
# SCHRITT 6: ROBUSTHEITSANALYSEN
# ================================================================================

print("\n--- ROBUSTHEITSANALYSEN ---")

# Welch-ANOVA (robust gegen Varianzheteroskedastizität)
print("\n1. WELCH-ANOVA (robust gegen ungleiche Varianzen)")
welch_anova <- oneway.test(flow_score ~ communication_condition, 
                          data = comprehensive_data, 
                          var.equal = FALSE)
print(welch_anova)

# Kruskal-Wallis Test (nicht-parametrische Alternative)
print("\n2. KRUSKAL-WALLIS TEST (nicht-parametrisch)")
kruskal_test <- kruskal.test(flow_score ~ communication_condition, 
                           data = comprehensive_data)
print(kruskal_test)

# Bei signifikantem Kruskal-Wallis: Dunn-Test für Post-hoc
if(kruskal_test$p.value < 0.05) {
  print("\n3. DUNN-TEST (Post-hoc für Kruskal-Wallis)")
  # Vereinfachter paarweiser Wilcoxon-Test mit Bonferroni-Korrektur
  dunn_alternative <- pairwise.wilcox.test(comprehensive_data$flow_score, 
                                         comprehensive_data$communication_condition,
                                         p.adjust.method = "bonferroni")
  print("Paarweise Wilcoxon-Tests (Bonferroni-korrigiert):")
  print(dunn_alternative)
}

# ================================================================================
# SCHRITT 7: MODELLVERGLEICH UND ZUSAMMENFASSUNG
# ================================================================================

print("\n--- MODELLVERGLEICH: ANOVA vs MIXED-EFFECTS ---")

# AIC/BIC Vergleich zwischen ANOVA und Mixed-Effects Modellen
anova_lm <- lm(flow_score ~ communication_condition * difficulty + fp_total, 
               data = comprehensive_data)

print("Modellvergleich (AIC/BIC):")
print("Mixed-Effects Modell (aus vorheriger Analyse):")
print(paste("AIC:", round(AIC(model_comprehensive_4), 2)))
print(paste("BIC:", round(BIC(model_comprehensive_4), 2)))

print("Standard lineares Modell (ANCOVA):")
print(paste("AIC:", round(AIC(anova_lm), 2)))
print(paste("BIC:", round(BIC(anova_lm), 2)))

# R-squared für ANOVA-Modelle
r_squared_comm <- summary(lm(flow_score ~ communication_condition, data = comprehensive_data))$r.squared
r_squared_full <- summary(lm(flow_score ~ communication_condition * difficulty, data = comprehensive_data))$r.squared  
r_squared_ancova <- summary(anova_lm)$r.squared

print("\nErklärte Varianz (R²):")
print(paste("Nur Communication Condition:", round(r_squared_comm, 4)))
print(paste("Communication × Difficulty:", round(r_squared_full, 4)))
print(paste("ANCOVA (+ Flow Proneness):", round(r_squared_ancova, 4)))

# ================================================================================
# SCHRITT 8: ZUSAMMENFASSUNG DER ANOVA-BEFUNDE
# ================================================================================

print("\n=== ZUSAMMENFASSUNG DER ANOVA-BEFUNDE ===")

# Hauptbefunde extrahieren
comm_f_stat <- anova_comm_summary[[1]][1, 4]  # F-Statistik
comm_p_val <- anova_comm_summary[[1]][1, 5]   # p-Wert
comm_eta_sq <- eta_squared_comm$Eta2_partial[1] # Eta-squared

print("HAUPTBEFUNDE:")
print(sprintf("1. Communication Condition Haupteffekt: F(%d,%d) = %.3f, p = %.4f, η²p = %.3f",
              anova_comm_summary[[1]][1, 1],  # df1
              anova_comm_summary[[1]][2, 1],  # df2  
              comm_f_stat, comm_p_val, comm_eta_sq))

if(comm_p_val < 0.001) {
  significance_level <- "hoch signifikant (p < .001)"
} else if(comm_p_val < 0.01) {
  significance_level <- "sehr signifikant (p < .01)"
} else if(comm_p_val < 0.05) {
  significance_level <- "signifikant (p < .05)"
} else {
  significance_level <- "nicht signifikant (p ≥ .05)"
}

effect_size_interpretation <- case_when(
  comm_eta_sq < 0.01 ~ "vernachlässigbar",
  comm_eta_sq < 0.06 ~ "klein", 
  comm_eta_sq < 0.14 ~ "mittel",
  TRUE ~ "groß"
)

print(sprintf("   Interpretation: %s mit %s Effekt", significance_level, effect_size_interpretation))

# Annahmen-Check Zusammenfassung
assumptions_met <- TRUE
assumption_violations <- c()

if(levene_test$`Pr(>F)`[1] < 0.05) {
  assumptions_met <- FALSE
  assumption_violations <- c(assumption_violations, "Varianzhomogenität verletzt")
}

if(ad_test$p.value < 0.05) {
  assumptions_met <- FALSE  
  assumption_violations <- c(assumption_violations, "Normalität verletzt")
}

print("\n2. ANNAHMEN-ÜBERPRÜFUNG:")
if(assumptions_met) {
  print("   Alle ANOVA-Annahmen erfüllt ✓")
  print("   → Parametrische ANOVA-Ergebnisse sind vertrauenswürdig")
} else {
  print(paste("   Verletzungen:", paste(assumption_violations, collapse = ", ")))
  print("   → Robustheitsanalysen (Welch-ANOVA, Kruskal-Wallis) beachten!")
}

# Konsistenz mit Mixed-Effects Check
print("\n3. KONSISTENZ MIT MIXED-EFFECTS MODELL:")
print("   (Detaillierte Vergleiche siehe vorherige Emmeans-Analyse)")
print("   → Bei ähnlichen p-Werten: Befunde robust über Analysemethoden hinweg")
print("   → Bei unterschiedlichen Ergebnissen: Mixed-Effects bevorzugen (berücksichtigt Datenstruktur)")

print("\n=== ENDE DER ANOVA-ANALYSE ===")
```

Shared flow calculation via Intra-class coefficient (univariate and multivariate)

```{r}
# ================================================================================
# TEIL 1: UNIVARIATE ICCs (nach Task UND Kommunikationsmedium getrennt)
# ================================================================================

print("\n--- UNIVARIATE ICCs ---")

# Daten aufteilen nach Task und Kommunikationsmedium
math_jitsi_data <- model_data_math %>% filter(comm == "Jitsi")
math_chat_data <- model_data_math %>% filter(comm == "Chat")
hp_jitsi_data <- model_data_hp %>% filter(comm == "Jitsi")
hp_chat_data <- model_data_hp %>% filter(comm == "Chat")

# Funktion für Univariate ICC (orientiert an deiner ursprünglichen Version)
compute_univariate_icc_simple <- function(data, name) {
  cat(sprintf("\nUnivariate ICC (%s):\n", name))
  cat(sprintf("Sample: %d Beobachtungen, %d Teams\n", nrow(data), length(unique(data$team_id))))
  
  # Verwende nur team_id als Random Effect (wie in deiner compute_icc Funktion)
  model <- lmer(flow_score ~ 1 + (1 | team_id), data = data)
  icc_result <- icc(model)
  
  print(icc_result)
  return(list(name = name, model = model, icc = icc_result))
}

# Berechne Univariate ICCs für alle Kombinationen
icc_math_jitsi <- compute_univariate_icc_simple(math_jitsi_data, "Math-Jitsi")
icc_math_chat <- compute_univariate_icc_simple(math_chat_data, "Math-Chat")
icc_hp_jitsi <- compute_univariate_icc_simple(hp_jitsi_data, "HP-Jitsi")
icc_hp_chat <- compute_univariate_icc_simple(hp_chat_data, "HP-Chat")

# ================================================================================
# TEIL 2: MULTIVARIATE ICCs nach Difficulty
# ================================================================================

print("\n--- MULTIVARIATE ICCs nach Difficulty separiert---")

# Funktion für Multivariate ICC (wie deine ursprüngliche compute_icc Funktion)
compute_multivariate_icc_simple <- function(data, base_name) {
  cat(sprintf("\nMultivariate ICCs für %s (Separate ICC pro Difficulty):\n", base_name))
  
  # Verfügbare Difficulty Levels
  difficulties <- unique(data$difficulty)
  cat(sprintf("Difficulty Levels: %s\n", paste(difficulties, collapse = ", ")))
  
  results <- list()
  
  for (level in difficulties) {
    subset_data <- data %>% filter(difficulty == level)
    
    if (nrow(subset_data) > 0 && length(unique(subset_data$team_id)) > 1) {
      cat(sprintf("\n%s - %s:\n", base_name, level))
      cat(sprintf("Sample: %d Beobachtungen, %d Teams\n", 
                  nrow(subset_data), length(unique(subset_data$team_id))))
      
      model <- lmer(flow_score ~ 1 + (1 | team_id), data = subset_data)
      icc_result <- icc(model)
      print(icc_result)
      
      results[[level]] <- list(
        difficulty = level,
        model = model,
        icc = icc_result,
        n_obs = nrow(subset_data),
        n_teams = length(unique(subset_data$team_id))
      )
    } else {
      cat(sprintf("\n%s - %s: Nicht genügend Daten\n", base_name, level))
      results[[level]] <- NULL
    }
  }
  
  return(results)
}

# ================================================================================
# TEIL 2b: ECHTER MULTIVARIATE ICC
# ================================================================================

print("\n--- ECHTER MULTIVARIATE ICC ---")

# Funktion für echten Multivariate ICC mit multilevel::mult.icc
compute_true_multivariate_icc <- function(data, base_name) {
  cat(sprintf("\nEchter Multivariate ICC für %s:\n", base_name))
  
  # Prüfe verfügbare Daten
  cat(sprintf("Gesamt Sample: %d Beobachtungen, %d Teams\n", 
              nrow(data), length(unique(data$team_id))))
  
  difficulties <- unique(data$difficulty)
  cat(sprintf("Difficulty Levels: %s\n", paste(difficulties, collapse = ", ")))
  
  # Bereite Daten für mult.icc vor
  icc_data <- data %>%
    dplyr::select(flow_score, difficulty, team_id) %>%
    # Verwende explizite dplyr::rename
    dplyr::rename(val = flow_score, Condition = difficulty, SessionID = team_id) %>%
    filter(!is.na(val), !is.na(Condition), !is.na(SessionID))
  
  cat(sprintf("Nach Filterung: %d gültige Beobachtungen\n", nrow(icc_data)))
  
  tryCatch({
    # Multivariate ICC
    multivariate_result <- icc_data %>%
      group_by(Condition) %>%
      mutate(dummy = 1:n()) %>%  # Dummy Variable
      # Prüfe ob genug Daten pro Condition
      filter(n() >= 3, length(unique(SessionID)) >= 2) %>%
      do(multilevel::mult.icc(x = as.data.frame(.[, c("val", "dummy")]), .$SessionID)) %>%
      ungroup() %>%
      dplyr::select(-ICC2) %>%  # Nur ICC1 behalten
      spread(Condition, ICC1) %>%  # Von Long zu Wide
      filter(Variable != "dummy")  # Dummy-Zeile entfernen
    
    # Nur zeigen wenn Ergebnisse vorhanden
    if (!is.null(multivariate_result) && nrow(multivariate_result) > 0) {
      cat("Multivariate ICC Ergebnisse (ICC1 nach Difficulty):\n")
      print(multivariate_result)
    } else {
      cat("Keine gültigen Multivariate ICC Ergebnisse\n")
    }
    
    return(list(
      name = base_name,
      result = multivariate_result,
      raw_data = icc_data
    ))
    
  }, error = function(e) {
    cat(sprintf("Fehler bei Multivariate ICC Berechnung: %s\n", e$message))
    cat("Mögliche Gründe: Zu wenig Daten pro Condition oder zu wenig Teams\n")
    return(NULL)
  })
}

# Berechne separate univariate ICCs pro Difficulty
cat("\n=== SEPARATE ICCs PRO DIFFICULTY LEVEL ===")
multivariate_math_jitsi <- compute_multivariate_icc_simple(math_jitsi_data, "Math-Jitsi")
multivariate_math_chat <- compute_multivariate_icc_simple(math_chat_data, "Math-Chat")
multivariate_hp_jitsi <- compute_multivariate_icc_simple(hp_jitsi_data, "HP-Jitsi")
multivariate_hp_chat <- compute_multivariate_icc_simple(hp_chat_data, "HP-Chat")

# Berechne echte Multivariate ICCs
cat("\n=== ECHTER MULTIVARIATE ICC ===")
true_multi_math_jitsi <- compute_true_multivariate_icc(math_jitsi_data, "Math-Jitsi")
true_multi_math_chat <- compute_true_multivariate_icc(math_chat_data, "Math-Chat")
true_multi_hp_jitsi <- compute_true_multivariate_icc(hp_jitsi_data, "HP-Jitsi")
true_multi_hp_chat <- compute_true_multivariate_icc(hp_chat_data, "HP-Chat")

# ================================================================================
# TEIL 3: ZUSAMMENFASSUNG UND VERGLEICHE
# ================================================================================

print("\n\n=== ZUSAMMENFASSUNG UND VERGLEICHE ===")

# Extrahiere ICC-Werte für Vergleich (robust gegen verschiedene icc() Output-Formate)
extract_icc_value <- function(icc_result) {
  if (is.list(icc_result)) {
    # Versuche verschiedene Feldnamen
    if ("ICC_adjusted" %in% names(icc_result)) {
      return(icc_result$ICC_adjusted)
    } else if ("ICC_conditional" %in% names(icc_result)) {
      return(icc_result$ICC_conditional)  
    } else if (length(icc_result) > 0) {
      return(icc_result[[1]]) # Nimm den ersten Wert
    }
  } else if (is.numeric(icc_result)) {
    return(icc_result[1]) # Falls es ein numerischer Vektor ist
  }
  return(NA)
}

# Erstelle Vergleichstabelle für Univariate ICCs
univariate_comparison <- data.frame(
  Task_Communication = c("Math-Jitsi", "Math-Chat", "HP-Jitsi", "HP-Chat"),
  ICC_Value = c(
    extract_icc_value(icc_math_jitsi$icc),
    extract_icc_value(icc_math_chat$icc),
    extract_icc_value(icc_hp_jitsi$icc),
    extract_icc_value(icc_hp_chat$icc)
  ),
  N_Observations = c(
    nrow(math_jitsi_data),
    nrow(math_chat_data),
    nrow(hp_jitsi_data),
    nrow(hp_chat_data)
  ),
  N_Teams = c(
    length(unique(math_jitsi_data$team_id)),
    length(unique(math_chat_data$team_id)),
    length(unique(hp_jitsi_data$team_id)),
    length(unique(hp_chat_data$team_id))
  )
)

cat("\nUnivariate ICC Vergleich:\n")
print(univariate_comparison)

# Analysiere Unterschiede zwischen Kommunikationsmedien
cat("\nVergleich zwischen Kommunikationsmedien:\n")

# Math Task Vergleich
math_jitsi_value <- univariate_comparison$ICC_Value[univariate_comparison$Task_Communication == "Math-Jitsi"]
math_chat_value <- univariate_comparison$ICC_Value[univariate_comparison$Task_Communication == "Math-Chat"]

if (!is.na(math_jitsi_value) && !is.na(math_chat_value)) {
  cat(sprintf("Math Task: Jitsi (%.4f) vs Chat (%.4f) - Differenz: %.4f\n", 
              math_jitsi_value, math_chat_value, math_jitsi_value - math_chat_value))
}

# HP Task Vergleich  
hp_jitsi_value <- univariate_comparison$ICC_Value[univariate_comparison$Task_Communication == "HP-Jitsi"]
hp_chat_value <- univariate_comparison$ICC_Value[univariate_comparison$Task_Communication == "HP-Chat"]

if (!is.na(hp_jitsi_value) && !is.na(hp_chat_value)) {
  cat(sprintf("HP Task: Jitsi (%.4f) vs Chat (%.4f) - Differenz: %.4f\n", 
              hp_jitsi_value, hp_chat_value, hp_jitsi_value - hp_chat_value))
}

# Erstelle Multivariate Zusammenfassung (beide Methoden)
create_multivariate_summary <- function(results, name) {
  cat(sprintf("\n%s - Separate ICCs nach Difficulty:\n", name))
  
  for (difficulty in names(results)) {
    result <- results[[difficulty]]
    if (!is.null(result)) {
      icc_val <- extract_icc_value(result$icc)
      if (!is.na(icc_val)) {
        cat(sprintf("  %s: ICC = %.4f (%d obs, %d teams)\n", 
                    difficulty, icc_val, result$n_obs, result$n_teams))
      }
    }
  }
}

create_multivariate_summary(multivariate_math_jitsi, "Math-Jitsi")
create_multivariate_summary(multivariate_math_chat, "Math-Chat")
create_multivariate_summary(multivariate_hp_jitsi, "HP-Jitsi")
create_multivariate_summary(multivariate_hp_chat, "HP-Chat")

cat("\n=== ECHTE MULTIVARIATE ICC ERGEBNISSE ===\n")

show_true_multivariate <- function(result, name) {
  cat(sprintf("\n%s - Echter Multivariate ICC:\n", name))
  
  if (!is.null(result) && !is.null(result$result)) {
    if (nrow(result$result) > 0) {
      # Extrahiere und zeige die ICC-Werte ohne die Tabelle nochmal zu printen
      numeric_cols <- sapply(result$result, is.numeric)
      if (any(numeric_cols)) {
        cat("ICC1-Werte nach Difficulty:\n")
        for (col in names(result$result)[numeric_cols]) {
          val <- result$result[[col]][1]
          if (!is.na(val)) {
            cat(sprintf("  %s: ICC1 = %.4f\n", col, val))
          }
        }
      }
    } else {
      cat("Keine gültigen Ergebnisse verfügbar\n")
    }
  } else {
    cat("Multivariate ICC konnte nicht berechnet werden\n")
  }
}

if (!is.null(true_multi_math_jitsi)) show_true_multivariate(true_multi_math_jitsi, "Math-Jitsi")
if (!is.null(true_multi_math_chat)) show_true_multivariate(true_multi_math_chat, "Math-Chat")
if (!is.null(true_multi_hp_jitsi)) show_true_multivariate(true_multi_hp_jitsi, "HP-Jitsi")
if (!is.null(true_multi_hp_chat)) show_true_multivariate(true_multi_hp_chat, "HP-Chat")
```

Correlation of flow with anticipated mediators

```{r}
# Master Thesis Analysis: Flow Mediation Analysis
# Getrennte Analysen für Math und Hidden Profile Tasks

library(dplyr)
library(tidyr)
library(lme4)
library(lmerTest)
library(rmcorr)
library(ggplot2)
library(psych)

# Konflikt zwischen plyr und dplyr lösen
summarise <- dplyr::summarise
mutate <- dplyr::mutate
select <- dplyr::select

# ================================================================================
# TEIL 1: DATENAUFBEREITUNG - NEUE MEDIATOREN
# ================================================================================

# Funktion zur Extraktion rundenweiser Mediatoren
extract_round_based_mediators <- function(data, var_pattern, var_name) {
  # Extrahiere alle relevanten Spalten
  med_data <- data %>%
    select(participant.code, contains("player")) %>%
    select(participant.code, matches(paste0("(mathJitsi|mathChat|HiddenProfile_Jitsi|HiddenProfile_Chat).*\\.", var_pattern, "$")))
  
  # Umstrukturierung in Long-Format
  med_long <- med_data %>%
    pivot_longer(cols = -participant.code, 
                 names_to = "variable", 
                 values_to = "value") %>%
    filter(!is.na(value)) %>%
    mutate(
      task = case_when(
        grepl("^math", variable) ~ "Math",
        grepl("^HiddenProfile", variable) ~ "HP"
      ),
      comm = case_when(
        grepl("Jitsi", variable) ~ "Jitsi",
        grepl("Chat", variable) ~ "Chat"
      ),
      round_raw = as.numeric(gsub(".*\\.(\\d+)\\.player.*", "\\1", variable)),
      # Standardisiere Rundennummern: Math 3-6 wird zu 1-4, HP 1-3 bleibt 1-3
      round = case_when(
        task == "Math" ~ round_raw - 2,  # Math: 3-6 wird zu 1-4
        task == "HP" ~ round_raw          # HP: 1-3 bleibt 1-3
      ),
      mediator = var_name
    ) %>%
    # Filtere nur die relevanten Runden
    filter((task == "Math" & round_raw >= 3 & round_raw <= 6) | 
           (task == "HP" & round_raw >= 1 & round_raw <= 3)) %>%
    select(participant.code, task, comm, round, mediator, value)
  
  return(med_long)
}

# Funktion zur Extraktion von Mediatoren mit mehreren Items
extract_multi_item_mediators <- function(data, items, var_name, round_based = TRUE) {
  if(round_based) {
    # Für rundenweise Mediatoren
    all_data <- data.frame()
    
    for(item in items) {
      item_data <- extract_round_based_mediators(data, item, paste0(var_name, "_", item))
      all_data <- bind_rows(all_data, item_data)
    }
    
    # Aggregiere über Items
    aggregated <- all_data %>%
      mutate(base_mediator = var_name) %>%
      group_by(participant.code, task, comm, round, base_mediator) %>%
      summarise(value = mean(value, na.rm = TRUE), .groups = "drop") %>%
      dplyr::rename(mediator = base_mediator)
    
    return(aggregated)
  } else {
    # Für einmalige Mediatoren (nur letzte Runde)
    med_data <- data %>%
      select(participant.code, contains("player"))
    
    # Erstelle Pattern für letzte Runde
    patterns <- c()
    for(item in items) {
      # Math: Runde 6, HP: Runde 3
      patterns <- c(patterns, 
                    paste0("mathJitsi\\.6\\.player\\.", item, "$"),
                    paste0("mathChat\\.6\\.player\\.", item, "$"),
                    paste0("HiddenProfile_Jitsi\\.3\\.player\\.", item, "$"),
                    paste0("HiddenProfile_Chat\\.3\\.player\\.", item, "$"))
    }
    
    # Kombiniere alle Patterns
    combined_pattern <- paste(patterns, collapse = "|")
    
    # Wähle relevante Spalten
    med_data <- med_data %>%
      select(participant.code, matches(combined_pattern))
    
    # Umstrukturierung
    med_long <- med_data %>%
      pivot_longer(cols = -participant.code, 
                   names_to = "variable", 
                   values_to = "value") %>%
      filter(!is.na(value)) %>%
      mutate(
        task = case_when(
          grepl("^math", variable) ~ "Math",
          grepl("^HiddenProfile", variable) ~ "HP"
        ),
        comm = case_when(
          grepl("Jitsi", variable) ~ "Jitsi",
          grepl("Chat", variable) ~ "Chat"
        ),
        item = gsub(".*\\.(\\w+)$", "\\1", variable)
      )
    
    # Aggregiere über Items
    aggregated <- med_long %>%
      group_by(participant.code, task, comm) %>%
      summarise(value = mean(value, na.rm = TRUE), .groups = "drop")
    
    return(aggregated)
  }
}

# ================================================================================
# STRUKTURELLE INTEGRATION
# ================================================================================

# Team Composition (nur einmal pro Aufgabe erhoben - letzte Runde)
tc_aggregated <- extract_multi_item_mediators(data, 
                                              c("tsz1", "tsz2", "tsz3", "td1", "td2", "td3", "tsc1", "tsc2", "tsc3"), 
                                              "team_composition", 
                                              round_based = FALSE)

# ================================================================================
# FUNKTIONALE INTEGRATION
# ================================================================================

# Information Sharing (info1, info2) - rundenweise
is_long <- extract_multi_item_mediators(data, c("info1", "info2"), "information_sharing", round_based = TRUE)

# Synchronization (ec1) - rundenweise
sync_long <- extract_round_based_mediators(data, "ec1", "synchronization")

# ================================================================================
# MOTIVATIONALE INTEGRATION
# ================================================================================

# Stress (is1-is5) - rundenweise
stress_long <- extract_multi_item_mediators(data, c("is1", "is2", "is3", "is4", "is5"), "stress", round_based = TRUE)

# Arousal - rundenweise
arousal_long <- extract_round_based_mediators(data, "arousal", "arousal")

# Valence (pleasure) - rundenweise
valence_long <- extract_round_based_mediators(data, "pleasure", "valence")

# Individual Motivation (tm1-tm3) - rundenweise
ind_motiv_long <- extract_multi_item_mediators(data, c("tm1", "tm2", "tm3"), "individual_motivation", round_based = TRUE)

# Team Motivation (te1-te3, nur einmal pro Aufgabe - letzte Runde)
team_motiv_aggregated <- extract_multi_item_mediators(data, c("te1", "te2", "te3"), "team_motivation", round_based = FALSE)

# ================================================================================
# FLOW SCORES VORBEREITEN
# ================================================================================

# Flow Scores aggregieren (falls noch nicht geschehen)
flow_aggregated <- flow_clean %>%
  group_by(participant.code, task, comm) %>%
  summarise(mean_flow_score = mean(flow_score, na.rm = TRUE), .groups = "drop")

# ================================================================================
# TEIL 2: REPEATED MEASURES KORRELATIONEN
# ================================================================================

# Funktion für rmcorr Analyse
perform_rmcorr <- function(data, mediator_name, task_filter) {
  # Filtere nach Task
  task_data <- data %>%
    filter(task == task_filter)
  
  # Flow Scores vorbereiten mit korrekten Rundennummern
  if(task_filter == "Math") {
    # Für Math: Wir brauchen nur die Runden, wo rundenweise Mediatoren gemessen wurden
    flow_round <- flow_clean %>%
      filter(task == task_filter) %>%
      group_by(participant.code, comm) %>%
      arrange(participant.code, comm) %>%
      mutate(round_raw = row_number()) %>%
      # Behalte nur Runden 3-6 (entspricht round 1-4 nach Transformation)
      filter(round_raw >= 3) %>%
      mutate(round = round_raw - 2) %>%
      ungroup()
  } else {
    # Für HP: Runden 1-3
    flow_round <- flow_clean %>%
      filter(task == task_filter) %>%
      group_by(participant.code, comm) %>%
      arrange(participant.code, comm) %>%
      mutate(round = row_number()) %>%
      filter(round <= 3) %>%
      ungroup()
  }
  
  # Merge mit Mediator-Daten
  merged_data <- task_data %>%
    left_join(flow_round %>% select(participant.code, comm, round, flow_score), 
              by = c("participant.code", "comm", "round")) %>%
    filter(!is.na(flow_score) & !is.na(value))
  
  # Berechne rmcorr für jede Kommunikationsbedingung
  results <- list()
  
  for(comm_type in c("Jitsi", "Chat")) {
    comm_data <- merged_data %>% filter(comm == comm_type)
    
    if(nrow(comm_data) > 10) {  # Genug Datenpunkte
      rmcorr_result <- rmcorr(participant = participant.code, 
                              measure1 = value, 
                              measure2 = flow_score, 
                              dataset = comm_data)
      
      results[[comm_type]] <- list(
        r = rmcorr_result$r,
        p = rmcorr_result$p,
        df = rmcorr_result$df,
        CI = rmcorr_result$CI
      )
    }
  }
  
  return(results)
}

# Führe rmcorr für alle rundenweisen Mediatoren durch
print("=== REPEATED MEASURES CORRELATIONS ===\n")

# Liste aller rundenweisen Mediatoren
round_based_mediators <- list(
  "information_sharing" = is_long,
  "synchronization" = sync_long,
  "stress" = stress_long,
  "arousal" = arousal_long,
  "valence" = valence_long,
  "individual_motivation" = ind_motiv_long
)

# Durchführung für Math Task
print("--- MATH TASK ---")
rmcorr_results_math <- list()
for(med_name in names(round_based_mediators)) {
  cat("\n", med_name, ":\n", sep = "")
  result <- perform_rmcorr(round_based_mediators[[med_name]], med_name, "Math")
  rmcorr_results_math[[med_name]] <- result
  
  # Ausgabe
  for(comm in names(result)) {
    cat("  ", comm, ": r = ", round(result[[comm]]$r, 3), 
        ", p = ", round(result[[comm]]$p, 3), 
        ", 95% CI [", round(result[[comm]]$CI[1], 3), ", ", 
        round(result[[comm]]$CI[2], 3), "]\n", sep = "")
  }
}

# Durchführung für HP Task
print("\n--- HIDDEN PROFILE TASK ---")
rmcorr_results_hp <- list()
for(med_name in names(round_based_mediators)) {
  cat("\n", med_name, ":\n", sep = "")
  result <- perform_rmcorr(round_based_mediators[[med_name]], med_name, "HP")
  rmcorr_results_hp[[med_name]] <- result
  
  # Ausgabe
  for(comm in names(result)) {
    cat("  ", comm, ": r = ", round(result[[comm]]$r, 3), 
        ", p = ", round(result[[comm]]$p, 3), 
        ", 95% CI [", round(result[[comm]]$CI[1], 3), ", ", 
        round(result[[comm]]$CI[2], 3), "]\n", sep = "")
  }
}

# ================================================================================
# TEIL 3: LINEAR MIXED MODELS
# ================================================================================

# Funktion für LMM Analysen
perform_lmm_analysis <- function(mediator_data, mediator_name, task_filter, is_round_based = TRUE) {
  
  # Filtere nach Task
  task_data <- mediator_data %>%
    filter(task == task_filter)
  
  if(is_round_based) {
    # Für rundenweise Mediatoren
    # Modell 1: Kommunikationsmedium -> Mediator
    model1 <- lmer(value ~ comm + (1|participant.code) + (1|round), 
                   data = task_data)
    
    # Flow Scores mit korrekten Rundennummern vorbereiten
    if(task_filter == "Math") {
      flow_round <- flow_clean %>%
        filter(task == task_filter) %>%
        group_by(participant.code, comm) %>%
        arrange(participant.code, comm) %>%
        mutate(round_raw = row_number()) %>%
        filter(round_raw >= 3) %>%
        mutate(round = round_raw - 2) %>%
        ungroup()
    } else {
      flow_round <- flow_clean %>%
        filter(task == task_filter) %>%
        group_by(participant.code, comm) %>%
        arrange(participant.code, comm) %>%
        mutate(round = row_number()) %>%
        filter(round <= 3) %>%
        ungroup()
    }
    
    merged_data <- task_data %>%
      left_join(flow_round %>% select(participant.code, comm, round, flow_score), 
                by = c("participant.code", "comm", "round"))
    
    # Modell 2: Mediator -> Flow
    model2 <- lmer(flow_score ~ value + (1|participant.code) + (1|round), 
                   data = merged_data)
    
  } else {
    # Für nicht-rundenweise Mediatoren (rename value column für consistency)
    if("team_composition_score" %in% names(task_data)) {
      task_data <- task_data %>% rename(value = team_composition_score)
    }
    if("team_motivation_score" %in% names(task_data)) {
      task_data <- task_data %>% rename(value = team_motivation_score)
    }
    
    # Modell 1: Kommunikationsmedium -> Mediator
    model1 <- lm(value ~ comm, data = task_data)
    
    # Merge mit aggregierten Flow Scores
    merged_data <- task_data %>%
      left_join(flow_aggregated, by = c("participant.code", "task", "comm"))
    
    # Modell 2: Mediator -> Flow
    model2 <- lm(mean_flow_score ~ value, data = merged_data)
  }
  
  return(list(
    comm_to_mediator = model1,
    mediator_to_flow = model2
  ))
}

# ================================================================================
# LMM ANALYSEN FÜR MATH TASK
# ================================================================================

print("\n\n=== LINEAR MIXED MODELS - MATH TASK ===\n")

# Strukturelle Integration
print("--- STRUKTURELLE INTEGRATION ---")
print("\nTeam Composition:")
tc_models_math <- perform_lmm_analysis(tc_aggregated, "team_composition", "Math", FALSE)
print("Kommunikation -> Team Composition:")
print(summary(tc_models_math$comm_to_mediator))
print("\nTeam Composition -> Flow:")
print(summary(tc_models_math$mediator_to_flow))

# Funktionale Integration
print("\n--- FUNKTIONALE INTEGRATION ---")

print("\nInformation Sharing:")
is_models_math <- perform_lmm_analysis(is_long, "information_sharing", "Math", TRUE)
print("Kommunikation -> Information Sharing:")
print(summary(is_models_math$comm_to_mediator))
print("\nInformation Sharing -> Flow:")
print(summary(is_models_math$mediator_to_flow))

print("\nSynchronization:")
sync_models_math <- perform_lmm_analysis(sync_long, "synchronization", "Math", TRUE)
print("Kommunikation -> Synchronization:")
print(summary(sync_models_math$comm_to_mediator))
print("\nSynchronization -> Flow:")
print(summary(sync_models_math$mediator_to_flow))

# Motivationale Integration
print("\n--- MOTIVATIONALE INTEGRATION ---")

print("\nStress:")
stress_models_math <- perform_lmm_analysis(stress_long, "stress", "Math", TRUE)
print("Kommunikation -> Stress:")
print(summary(stress_models_math$comm_to_mediator))
print("\nStress -> Flow:")
print(summary(stress_models_math$mediator_to_flow))

print("\nArousal:")
arousal_models_math <- perform_lmm_analysis(arousal_long, "arousal", "Math", TRUE)
print("Kommunikation -> Arousal:")
print(summary(arousal_models_math$comm_to_mediator))
print("\nArousal -> Flow:")
print(summary(arousal_models_math$mediator_to_flow))

print("\nValence:")
valence_models_math <- perform_lmm_analysis(valence_long, "valence", "Math", TRUE)
print("Kommunikation -> Valence:")
print(summary(valence_models_math$comm_to_mediator))
print("\nValence -> Flow:")
print(summary(valence_models_math$mediator_to_flow))

print("\nIndividual Motivation:")
ind_motiv_models_math <- perform_lmm_analysis(ind_motiv_long, "individual_motivation", "Math", TRUE)
print("Kommunikation -> Individual Motivation:")
print(summary(ind_motiv_models_math$comm_to_mediator))
print("\nIndividual Motivation -> Flow:")
print(summary(ind_motiv_models_math$mediator_to_flow))

print("\nTeam Motivation:")
tm_models_math <- perform_lmm_analysis(team_motiv_aggregated, "team_motivation", "Math", FALSE)
print("Kommunikation -> Team Motivation:")
print(summary(tm_models_math$comm_to_mediator))
print("\nTeam Motivation -> Flow:")
print(summary(tm_models_math$mediator_to_flow))

# ================================================================================
# LMM ANALYSEN FÜR HP TASK
# ================================================================================

print("\n\n=== LINEAR MIXED MODELS - HIDDEN PROFILE TASK ===\n")

# Strukturelle Integration
print("--- STRUKTURELLE INTEGRATION ---")
print("\nTeam Composition:")
tc_models_hp <- perform_lmm_analysis(tc_aggregated, "team_composition", "HP", FALSE)
print("Kommunikation -> Team Composition:")
print(summary(tc_models_hp$comm_to_mediator))
print("\nTeam Composition -> Flow:")
print(summary(tc_models_hp$mediator_to_flow))

# Funktionale Integration
print("\n--- FUNKTIONALE INTEGRATION ---")

print("\nInformation Sharing:")
is_models_hp <- perform_lmm_analysis(is_long, "information_sharing", "HP", TRUE)
print("Kommunikation -> Information Sharing:")
print(summary(is_models_hp$comm_to_mediator))
print("\nInformation Sharing -> Flow:")
print(summary(is_models_hp$mediator_to_flow))

print("\nSynchronization:")
sync_models_hp <- perform_lmm_analysis(sync_long, "synchronization", "HP", TRUE)
print("Kommunikation -> Synchronization:")
print(summary(sync_models_hp$comm_to_mediator))
print("\nSynchronization -> Flow:")
print(summary(sync_models_hp$mediator_to_flow))

# Motivationale Integration
print("\n--- MOTIVATIONALE INTEGRATION ---")

print("\nStress:")
stress_models_hp <- perform_lmm_analysis(stress_long, "stress", "HP", TRUE)
print("Kommunikation -> Stress:")
print(summary(stress_models_hp$comm_to_mediator))
print("\nStress -> Flow:")
print(summary(stress_models_hp$mediator_to_flow))

print("\nArousal:")
arousal_models_hp <- perform_lmm_analysis(arousal_long, "arousal", "HP", TRUE)
print("Kommunikation -> Arousal:")
print(summary(arousal_models_hp$comm_to_mediator))
print("\nArousal -> Flow:")
print(summary(arousal_models_hp$mediator_to_flow))

print("\nValence:")
valence_models_hp <- perform_lmm_analysis(valence_long, "valence", "HP", TRUE)
print("Kommunikation -> Valence:")
print(summary(valence_models_hp$comm_to_mediator))
print("\nValence -> Flow:")
print(summary(valence_models_hp$mediator_to_flow))

print("\nIndividual Motivation:")
ind_motiv_models_hp <- perform_lmm_analysis(ind_motiv_long, "individual_motivation", "HP", TRUE)
print("Kommunikation -> Individual Motivation:")
print(summary(ind_motiv_models_hp$comm_to_mediator))
print("\nIndividual Motivation -> Flow:")
print(summary(ind_motiv_models_hp$mediator_to_flow))

print("\nTeam Motivation:")
tm_models_hp <- perform_lmm_analysis(team_motiv_aggregated, "team_motivation", "HP", FALSE)
print("Kommunikation -> Team Motivation:")
print(summary(tm_models_hp$comm_to_mediator))
print("\nTeam Motivation -> Flow:")
print(summary(tm_models_hp$mediator_to_flow))

# ================================================================================
# TEIL 4: ZUSAMMENFASSENDE TABELLEN
# ================================================================================

# Funktion zur Extraktion der Koeffizienten
extract_coefficients <- function(model, is_lmm = TRUE) {
  if(is_lmm) {
    coef_summary <- summary(model)$coefficients
    # Extrahiere Koeffizient für commJitsi
    if("commJitsi" %in% rownames(coef_summary)) {
      return(c(
        estimate = coef_summary["commJitsi", "Estimate"],
        se = coef_summary["commJitsi", "Std. Error"],
        t = coef_summary["commJitsi", "t value"],
        p = coef_summary["commJitsi", "Pr(>|t|)"]
      ))
    }
  } else {
    coef_summary <- summary(model)$coefficients
    if("commJitsi" %in% rownames(coef_summary)) {
      return(c(
        estimate = coef_summary["commJitsi", "Estimate"],
        se = coef_summary["commJitsi", "Std. Error"],
        t = coef_summary["commJitsi", "t value"],
        p = coef_summary["commJitsi", "Pr(>|t|)"]
      ))
    }
  }
  
  # Falls value der Prädiktor ist
  if("value" %in% rownames(coef_summary)) {
    return(c(
      estimate = coef_summary["value", "Estimate"],
      se = coef_summary["value", "Std. Error"],
      t = coef_summary["value", "t value"],
      p = coef_summary["value", "Pr(>|t|)"]
    ))
  }
  
  return(c(estimate = NA, se = NA, t = NA, p = NA))
}

# Erstelle Zusammenfassungstabelle für Math Task
create_summary_table <- function(models_list, task_name) {
  summary_data <- data.frame()
  
  for(med_name in names(models_list)) {
    if(!is.null(models_list[[med_name]])) {
      # Kommunikation -> Mediator
      comm_coef <- extract_coefficients(models_list[[med_name]]$comm_to_mediator)
      
      # Mediator -> Flow
      flow_coef <- extract_coefficients(models_list[[med_name]]$mediator_to_flow)
      
      row_data <- data.frame(
        Mediator = med_name,
        Comm_to_Med_Est = round(comm_coef["estimate"], 3),
        Comm_to_Med_p = round(comm_coef["p"], 3),
        Med_to_Flow_Est = round(flow_coef["estimate"], 3),
        Med_to_Flow_p = round(flow_coef["p"], 3)
      )
      
      summary_data <- rbind(summary_data, row_data)
    }
  }
  
  return(summary_data)
}

# Sammle alle Modelle
all_models_math <- list(
  "Team Composition" = tc_models_math,
  "Information Sharing" = is_models_math,
  "Synchronization" = sync_models_math,
  "Stress" = stress_models_math,
  "Arousal" = arousal_models_math,
  "Valence" = valence_models_math,
  "Individual Motivation" = ind_motiv_models_math,
  "Team Motivation" = tm_models_math
)

all_models_hp <- list(
  "Team Composition" = tc_models_hp,
  "Information Sharing" = is_models_hp,
  "Synchronization" = sync_models_hp,
  "Stress" = stress_models_hp,
  "Arousal" = arousal_models_hp,
  "Valence" = valence_models_hp,
  "Individual Motivation" = ind_motiv_models_hp,
  "Team Motivation" = tm_models_hp
)

# Erstelle Zusammenfassungstabellen
print("\n\n=== ZUSAMMENFASSUNGSTABELLEN ===\n")
print("Math Task - Übersicht der Effekte:")
summary_math <- create_summary_table(all_models_math, "Math")
print(summary_math)

print("\n\nHP Task - Übersicht der Effekte:")
summary_hp <- create_summary_table(all_models_hp, "HP")
print(summary_hp)

# ================================================================================
# TEIL 5: VISUALISIERUNGEN
# ================================================================================

# Funktion für Mediator-Plots
create_mediator_plot <- function(mediator_data, mediator_name, task_filter) {
  # Aggregiere Daten für Visualisierung
  plot_data <- mediator_data %>%
    filter(task == task_filter) %>%
    group_by(comm) %>%
    summarise(
      mean_value = mean(value, na.rm = TRUE),
      se_value = sd(value, na.rm = TRUE) / sqrt(n()),
      .groups = "drop"
    )
  
  p <- ggplot(plot_data, aes(x = comm, y = mean_value, fill = comm)) +
    geom_bar(stat = "identity", position = "dodge") +
    geom_errorbar(aes(ymin = mean_value - se_value, ymax = mean_value + se_value),
                  width = 0.2, position = position_dodge(0.9)) +
    labs(title = paste(task_filter, "Task -", mediator_name),
         x = "Communication Medium",
         y = paste("Mean", mediator_name),
         fill = "Communication") +
    theme_minimal() +
    scale_fill_brewer(palette = "Set2")
  
  return(p)
}

# Erstelle Plots für ausgewählte Mediatoren
print("\n=== VISUALISIERUNGEN ===")
print("Erstelle Plots für Mediatoren...")

p1 <- create_mediator_plot(is_long, "Information Sharing", "Math")
p2 <- create_mediator_plot(sync_long, "Synchronization", "Math")
p3 <- create_mediator_plot(stress_long, "Stress", "Math")
p4 <- create_mediator_plot(valence_long, "Valence", "Math")


p5 <- create_mediator_plot(is_long, "Information Sharing", "HP")
p6 <- create_mediator_plot(sync_long, "Synchronization", "HP")
p7 <- create_mediator_plot(stress_long, "Stress", "HP")
p8 <- create_mediator_plot(ind_motiv_long, "Individual Motivation", "HP")

# Zeige Plots
print(p1)
print(p2)
print(p3)
print(p4)
print(p5)
print(p6)
print(p7)
print(p8)

# ================================================================================
# SCHLUSSNOTIZEN
# ================================================================================

print("\n\n=== ANALYSEN ABGESCHLOSSEN ===")
print("1. Repeated Measures Korrelationen für alle rundenweisen Mediatoren berechnet")
print("2. Linear Mixed Models für Kommunikation -> Mediator erstellt")
print("3. Linear Mixed Models für Mediator -> Flow erstellt")
print("4. Getrennte Analysen für Math und HP Tasks durchgeführt")
print("5. Zusammenfassungstabellen mit allen Effekten erstellt")
print("6. Visualisierungen der Mediator-Unterschiede zwischen Kommunikationsmedien erstellt")
```

Mediator differences between the communication treatments between difficulty levels

```{r}
# Mediator-Unterschiede zwischen Chat und Jitsi nach Schwierigkeitsstufe
# Erklärung des Shared Flow Paradoxes: Chat sinkt, Jitsi steigt mit Difficulty
# NUR AKTUELLE DATEN (Chat vs Jitsi)
# ================================================================================

library(lme4)
library(lmerTest)
library(emmeans)
library(dplyr)
library(ggplot2)

print("=== MEDIATOR-UNTERSCHIEDE: CHAT vs JITSI nach DIFFICULTY ===")
print("Analyse basiert auf aktuellen Mediatoren aus dem neuen Experiment")

# ================================================================================
# TEIL 1: DATEN VORBEREITEN - DIREKT AUS AKTUELLEN DATEN
# ================================================================================

# Kombiniere Math und HP Daten aus flow_clean (aktueller Datensatz)
mediator_analysis_base <- flow_clean %>%
  filter(comm %in% c("Chat", "Jitsi")) %>%
  mutate(
    communication = factor(comm, levels = c("Chat", "Jitsi")),
    difficulty_simple = case_when(
      difficulty == "Easy" ~ "Easy",
      difficulty %in% c("Optimal_Selected", "Optimal_Calibrated") ~ "Optimal",
      difficulty == "Hard" ~ "Hard"
    ),
    difficulty_simple = factor(difficulty_simple, levels = c("Easy", "Optimal", "Hard"))
  )

print(paste("Basis-Analysedaten:", nrow(mediator_analysis_base), "Beobachtungen"))
print(paste("Teilnehmer:", n_distinct(mediator_analysis_base$participant.code)))
print(paste("Teams:", n_distinct(mediator_analysis_base$team_id)))

# Überprüfe Datenverteilung
print("\n--- DATENVERTEILUNG ---")
data_distribution <- mediator_analysis_base %>%
  group_by(communication, difficulty_simple, task) %>%
  summarise(
    n_obs = n(),
    n_participants = n_distinct(participant.code),
    .groups = "drop"
  )
print(data_distribution)

# ================================================================================
# TEIL 2: VERWENDE BEREITS EXTRAHIERTE MEDIATOREN
# ================================================================================

print("\n=== VERWENDE BEREITS EXTRAHIERTE MEDIATOREN ===")

# Prüfe welche Mediator-Datensätze verfügbar sind
available_mediator_datasets <- list()

if(exists("stress_long")) {
  available_mediator_datasets[["stress"]] <- stress_long
}
if(exists("is_long")) {
  available_mediator_datasets[["information_sharing"]] <- is_long
}
if(exists("sync_long")) {
  available_mediator_datasets[["synchronization"]] <- sync_long
}
if(exists("tc_aggregated")) {
  available_mediator_datasets[["team_composition"]] <- tc_aggregated
}
if(exists("arousal_long")) {
  available_mediator_datasets[["arousal"]] <- arousal_long
}
if(exists("valence_long")) {
  available_mediator_datasets[["valence"]] <- valence_long
}
if(exists("ind_motiv_long")) {
  available_mediator_datasets[["individual_motivation"]] <- ind_motiv_long
}
if(exists("team_motiv_aggregated")) {
  available_mediator_datasets[["team_motivation"]] <- team_motiv_aggregated
}

print("Verfügbare Mediator-Datensätze:")
print(names(available_mediator_datasets))

# Aggregiere die rundenweisen Mediatoren für die Analyse
# (wir brauchen einen Wert pro participant.code × task × comm)

mediator_aggregated_list <- list()

for(med_name in names(available_mediator_datasets)) {
  med_data <- available_mediator_datasets[[med_name]]
  
  if("round" %in% names(med_data)) {
    # Rundenweise Mediatoren: Aggregiere über Runden
    med_agg <- med_data %>%
      group_by(participant.code, task, comm) %>%
      dplyr::summarise(!!paste0(med_name, "_score") := mean(value, na.rm = TRUE), .groups = "drop")
  } else {
    # Einmalige Mediatoren: Rename value column
    med_agg <- med_data %>%
      dplyr::rename(!!paste0(med_name, "_score") := value)
  }
  
  mediator_aggregated_list[[med_name]] <- med_agg
}

# Kombiniere alle Mediatoren mit den Basis-Daten
mediator_analysis_data <- mediator_analysis_base

for(med_name in names(mediator_aggregated_list)) {
  mediator_analysis_data <- mediator_analysis_data %>%
    left_join(mediator_aggregated_list[[med_name]], by = c("participant.code", "task", "comm"))
}

# Verfügbare Mediatoren identifizieren
mediator_cols <- names(mediator_analysis_data)[grepl("_score$", names(mediator_analysis_data))]
mediator_cols <- mediator_cols[mediator_cols != "flow_score"]  # Entferne flow_score
print("Verfügbare Mediatoren (aus bereits extrahierten Datensätzen):")
print(mediator_cols)

# Prüfe Datenverteilung
print("\n--- DATENVERTEILUNG MIT MEDIATOREN ---")
data_distribution_with_mediators <- mediator_analysis_data %>%
  group_by(communication, difficulty_simple, task) %>%
  summarise(
    n_obs = n(),
    n_participants = n_distinct(participant.code),
    n_with_stress = sum(!is.na(stress_score)),
    n_with_info = sum(!is.na(information_sharing_score)),
    .groups = "drop"
  )
print(data_distribution_with_mediators)

# ================================================================================
# TEIL 3: MIXED-EFFECTS ANALYSEN
# ================================================================================

print("\n=== MIXED-EFFECTS ANALYSEN ===")

mediator_results <- list()

for(mediator in mediator_cols) {
  cat("\n", rep("=", 60), "\n", sep = "")
  mediator_name <- gsub("_score$", "", mediator)
  cat("MEDIATOR:", toupper(mediator_name), "\n")
  cat(rep("=", 60), "\n", sep = "")
  
  # Filtere Daten für aktuellen Mediator
  mediator_data <- mediator_analysis_data %>%
    filter(!is.na(!!sym(mediator)))
  
  if(nrow(mediator_data) < 20) {
    cat("Zu wenige Daten für", mediator_name, "- übersprungen\n")
    next
  }
  
  tryCatch({
    # Erst prüfen, ob genug Varianz in den Faktoren vorhanden ist
    cat("Datencheck für", mediator_name, ":\n")
    cat("- Communication levels:", paste(unique(mediator_data$communication), collapse = ", "), "\n")
    cat("- Difficulty levels:", paste(unique(mediator_data$difficulty_simple), collapse = ", "), "\n") 
    cat("- Task levels:", paste(unique(mediator_data$task), collapse = ", "), "\n")
    cat("- Anzahl Teams:", n_distinct(mediator_data$team_id), "\n")
    
    # Prüfe ob alle Faktoren mindestens 2 Stufen haben
    if(n_distinct(mediator_data$communication) < 2) {
      cat("ÜBERSPRUNGEN: Nur", n_distinct(mediator_data$communication), "Communication level(s)\n")
      next
    }
    if(n_distinct(mediator_data$difficulty_simple) < 2) {
      cat("ÜBERSPRUNGEN: Nur", n_distinct(mediator_data$difficulty_simple), "Difficulty level(s)\n")
      next
    }
    if(n_distinct(mediator_data$task) < 2) {
      cat("ÜBERSPRUNGEN: Nur", n_distinct(mediator_data$task), "Task level(s)\n") 
      next
    }
    
    # Vereinfachtes Modell wenn zu wenig Teams
    if(n_distinct(mediator_data$team_id) < 5) {
      formula_str <- paste(mediator, "~ communication * difficulty_simple * task + (1|participant.code)")
    } else {
      formula_str <- paste(mediator, "~ communication * difficulty_simple * task + (1|participant.code) + (1|team_id)")
    }
    
    cat("Verwende Formel:", formula_str, "\n")
    model_full <- lmer(as.formula(formula_str), data = mediator_data)
    
    cat("\n--- MODELL ZUSAMMENFASSUNG ---\n")
    print(summary(model_full))
    
    # ANOVA
    cat("\n--- ANOVA ERGEBNISSE ---\n")
    anova_result <- anova(model_full)
    print(anova_result)
    
    # Post-Hoc Tests: Communication|Difficulty
    cat("\n--- POST-HOC: Communication × Difficulty ---\n")
    emmeans_comm_diff <- emmeans(model_full, pairwise ~ communication | difficulty_simple)
    posthoc_comm_diff <- as.data.frame(emmeans_comm_diff$contrasts)
    print(posthoc_comm_diff)
    
    # Marginal Means
    cat("\n--- MARGINAL MEANS ---\n")
    marginal_means <- as.data.frame(emmeans(model_full, ~ communication * difficulty_simple * task))
    print(marginal_means)
    
    # Speichere Ergebnisse
    mediator_results[[mediator]] <- list(
      model = model_full,
      anova = anova_result,
      posthoc_comm_diff = posthoc_comm_diff,
      marginal_means = marginal_means
    )
    
  }, error = function(e) {
    cat("Fehler bei", mediator_name, ":", e$message, "\n")
    
    # Noch einfacheres Fallback-Modell
    cat("Versuche einfacheres Modell...\n")
    tryCatch({
      simple_formula <- paste(mediator, "~ communication + difficulty_simple + task + (1|participant.code)")
      simple_model <- lmer(as.formula(simple_formula), data = mediator_data)
      
      cat("Einfaches Modell erfolgreich:\n")
      print(summary(simple_model))
      
      mediator_results[[mediator]] <- list(
        model = simple_model,
        note = "Vereinfachtes Modell ohne Interaktionen"
      )
      
    }, error = function(e2) {
      cat("Auch einfaches Modell fehlgeschlagen:", e2$message, "\n")
    })
  })
}

# ================================================================================
# TEIL 4: ZUSAMMENFASSUNG SIGNIFIKANTER UNTERSCHIEDE
# ================================================================================

print("\n\n=== ZUSAMMENFASSUNG SIGNIFIKANTER UNTERSCHIEDE ===")

significant_differences <- data.frame()

for(mediator in names(mediator_results)) {
  result <- mediator_results[[mediator]]
  
  if(!is.null(result$posthoc_comm_diff)) {
    sig_tests <- result$posthoc_comm_diff %>%
      filter(p.value < 0.05) %>%
      mutate(
        mediator = gsub("_score$", "", mediator),
        effect_direction = ifelse(estimate > 0, "Jitsi > Chat", "Chat > Jitsi"),
        effect_size = abs(estimate)
      )
    
    if(nrow(sig_tests) > 0) {
      significant_differences <- bind_rows(significant_differences, sig_tests)
    }
  }
}

if(nrow(significant_differences) > 0) {
  print("SIGNIFIKANTE CHAT vs JITSI UNTERSCHIEDE:")
  significant_summary <- significant_differences %>% 
    select(mediator, difficulty_simple, effect_direction, estimate, p.value) %>%
    arrange(difficulty_simple, p.value)
  print(significant_summary)
} else {
  print("Keine signifikanten Unterschiede zwischen Chat und Jitsi gefunden.")
}

# ================================================================================
# TEIL 5: SPEZIFISCHE EASY vs HARD ANALYSEN
# ================================================================================

print("\n=== SPEZIFISCHE ANALYSEN: EASY vs HARD ===")

for(difficulty_level in c("Easy", "Hard")) {
  cat("\n", rep("=", 50), "\n", sep = "")
  cat("DIFFICULTY LEVEL:", difficulty_level, "\n")
  cat(rep("=", 50), "\n")
  
  difficulty_data <- mediator_analysis_data %>%
    filter(difficulty_simple == difficulty_level)
  
  print(paste("Daten für", difficulty_level, ":", nrow(difficulty_data), "Beobachtungen"))
  
  for(mediator in mediator_cols) {
    mediator_name <- gsub("_score$", "", mediator)
    
    analysis_data <- difficulty_data %>%
      filter(!is.na(!!sym(mediator)))
    
    if(nrow(analysis_data) < 10) next
    
    tryCatch({
      model <- lmer(as.formula(paste(mediator, "~ communication + task + (1|participant.code) + (1|team_id)")), 
                   data = analysis_data)
      
      model_summary <- summary(model)
      communication_effect <- model_summary$coefficients["communicationJitsi", ]
      
      if(communication_effect["Pr(>|t|)"] < 0.05) {
        cat("\n*** SIGNIFIKANT:", mediator_name, "in", difficulty_level, "***\n")
        cat("Jitsi vs Chat Effekt:", round(communication_effect["Estimate"], 3), 
            ", p =", round(communication_effect["Pr(>|t|)"], 4), "\n")
        
        direction <- ifelse(communication_effect["Estimate"] > 0, "Jitsi > Chat", "Chat > Jitsi")
        cat("Richtung:", direction, "\n")
        
        # Mittelwerte
        means_data <- analysis_data %>%
          group_by(communication) %>%
          summarise(mean_value = mean(!!sym(mediator), na.rm = TRUE), .groups = "drop")
        
        cat("Mittelwerte: Chat =", round(means_data$mean_value[means_data$communication == "Chat"], 3),
            ", Jitsi =", round(means_data$mean_value[means_data$communication == "Jitsi"], 3), "\n")
      }
      
    }, error = function(e) {
      # Stumm weitermachen
    })
  }
}

# ================================================================================
# TEIL 6: VISUALISIERUNGEN
# ================================================================================

print("\n=== VISUALISIERUNGEN ===")

for(mediator in names(mediator_results)) {
  result <- mediator_results[[mediator]]
  
  if(!is.null(result$marginal_means)) {
    mediator_name <- gsub("_score$", "", mediator)
    
    plot_data <- result$marginal_means %>%
      mutate(communication = factor(communication, levels = c("Chat", "Jitsi")))
    
    p <- ggplot(plot_data, aes(x = difficulty_simple, y = emmean, 
                              color = communication, group = communication)) +
      geom_line(size = 1.2, alpha = 0.8, position = position_dodge(width = 0.1)) +
      geom_point(size = 3, position = position_dodge(width = 0.1)) +
      geom_errorbar(aes(ymin = emmean - SE, ymax = emmean + SE), 
                    width = 0.1, alpha = 0.7, position = position_dodge(width = 0.1)) +
      facet_wrap(~ task) +
      scale_color_manual(values = c("Chat" = "#E31A1C", "Jitsi" = "#1F78B4")) +
      labs(
        title = paste("Mediator:", str_to_title(gsub("_", " ", mediator_name))),
        subtitle = "Communication × Difficulty by Task",
        x = "Difficulty Level",
        y = paste("Estimated", str_to_title(gsub("_", " ", mediator_name))),
        color = "Communication"
      ) +
      theme_minimal() +
      theme(
        plot.title = element_text(size = 14, face = "bold"),
        axis.title = element_text(size = 12),
        strip.text = element_text(size = 12, face = "bold")
      )
    
    print(p)
    assign(paste0("p_", gsub("_", "", mediator_name)), p, envir = .GlobalEnv)
  }
}

# ================================================================================
# TEIL 7: INTERPRETATION FÜR SHARED FLOW PARADOX
# ================================================================================

print("\n=== INTERPRETATION FÜR SHARED FLOW PARADOX ===")

cat("\nSHARED FLOW BEFUND:\n")
cat("- Chat: Flow sinkt mit zunehmender Schwierigkeit\n")
cat("- Jitsi: Flow steigt mit zunehmender Schwierigkeit\n\n")

if(nrow(significant_differences) > 0) {
  easy_effects <- significant_differences %>% filter(difficulty_simple == "Easy")
  hard_effects <- significant_differences %>% filter(difficulty_simple == "Hard")
  
  if(nrow(easy_effects) > 0) {
    cat("Bei LEICHTEN Aufgaben:\n")
    for(i in 1:nrow(easy_effects)) {
      cat("- ", easy_effects$mediator[i], ": ", easy_effects$effect_direction[i], 
          " (p = ", round(easy_effects$p.value[i], 3), ")\n", sep = "")
    }
  }
  
  if(nrow(hard_effects) > 0) {
    cat("\nBei SCHWEREN Aufgaben:\n")
    for(i in 1:nrow(hard_effects)) {
      cat("- ", hard_effects$mediator[i], ": ", hard_effects$effect_direction[i], 
          " (p = ", round(hard_effects$p.value[i], 3), ")\n", sep = "")
    }
  }
  
  # Identifiziere sich ändernde Muster
  pattern_changes <- significant_differences %>%
    select(mediator, difficulty_simple, effect_direction) %>%
    pivot_wider(names_from = difficulty_simple, values_from = effect_direction) %>%
    filter(!is.na(Easy) & !is.na(Hard) & Easy != Hard)
  
  if(nrow(pattern_changes) > 0) {
    cat("\nMEDIATOREN MIT SICH ÄNDERNDEN MUSTERN:\n")
    for(i in 1:nrow(pattern_changes)) {
      cat("- ", pattern_changes$mediator[i], ": Easy (", pattern_changes$Easy[i], 
          ") vs Hard (", pattern_changes$Hard[i], ")\n", sep = "")
    }
    cat("\n*** DIESE KÖNNTEN DAS SHARED FLOW PARADOX ERKLÄREN! ***\n")
  }
  
} else {
  cat("Keine signifikanten Mediator-Unterschiede gefunden.\n")
}

print("\n=== ANALYSEN ABGESCHLOSSEN ===")
```


Mediation analysis in comparison with data from experiment 1

```{r}
# Erweiterte Mediationsanalyse: Integration alter und neuer Datensätze
# Vergleich von SP, MP (ohne Kommunikation), MP+Chat und MP+Jitsi

library(dplyr)
library(tidyr)
library(lme4)
library(lmerTest)
library(rmcorr)
library(ggplot2)
library(psych)

# ================================================================================
# TEIL 1: ALTE DATEN KORREKT AUFBEREITEN
# ================================================================================

print("--- KORRIGIERE ALTE DATEN ---")

# 1.1 Mapping von Order-Strings zu Difficulties (vereinfacht)
create_difficulty_mapping <- function(order_string) {
  # Teile Order-String auf
  order_parts <- strsplit(order_string, "-")[[1]]
  
  # Prüfe ob genau 4 Parts vorhanden sind (vollständiges Experiment)
  if(length(order_parts) != 4) {
    return(NULL)  # Unvollständige Daten
  }
  
  # Mapping: Position im String -> Difficulty
  difficulty_map <- data.frame(
    round = 1:length(order_parts),
    difficulty_code = order_parts,
    stringsAsFactors = FALSE
  ) %>%
    mutate(
      difficulty = case_when(
        difficulty_code == "BOREDOM" ~ "Easy",
        difficulty_code == "AUTONOMY" ~ "Optimal_Selected", 
        difficulty_code == "FLOW" ~ "Optimal_Calibrated",
        difficulty_code == "OVERLOAD" ~ "Hard",
        TRUE ~ NA_character_
      )
    )
  
  return(difficulty_map)
}

# 1.2 Erweiterte Aufbereitung + Filter in einem Schritt
old_rounds_corrected <- data_old_rounds %>%
  mutate(
    participant.code = SubjectID,
    team_id = SessionID,
    comm = case_when(
      Treatment == "MP" ~ "Together_None",
      Treatment == "SP" ~ "Alone",
      TRUE ~ NA_character_
    ),
    task = "Math",
    order = as.character(ConditionOrder),
    condition_num = as.numeric(sub("_.*", "", Condition)),
    difficulty = case_when(
      condition_num == 1 ~ "Easy",
      condition_num == 2 ~ "Optimal_Calibrated",
      condition_num == 3 ~ "Optimal_Selected",
      condition_num == 4 ~ "Hard",
      TRUE ~ NA_character_
    ),
    flow_score = flowFKS_9,
    stress_value = stress,
    individual_motivation_value = motivation,
    valence_value = valence,
    arousal_value = arousal,
    information_sharing_value = infSharing,
    synchronization_value = teamSynch
  ) %>%
  select(-condition_num) %>%
  filter(
    !is.na(order) & order != "" &
    lengths(strsplit(order, "-")) == 4
  )

# 1.3 Berechne Round-Nummer basierend auf Order und Condition (vereinfacht)
old_rounds_with_rounds <- old_rounds_corrected %>%
  group_by(participant.code) %>%
  do({
    participant_data <- .
    order_string <- unique(participant_data$order)[1]
    
    difficulty_mapping <- create_difficulty_mapping(order_string)
    
    if(!is.null(difficulty_mapping)) {
      # Verbinde mit Difficulty-Mapping
      participant_data %>%
        left_join(difficulty_mapping, by = "difficulty") %>%
        select(-difficulty_code)  # Entferne temporäre Spalte
    } else {
      # Sollte nicht passieren da wir bereits gefiltert haben
      participant_data %>% mutate(round = NA)
    }
  }) %>%
  ungroup()

print(paste("Alte Daten korrekt aufbereitet:", nrow(old_rounds_with_rounds), "Beobachtungen"))

# 1.4 Korrigierte Team Composition/Motivation + TEAM-FAKTOREN Integration (UNVERÄNDERT)
old_final_corrected <- data_old_final %>%
  filter(Condition == "PHASE") %>%
  transmute(
    participant.code = SubjectID,
    team_id = SessionID,
    # comm behalten wir, aber nicht für den Join verwenden (vermeidet .x/.y-Probleme)
    comm = case_when(
      Treatment == "MP" ~ "Together_None",
      Treatment == "SP" ~ "Alone",
      TRUE ~ NA_character_
    ),
    task = "Math",
    # Direkte Ableitung aus vorhandenen Spalten
    team_motivation_value = as.numeric(grpEffort),
    team_size_score = rowMeans(cbind(
      8 - grpSizeTooLarge,
      8 - grpSizeTooSmall,
      grpSizeJustRight
    ), na.rm = TRUE),
    team_composition_value = rowMeans(cbind(
      # team_size_score ist eine temporäre Spalte in transmute, wir müssen sie wieder berechnen:
      rowMeans(cbind(8 - grpSizeTooLarge, 8 - grpSizeTooSmall, grpSizeJustRight), na.rm = TRUE),
      grpDivers,
      grpSkill
    ), na.rm = TRUE),
    
    # ============================================================================
    # NEU: Team-Faktoren aus den verfügbaren Variablen
    # ============================================================================
    # Interdependence: 3 Items (int1 umgepolt basierend auf der Alpha-Analyse)
    interdependence_value = interdepMutualDependenc,
    
    # Common Goal: 5 Items verfügbar (cg1, cg3, cg5 umgepolt basierend auf der Alpha-Analyse)
    common_goal_value = rowMeans(cbind(
      clearGoal,      # Item 2 (entspricht cg2)
      challGoal,          # Item 3 (entspricht cg3)
      8 - noChallGoal,    # Item 4 umgepolt (entspricht cg4)
      8- noConseqGoal,       # Item 5 umgepolt (entspricht cg5)
      conseqGoal      # Item 6(entspricht cg6)
      # Item 1 (cg1) ist nicht verfügbar in alten Daten
    ), na.rm = TRUE),
    
    # Means for Coordination: 2 Items (mc1 umgepolt basierend auf der Alpha-Analyse)
    means_coordination_value = rowMeans(cbind(
      8 - coordDifficult,  # Item 1 umgepolt (entspricht mc1)
      coordPossible        # Item 2 (entspricht mc2)
    ), na.rm = TRUE),
    
    # ============================================================================
    # ERWEITERTE TEAM-FAKTOREN für detaillierte Analyse
    # ============================================================================
    
    # Group Size (aus den drei vorhandenen Items - bereits richtig gepolt)
    group_size_value = rowMeans(cbind(
      8 - grpSizeTooLarge,   # Item 1: "Gruppe ist nicht zu groß" 
      8 - grpSizeTooSmall,   # Item 2: "Gruppe ist nicht zu klein"
      grpSizeJustRight       # Item 3: "Gruppengröße ist genau richtig"
    ), na.rm = TRUE),
    
    # Group Diversity (direkt verfügbar, nur ein Item)
    group_diversity_value = grpDivers,
    
    # Group Skill (direkt verfügbar, nur ein Item) 
    group_skill_value = grpSkill,
    
    # Communication Required (direkt verfügbar - entspricht int2)
    communication_required_value = interdepCommRequired,
    
    # Work Independence (sirekt verfügbar - entspricht int1)
    work_independence_value = interdepOwnJob,
    
    # Social Presence (direkt verfügbar)
    social_presence_value = socPres,
    
    # Perceived Task Complexity (nicht verfügbar in alten Daten)
    perceived_task_complexity_value = NA_real_
  ) %>%
  select(participant.code, team_id, comm, task, team_composition_value, team_motivation_value,
         interdependence_value, common_goal_value, means_coordination_value,
         # Erweiterte Team-Faktoren
         group_size_value, group_diversity_value, group_skill_value,
         communication_required_value, work_independence_value, social_presence_value, perceived_task_complexity_value)

# Funktion zur Vereinheitlichung der participant.code Strings
normalize_participant_code <- function(pc) {
  pc %>%
    tolower() %>%
    gsub("-", "_", .) %>%
    gsub("_+", "_", .) %>%
    gsub("^_|_$", "", .) %>%
    # jetzt umstellen: falls "_mp_" oder "_sp_" in der Mitte, verschiebe ans Ende
    gsub("^(session_\\d+)_(mp|sp)_(.+)$", "\\1_\\3_\\2", .)
}

normalize_team_id <- function(tid) {
  tid %>%
    tolower() %>%
    gsub("session_(\\d+)[a-z]", "session_\\1", .) %>%  # Entfernt Buchstaben hinter Zahl in session_65b
    gsub("-", "_", .) %>%
    gsub("_na$", "", .) %>%
    gsub("_+", "_", .) %>%
    gsub("^_|_$", "", .)
}

# Alte Runden-Daten normalisieren
old_rounds_with_rounds <- old_rounds_with_rounds %>%
  mutate(
    participant.code = normalize_participant_code(participant.code),
    team_id = normalize_team_id(team_id)
  )

# Alte Team-Daten normalisieren
old_final_corrected <- old_final_corrected %>%
  mutate(
    participant.code = normalize_participant_code(participant.code),
    session_num = sub("^(session_\\d+)_.*", "\\1", participant.code),
    treatment = sub(".*_(mp|sp)$", "\\1", participant.code),
    treatment = ifelse(treatment %in% c("mp", "sp"), treatment, NA_character_),
    team_id = paste0(session_num, "_", treatment)
  ) %>%
  dplyr::select(-session_num, -treatment)

# ============================================================================
# NEU: POST-RUNDEN STRUKTUR FÜR ALTE DATEN
# ============================================================================

# Normale Runden (nur rundenweise Mediatoren)
old_rounds_normal <- old_rounds_with_rounds %>%
  select(participant.code, team_id, comm, task, difficulty, order, round,
         flow_score, stress_value, individual_motivation_value, 
         valence_value, arousal_value, information_sharing_value, 
         synchronization_value) %>%
  # Setze Team-Faktoren auf NA für normale Runden
  mutate(
    team_composition_value = NA_real_,
    team_motivation_value = NA_real_,
    interdependence_value = NA_real_,
    common_goal_value = NA_real_,
    means_coordination_value = NA_real_,
    # Erweiterte Team-Faktoren auch auf NA
    group_size_value = NA_real_,
    group_diversity_value = NA_real_,
    group_skill_value = NA_real_,
    communication_required_value = NA_real_,
    work_independence_value = NA_real_,
    social_presence_value = NA_real_,
    perceived_task_complexity_value = NA_real_
  )

# Post-Runden (nur Team-Faktoren)
old_rounds_post <- old_rounds_with_rounds %>%
  distinct(participant.code, team_id, comm, task, order) %>%
  left_join(old_final_corrected %>% select(-comm), 
            by = c("participant.code", "team_id", "task")) %>%
  mutate(
    round = "Post",
    difficulty = "Post",
    # Rundenweise Mediatoren auf NA
    flow_score = NA_real_,
    stress_value = NA_real_,
    individual_motivation_value = NA_real_,
    valence_value = NA_real_,
    arousal_value = NA_real_,
    information_sharing_value = NA_real_,
    synchronization_value = NA_real_
  ) %>%
  select(participant.code, team_id, comm, task, difficulty, order, round,
         flow_score, stress_value, individual_motivation_value, 
         valence_value, arousal_value, information_sharing_value, 
         synchronization_value, team_composition_value, team_motivation_value,
         interdependence_value, common_goal_value, means_coordination_value,
         # Erweiterte Team-Faktoren
         group_size_value, group_diversity_value, group_skill_value,
         communication_required_value, work_independence_value, social_presence_value, perceived_task_complexity_value)

# Kombiniere alte normale + Post-Runden (Typ-Anpassung)
old_rounds_final <- bind_rows(
  old_rounds_normal %>% mutate(round = as.character(round)),
  old_rounds_post
)

message("Rows in old_rounds_final (mit Post-Runden):", nrow(old_rounds_final))

# Quick-check wie viele NAs in den Team-Variablen:
message("NAs in team_composition_value after join: ", sum(is.na(old_rounds_final$team_composition_value)))
message("NAs in team_motivation_value after join: ", sum(is.na(old_rounds_final$team_motivation_value)))
message("NAs in interdependence_value after join: ", sum(is.na(old_rounds_final$interdependence_value)))
message("NAs in common_goal_value after join: ", sum(is.na(old_rounds_final$common_goal_value)))
message("NAs in means_coordination_value after join: ", sum(is.na(old_rounds_final$means_coordination_value)))

# ================================================================================
# FÜR NEUE DATEN: Team-Faktoren mit korrekter Umpolung + POST-RUNDEN
# ================================================================================

# 2.1 Prüfe verfügbare Difficulties in flow_clean
print("Verfügbare Difficulties in flow_clean:")
difficulty_check <- flow_clean %>%
  filter(comm %in% c("Chat", "Jitsi")) %>%
  group_by(difficulty, task) %>%
  dplyr::summarise(n = n(), .groups = "drop")
print(difficulty_check)

# 2.2 Erstelle Order-Strings für neue Daten
create_order_string_new <- function(participant_data) {
  # Sortiere nach einer eindeutigen Reihenfolge (z.B. basierend auf Row-Number im originalen Datensatz)
  ordered_data <- participant_data %>%
    arrange(participant.code, task, comm) %>%
    group_by(participant.code, task, comm) %>%
    mutate(round = row_number()) %>%
    ungroup()
  
  # Erstelle Order-String
  order_summary <- ordered_data %>%
    group_by(participant.code, task, comm) %>%
    dplyr::summarise(
      order = paste0("['", paste(difficulty, collapse = "', '"), "']"),
      .groups = "drop"
    )
  
  return(list(data_with_rounds = ordered_data, order_summary = order_summary))
}

# 2.3 Wende auf neue Daten an
new_data_processing <- flow_clean %>%
  filter(comm %in% c("Chat", "Jitsi")) %>%
  group_by(participant.code, task, comm) %>%
  group_split() %>%
  map_dfr(~{
    group_data <- .x
    
    # Füge Round-Nummern hinzu
    group_data %>%
      arrange(participant.code, task, comm) %>%
      mutate(round = row_number())
  })

# 2.4 Erstelle Order-Zusammenfassung
order_summary_new <- new_data_processing %>%
  group_by(participant.code, task, comm) %>%
  dplyr::summarise(
    order = paste0("['", paste(difficulty, collapse = "', '"), "']"),
    .groups = "drop"
  )

# 2.5 Extrahiere Mediatoren für neue Daten (korrigiert)
print("Extrahiere Mediatoren für neue Daten...")

# Funktion für Math + HP Mediator-Extraktion
extract_mediators_new <- function(data, var_pattern, var_name, last_round_only = FALSE) {
  if(last_round_only) {
    # Für einmalige Mediatoren: letzte Runde pro Task
    patterns <- c(
      paste0("mathJitsi\\.6\\.player\\.", var_pattern, "$"),
      paste0("mathChat\\.6\\.player\\.", var_pattern, "$"),
      paste0("HiddenProfile_Jitsi\\.3\\.player\\.", var_pattern, "$"),
      paste0("HiddenProfile_Chat\\.3\\.player\\.", var_pattern, "$")
    )
  } else {
    # Für rundenweise Mediatoren: alle relevanten Runden
    patterns <- c(
      paste0("(mathJitsi|mathChat)\\.[3-6]\\.player\\.", var_pattern, "$"),
      paste0("(HiddenProfile_Jitsi|HiddenProfile_Chat)\\.[1-3]\\.player\\.", var_pattern, "$")
    )
  }
  
  combined_pattern <- paste(patterns, collapse = "|")
  
  med_data <- data %>%
    dplyr::select(participant.code, matches(combined_pattern)) %>%
    pivot_longer(cols = -participant.code, names_to = "variable", values_to = "value") %>%
    filter(!is.na(value)) %>%
    mutate(
      task = case_when(
        grepl("^math", variable) ~ "Math",
        grepl("^HiddenProfile", variable) ~ "HP"
      ),
      comm = case_when(
        grepl("Jitsi", variable) ~ "Jitsi",
        grepl("Chat", variable) ~ "Chat"
      ),
      round_raw = as.numeric(gsub(".*\\.(\\d+)\\.player.*", "\\1", variable))
    )
  
  if(!last_round_only) {
    # Für rundenweise: berechne standardisierte Round-Nummer
    med_data <- med_data %>%
      mutate(
        round = case_when(
          task == "Math" ~ round_raw - 2,  # Math: 3-6 -> 1-4
          task == "HP" ~ round_raw         # HP: 1-3 -> 1-3
        )
      ) %>%
      filter((task == "Math" & round_raw >= 3 & round_raw <= 6) |
             (task == "HP" & round_raw >= 1 & round_raw <= 3))
  }
  
  # Aggregiere Items falls mehrere vorhanden
  if(last_round_only) {
    result <- med_data %>%
      group_by(participant.code, task, comm) %>%
      summarise(!!paste0(var_name, "_value") := mean(value, na.rm = TRUE), .groups = "drop")
  } else {
    result <- med_data %>%
      group_by(participant.code, task, comm, round) %>%
      summarise(!!paste0(var_name, "_value") := mean(value, na.rm = TRUE), .groups = "drop")
  }
  
  return(result)
}

# Extrahiere alle Mediatoren
stress_new <- extract_mediators_new(data, "is[1-5]", "stress")
info_sharing_new <- extract_mediators_new(data, "info[1-2]", "information_sharing") 
sync_new <- extract_mediators_new(data, "ec1", "synchronization")
arousal_new <- extract_mediators_new(data, "arousal", "arousal")
valence_new <- extract_mediators_new(data, "pleasure", "valence")
motivation_new <- extract_mediators_new(data, "tm[1-3]", "individual_motivation")

# Einmalige Mediatoren
team_comp_new <- extract_mediators_new(data, "(tsz[1-3]|td[1-3]|tsc[1-3])", "team_composition", last_round_only = TRUE)
team_motiv_new <- extract_mediators_new(data, "te[1-3]", "team_motivation", last_round_only = TRUE)

# Team-Faktoren mit korrekter Umpolung
# Interdependence: Item 1 umpolung
interdependence_new <- data %>%
  dplyr::select(participant.code, matches("(mathJitsi|mathChat)\\.6\\.player\\.int[3]$|HiddenProfile_(Jitsi|Chat)\\.3\\.player\\.int[3]$")) %>%
  pivot_longer(cols = -participant.code, names_to = "variable", values_to = "value") %>%
  filter(!is.na(value)) %>%
  mutate(
    task = case_when(
      grepl("^math", variable) ~ "Math",
      grepl("^HiddenProfile", variable) ~ "HP"
    ),
    comm = case_when(
      grepl("Jitsi", variable) ~ "Jitsi",
      grepl("Chat", variable) ~ "Chat"
    ),
    item = gsub(".*\\.(int\\d+)$", "\\1", variable),
    # Umpolung für int1
    value_corrected = ifelse(item == "int1", 8 - value, value)
  ) %>%
  group_by(participant.code, task, comm) %>%
  summarise(interdependence_value = mean(value_corrected, na.rm = TRUE), .groups = "drop")

# Common Goal: Items 1, 3, 5 Umpolung  
common_goal_new <- data %>%
  dplyr::select(participant.code, matches("(mathJitsi|mathChat)\\.6\\.player\\.cg[1-6]$|HiddenProfile_(Jitsi|Chat)\\.3\\.player\\.cg[1-6]$")) %>%
  pivot_longer(cols = -participant.code, names_to = "variable", values_to = "value") %>%
  filter(!is.na(value)) %>%
  mutate(
    task = case_when(
      grepl("^math", variable) ~ "Math",
      grepl("^HiddenProfile", variable) ~ "HP"
    ),
    comm = case_when(
      grepl("Jitsi", variable) ~ "Jitsi",
      grepl("Chat", variable) ~ "Chat"
    ),
    item = gsub(".*\\.(cg\\d+)$", "\\1", variable),
    # Umpolung für cg1, cg3, cg5
    value_corrected = ifelse(item %in% c("cg1", "cg3", "cg5"), 8 - value, value)
  ) %>%
  group_by(participant.code, task, comm) %>%
  summarise(common_goal_value = mean(value_corrected, na.rm = TRUE), .groups = "drop")

# Means Coordination: Item 1 Umpolung
means_coordination_new <- data %>%
  dplyr::select(participant.code, matches("(mathJitsi|mathChat)\\.6\\.player\\.mc[1-2]$|HiddenProfile_(Jitsi|Chat)\\.3\\.player\\.mc[1-2]$")) %>%
  pivot_longer(cols = -participant.code, names_to = "variable", values_to = "value") %>%
  filter(!is.na(value)) %>%
  mutate(
    task = case_when(
      grepl("^math", variable) ~ "Math",
      grepl("^HiddenProfile", variable) ~ "HP"
    ),
    comm = case_when(
      grepl("Jitsi", variable) ~ "Jitsi",
      grepl("Chat", variable) ~ "Chat"
    ),
    item = gsub(".*\\.(mc\\d+)$", "\\1", variable),
    # Umpolung für mc1
    value_corrected = ifelse(item == "mc1", 8 - value, value)
  ) %>%
  group_by(participant.code, task, comm) %>%
  summarise(means_coordination_value = mean(value_corrected, na.rm = TRUE), .groups = "drop")

# ================================================================================
# ERWEITERTE TEAM-FAKTOREN FÜR NEUE DATEN
# ================================================================================

print("Extrahiere erweiterte Team-Faktoren für neue Daten...")

# Group Size: 3 Items (tsz1-3)
group_size_new <- data %>%
  dplyr::select(participant.code, matches("(mathJitsi|mathChat)\\.6\\.player\\.tsz[1-3]$|HiddenProfile_(Jitsi|Chat)\\.3\\.player\\.tsz[1-3]$")) %>%
  pivot_longer(cols = -participant.code, names_to = "variable", values_to = "value") %>%
  filter(!is.na(value)) %>%
  mutate(
    task = case_when(
      grepl("^math", variable) ~ "Math",
      grepl("^HiddenProfile", variable) ~ "HP"
    ),
    comm = case_when(
      grepl("Jitsi", variable) ~ "Jitsi",
      grepl("Chat", variable) ~ "Chat"
    ),
    item = gsub(".*\\.(tsz\\d+)$", "\\1", variable)
    # Keine Umpolung nötig für tsz Items
  ) %>%
  group_by(participant.code, task, comm) %>%
  summarise(group_size_value = mean(value, na.rm = TRUE), .groups = "drop")

# Group Diversity: 3 Items (td1-3)
group_diversity_new <- data %>%
  dplyr::select(participant.code, matches("(mathJitsi|mathChat)\\.6\\.player\\.td[1-3]$|HiddenProfile_(Jitsi|Chat)\\.3\\.player\\.td[1-3]$")) %>%
  pivot_longer(cols = -participant.code, names_to = "variable", values_to = "value") %>%
  filter(!is.na(value)) %>%
  mutate(
    task = case_when(
      grepl("^math", variable) ~ "Math",
      grepl("^HiddenProfile", variable) ~ "HP"
    ),
    comm = case_when(
      grepl("Jitsi", variable) ~ "Jitsi",
      grepl("Chat", variable) ~ "Chat"
    ),
    item = gsub(".*\\.(td\\d+)$", "\\1", variable)
    # Keine Umpolung nötig für td Items
  ) %>%
  group_by(participant.code, task, comm) %>%
  summarise(group_diversity_value = mean(value, na.rm = TRUE), .groups = "drop")

# Group Skill: 3 Items (tsc1-3)
group_skill_new <- data %>%
  dplyr::select(participant.code, matches("(mathJitsi|mathChat)\\.6\\.player\\.tsc[1-3]$|HiddenProfile_(Jitsi|Chat)\\.3\\.player\\.tsc[1-3]$")) %>%
  pivot_longer(cols = -participant.code, names_to = "variable", values_to = "value") %>%
  filter(!is.na(value)) %>%
  mutate(
    task = case_when(
      grepl("^math", variable) ~ "Math",
      grepl("^HiddenProfile", variable) ~ "HP"
    ),
    comm = case_when(
      grepl("Jitsi", variable) ~ "Jitsi",
      grepl("Chat", variable) ~ "Chat"
    ),
    item = gsub(".*\\.(tsc\\d+)$", "\\1", variable)
    # Keine Umpolung nötig für tsc Items
  ) %>%
  group_by(participant.code, task, comm) %>%
  summarise(group_skill_value = mean(value, na.rm = TRUE), .groups = "drop")

# Communication Required: Einzelnes Item (int2)
communication_required_new <- data %>%
  dplyr::select(participant.code, matches("(mathJitsi|mathChat)\\.6\\.player\\.int2$|HiddenProfile_(Jitsi|Chat)\\.3\\.player\\.int2$")) %>%
  pivot_longer(cols = -participant.code, names_to = "variable", values_to = "value") %>%
  filter(!is.na(value)) %>%
  mutate(
    task = case_when(
      grepl("^math", variable) ~ "Math",
      grepl("^HiddenProfile", variable) ~ "HP"
    ),
    comm = case_when(
      grepl("Jitsi", variable) ~ "Jitsi",
      grepl("Chat", variable) ~ "Chat"
    )
    # Keine Umpolung nötig für int2
  ) %>%
  group_by(participant.code, task, comm) %>%
  summarise(communication_required_value = mean(value, na.rm = TRUE), .groups = "drop")

# Work Independence: Einzelnes Item (int1)
work_independence_new <- data %>%
  dplyr::select(participant.code, matches("(mathJitsi|mathChat)\\.6\\.player\\.int1$|HiddenProfile_(Jitsi|Chat)\\.3\\.player\\.int1$")) %>%
  pivot_longer(cols = -participant.code, names_to = "variable", values_to = "value") %>%
  filter(!is.na(value)) %>%
  mutate(
    task = case_when(
      grepl("^math", variable) ~ "Math",
      grepl("^HiddenProfile", variable) ~ "HP"
    ),
    comm = case_when(
      grepl("Jitsi", variable) ~ "Jitsi",
      grepl("Chat", variable) ~ "Chat"
    )
    # Keine Umpolung nötig für int1
  ) %>%
  group_by(participant.code, task, comm) %>%
  summarise(work_independence_value = mean(value, na.rm = TRUE), .groups = "drop")

# Social Presence: 5 Items (psp1-5)
social_presence_new <- data %>%
  dplyr::select(participant.code, matches("(mathJitsi|mathChat)\\.6\\.player\\.psp[1-5]$|HiddenProfile_(Jitsi|Chat)\\.3\\.player\\.psp[1-5]$")) %>%
  pivot_longer(cols = -participant.code, names_to = "variable", values_to = "value") %>%
  filter(!is.na(value)) %>%
  mutate(
    task = case_when(
      grepl("^math", variable) ~ "Math",
      grepl("^HiddenProfile", variable) ~ "HP"
    ),
    comm = case_when(
      grepl("Jitsi", variable) ~ "Jitsi",
      grepl("Chat", variable) ~ "Chat"
    ),
    item = gsub(".*\\.(psp\\d+)$", "\\1", variable)
    # Keine Umpolung nötig für psp Items (außer explizit angegeben)
  ) %>%
  group_by(participant.code, task, comm) %>%
  summarise(social_presence_value = mean(value, na.rm = TRUE), .groups = "drop")

# Perceived Task Complexity: 4 Items (ptc1-4)
perceived_task_complexity_new <- data %>%
  dplyr::select(participant.code, matches("(mathJitsi|mathChat)\\.6\\.player\\.ptc[1-4]$|HiddenProfile_(Jitsi|Chat)\\.3\\.player\\.ptc[1-4]$")) %>%
  pivot_longer(cols = -participant.code, names_to = "variable", values_to = "value") %>%
  filter(!is.na(value)) %>%
  mutate(
    task = case_when(
      grepl("^math", variable) ~ "Math",
      grepl("^HiddenProfile", variable) ~ "HP"
    ),
    comm = case_when(
      grepl("Jitsi", variable) ~ "Jitsi",
      grepl("Chat", variable) ~ "Chat"
    ),
    item = gsub(".*\\.(ptc\\d+)$", "\\1", variable)
    # Keine Umpolung nötig für ptc Items (außer explizit angegeben)
  ) %>%
  group_by(participant.code, task, comm) %>%
  summarise(perceived_task_complexity_value = mean(value, na.rm = TRUE), .groups = "drop")

# ============================================================================
# NEU: POST-RUNDEN STRUKTUR FÜR NEUE DATEN
# ============================================================================

new_data_processing <- new_data_processing %>% select(-order)
joined_test <- new_data_processing %>%
  left_join(order_summary_new, by = c("participant.code", "task", "comm"))

# Normale Runden (nur rundenweise Mediatoren)
new_rounds_normal <- new_data_processing %>%
  left_join(order_summary_new, by = c("participant.code", "task", "comm")) %>%
  left_join(stress_new, by = c("participant.code", "task", "comm", "round")) %>%
  left_join(info_sharing_new, by = c("participant.code", "task", "comm", "round")) %>%
  left_join(sync_new, by = c("participant.code", "task", "comm", "round")) %>%
  left_join(arousal_new, by = c("participant.code", "task", "comm", "round")) %>%
  left_join(valence_new, by = c("participant.code", "task", "comm", "round")) %>%
  left_join(motivation_new, by = c("participant.code", "task", "comm", "round")) %>%
  mutate(
    comm = case_when(
      comm == "Jitsi" ~ "Together_Jitsi",
      comm == "Chat" ~ "Together_Chat",
      TRUE ~ comm
    )
  ) %>%
  select(participant.code, team_id, comm, task, difficulty, round, order,
         flow_score, stress_value, individual_motivation_value, 
         valence_value, arousal_value, information_sharing_value, 
         synchronization_value) %>%
  # Setze Team-Faktoren auf NA für normale Runden
  mutate(
    team_composition_value = NA_real_,
    team_motivation_value = NA_real_,
    interdependence_value = NA_real_,
    common_goal_value = NA_real_,
    means_coordination_value = NA_real_
  )

# Post-Runden (nur Team-Faktoren)
new_rounds_post <- new_data_processing %>%
  distinct(participant.code, team_id, task, comm) %>%
  left_join(order_summary_new, by = c("participant.code", "task", "comm")) %>%
  left_join(team_comp_new, by = c("participant.code", "task", "comm")) %>%
  left_join(team_motiv_new, by = c("participant.code", "task", "comm")) %>%
  left_join(interdependence_new, by = c("participant.code", "task", "comm")) %>%
  left_join(common_goal_new, by = c("participant.code", "task", "comm")) %>%
  left_join(means_coordination_new, by = c("participant.code", "task", "comm")) %>%
  # Erweiterte Team-Faktoren hinzufügen
  left_join(group_size_new, by = c("participant.code", "task", "comm")) %>%
  left_join(group_diversity_new, by = c("participant.code", "task", "comm")) %>%
  left_join(group_skill_new, by = c("participant.code", "task", "comm")) %>%
  left_join(communication_required_new, by = c("participant.code", "task", "comm")) %>%
  left_join(work_independence_new, by = c("participant.code", "task", "comm")) %>%
  left_join(social_presence_new, by = c("participant.code", "task", "comm")) %>%
  left_join(perceived_task_complexity_new, by = c("participant.code", "task", "comm")) %>%
  mutate(
    comm = case_when(
      comm == "Jitsi" ~ "Together_Jitsi",
      comm == "Chat" ~ "Together_Chat",
      TRUE ~ comm
    ),
    round = "Post",
    difficulty = "Post",
    # Rundenweise Mediatoren auf NA
    flow_score = NA_real_,
    stress_value = NA_real_,
    individual_motivation_value = NA_real_,
    valence_value = NA_real_,
    arousal_value = NA_real_,
    information_sharing_value = NA_real_,
    synchronization_value = NA_real_
  ) %>%
  select(participant.code, team_id, comm, task, difficulty, round, order,
         flow_score, stress_value, individual_motivation_value, 
         valence_value, arousal_value, information_sharing_value, 
         synchronization_value, team_composition_value, team_motivation_value,
         interdependence_value, common_goal_value, means_coordination_value,
         # Erweiterte Team-Faktoren
         group_size_value, group_diversity_value, group_skill_value,
         communication_required_value, work_independence_value, social_presence_value, perceived_task_complexity_value)

# Kombiniere neue normale + Post-Runden (Typ-Anpassung)
new_rounds_final <- bind_rows(
  new_rounds_normal %>% mutate(round = as.character(round)),
  new_rounds_post
)

print(paste("Neue Daten korrekt aufbereitet (mit Post-Runden):", nrow(new_rounds_final), "Beobachtungen"))

# ================================================================================
# FINALE INTEGRATION MIT POST-RUNDEN-STRUKTUR
# ================================================================================

print("--- FINALE INTEGRATION MIT POST-RUNDEN ---")

# Kombiniere korrigierte Datensätze
integrated_data_full <- bind_rows(
  old_rounds_final,
  new_rounds_final
) %>%
  mutate(
    comm = factor(comm, levels = c("Alone", "Together_None", "Together_Chat", "Together_Jitsi"))
  )

# ============================================================================
# NEUE DATENFILTER FÜR DEINE BESTEHENDEN ANALYSEN
# ============================================================================

# Für deine bestehenden Analysen: Nur normale Runden (Math Task)
integrated_data <- integrated_data_full %>% 
  filter(task == "Math", round != "Post", !is.na(flow_score)) %>%
  mutate(round = as.numeric(round))

# Für Team-Faktoren Analysen: Nur Post-Runden
integrated_data_team_factors <- integrated_data_full %>%
  filter(task == "Math", round == "Post")

print(paste("Integrierte Daten (normale Runden):", nrow(integrated_data), "Beobachtungen"))
print(paste("Team-Faktoren Daten (Post-Runden):", nrow(integrated_data_team_factors), "Beobachtungen"))

print("✅ Post-Runden Integration erfolgreich - deine bestehenden Analysen funktionieren weiter!")

# ================================================================================
# FINALE INTEGRATION MIT POST-RUNDEN-STRUKTUR
# ================================================================================

print("--- FINALE INTEGRATION MIT POST-RUNDEN ---")

# Kombiniere korrigierte Datensätze
integrated_data_full <- bind_rows(
  old_rounds_final,
  new_rounds_final
) %>%
  mutate(
    comm = factor(comm, levels = c("Alone", "Together_None", "Together_Chat", "Together_Jitsi"))
  )

integrated_data <- integrated_data_full %>% filter(task == "Math")

integrated_data_team_factors <- integrated_data_full %>%
  filter(task == "Math", round == "Post")

print(paste("Integrierte Daten:", nrow(integrated_data), "Beobachtungen"))

# ================================================================================
# TEIL 4: DESKRIPTIVE STATISTIKEN
# ================================================================================

print("=== DESKRIPTIVE STATISTIKEN DES INTEGRIERTEN DATENSATZES ===\n")

# Übersicht über Stichprobengrößen
sample_overview <- integrated_data %>%
  group_by(comm) %>%
  summarise(
    n_participants = n_distinct(participant.code),
    n_teams = n_distinct(team_id),
    n_observations = n(),
    .groups = "drop"
  )

print("Stichprobengrößen nach Kommunikationsbedingung:")
print(sample_overview)

# Flow Scores nach Bedingung
flow_by_comm <- integrated_data %>%
  group_by(comm) %>%
  summarise(
    flow_mean = mean(flow_score, na.rm = TRUE),
    flow_sd = sd(flow_score, na.rm = TRUE),
    .groups = "drop"
  )

print("\nFlow Scores nach Kommunikationsbedingung:")
print(flow_by_comm)

# ================================================================================
# TEIL 5: REPEATED MEASURES KORRELATIONEN
# ================================================================================

print("\n\n=== REPEATED MEASURES CORRELATIONS ===\n")

# Liste der rundenweisen Mediatoren
round_mediators <- c("stress_value", "individual_motivation_value", 
                    "valence_value", "arousal_value", 
                    "information_sharing_value", "synchronization_value")

# Funktion für rmcorr mit mehreren Gruppen
perform_rmcorr_extended <- function(data, mediator_name) {
  results <- list()
  
  for(comm_type in levels(data$comm)) {
    comm_data <- data %>% 
      filter(comm == comm_type) %>%
      filter(!is.na(get(mediator_name)) & !is.na(flow_score))
    
    if(nrow(comm_data) > 10 & n_distinct(comm_data$participant.code) > 3) {
      rmcorr_result <- rmcorr(
        participant = participant.code,
        measure1 = get(mediator_name),
        measure2 = flow_score,
        dataset = comm_data
      )
      
      results[[comm_type]] <- list(
        r = rmcorr_result$r,
        p = rmcorr_result$p,
        df = rmcorr_result$df,
        CI = rmcorr_result$CI,
        n = nrow(comm_data)
      )
    }
  }
  
  return(results)
}

# Durchführung für alle Mediatoren
rmcorr_results <- list()

for(mediator in round_mediators) {
  cat("\n", gsub("_value", "", mediator), ":\n", sep = "")
  results <- perform_rmcorr_extended(integrated_data, mediator)
  rmcorr_results[[mediator]] <- results
  
  for(comm_type in names(results)) {
    if(!is.null(results[[comm_type]])) {
      cat("  ", comm_type, ": r = ", round(results[[comm_type]]$r, 3),
          ", p = ", format.pval(results[[comm_type]]$p, digits = 3),
          ", n = ", results[[comm_type]]$n,
          ", 95% CI [", round(results[[comm_type]]$CI[1], 3), 
          ", ", round(results[[comm_type]]$CI[2], 3), "]\n", sep = "")
    }
  }
}

# ================================================================================
# TEIL 6: LINEAR MIXED MODELS
# ================================================================================

print("\n\n=== LINEAR MIXED MODELS ===\n")

# 6.1 Modelle für rundenweise Mediatoren
print("--- RUNDENWEISE MEDIATOREN ---\n")

for(mediator in round_mediators) {
  mediator_name <- gsub("_value", "", mediator)
  cat("\n", toupper(mediator_name), ":\n", sep = "")
  
  # Modell 1: Kommunikation -> Mediator
  formula1 <- as.formula(paste(mediator, "~ comm + (1|participant.code) + (1|round)"))
  model1 <- lmer(formula1, data = integrated_data)
  
  cat("Kommunikation -> ", mediator_name, ":\n", sep = "")
  print(summary(model1)$coefficients)
  
  # Modell 2: Mediator -> Flow
  formula2 <- as.formula(paste("flow_score ~", mediator, "+ (1|participant.code) + (1|round)"))
  model2 <- lmer(formula2, data = integrated_data)
  
  cat("\n", mediator_name, " -> Flow:\n", sep = "")
  print(summary(model2)$coefficients[2,])
  cat("\n")
}

# 6.2 Modelle für einmalige Mediatoren (ANGEPASST)
print("\n--- EINMALIGE MEDIATOREN (ANGEPASST) ---\n")

# Team Composition (KORRIGIERT)
print("\nTEAM COMPOSITION:")

# Verwende integrated_data_team_factors statt tc_data
tc_data <- integrated_data_team_factors %>%
  select(participant.code, comm, team_composition_value) %>%
  filter(!is.na(team_composition_value))

model_tc1 <- lm(team_composition_value ~ comm, data = tc_data)
print("Kommunikation -> Team Composition:")
print(summary(model_tc1)$coefficients)

# Für Mediator -> Flow Analyse: Kombiniere Team-Faktoren mit aggregierten Flow-Scores
tc_flow <- integrated_data %>%
  group_by(participant.code, comm) %>%
  summarise(
    mean_flow = mean(flow_score, na.rm = TRUE),
    .groups = "drop"
  ) %>%
  # Joine mit Team-Faktoren aus Post-Runden
  left_join(
    integrated_data_team_factors %>% 
      select(participant.code, comm, team_composition_value),
    by = c("participant.code", "comm")
  ) %>%
  filter(!is.na(team_composition_value))

model_tc2 <- lm(mean_flow ~ team_composition_value, data = tc_flow)
print("\nTeam Composition -> Flow:")
print(summary(model_tc2)$coefficients[2,])

# Team Motivation (KORRIGIERT)
print("\n\nTEAM MOTIVATION:")

# Verwende integrated_data_team_factors
tm_data <- integrated_data_team_factors %>%
  select(participant.code, comm, team_motivation_value) %>%
  filter(!is.na(team_motivation_value))

model_tm1 <- lm(team_motivation_value ~ comm, data = tm_data)
print("Kommunikation -> Team Motivation:")
print(summary(model_tm1)$coefficients)

# Für Mediator -> Flow Analyse
tm_flow <- integrated_data %>%
  group_by(participant.code, comm) %>%
  summarise(
    mean_flow = mean(flow_score, na.rm = TRUE),
    .groups = "drop"
  ) %>%
  # Joine mit Team-Faktoren aus Post-Runden
  left_join(
    integrated_data_team_factors %>% 
      select(participant.code, comm, team_motivation_value),
    by = c("participant.code", "comm")
  ) %>%
  filter(!is.na(team_motivation_value))

model_tm2 <- lm(mean_flow ~ team_motivation_value, data = tm_flow)
print("\nTeam Motivation -> Flow:")
print(summary(model_tm2)$coefficients[2,])

# ================================================================================
# TEIL 7: ZUSAMMENFASSENDE TABELLEN UND VISUALISIERUNGEN
# ================================================================================

# 7.1 Erstelle Übersichtstabelle der Effekte
create_summary_table_extended <- function() {
  # Platzhalter für erweiterte Zusammenfassung
  # Hier könnten die Koeffizienten aus allen Modellen extrahiert werden
  return(NULL)
}

# 7.2 Visualisierungen
print("\n\n=== VISUALISIERUNGEN ===\n")

# Flow nach Kommunikationsbedingung
p1 <- ggplot(integrated_data, aes(x = comm, y = flow_score, fill = comm)) +
  geom_boxplot(alpha = 0.7) +
  scale_fill_manual(values = c("Alone" = "#E69F00", 
                              "Together_None" = "#56B4E9", 
                              "Together_Chat" = "#009E73", 
                              "Together_Jitsi" = "#F0E442")) +
  labs(title = "Flow Scores by Communication Condition",
       x = "Communication Condition",
       y = "Flow Score",
       fill = "Condition") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

print(p1)

# Mediator-Profile nach Bedingung
mediator_profiles <- integrated_data %>%
  group_by(comm) %>%
  summarise(
    Stress = mean(stress_value, na.rm = TRUE),
    `Individual Motivation` = mean(individual_motivation_value, na.rm = TRUE),
    Valence = mean(valence_value, na.rm = TRUE),
    Arousal = mean(arousal_value, na.rm = TRUE),
    `Information Sharing` = mean(information_sharing_value, na.rm = TRUE),
    Synchronization = mean(synchronization_value, na.rm = TRUE),
    .groups = "drop"
  ) %>%
  pivot_longer(cols = -comm, names_to = "Mediator", values_to = "Score")

p2 <- ggplot(mediator_profiles, aes(x = Mediator, y = Score, fill = comm)) +
  geom_bar(stat = "identity", position = "dodge") +
  scale_fill_manual(values = c("Alone" = "#E69F00", 
                              "Together_None" = "#56B4E9", 
                              "Together_Chat" = "#009E73", 
                              "Together_Jitsi" = "#F0E442")) +
  labs(title = "Mediator Profiles by Communication Condition",
       x = "Mediator",
       y = "Mean Score",
       fill = "Condition") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

print(p2)

# ================================================================================
# TEIL 8: POST-HOC ANALYSEN
# ================================================================================

print("\n\n=== POST-HOC ANALYSEN ===\n")

# Vergleiche spezifische Kontraste
print("Geplante Kontraste:")

# Alone vs. alle Together Bedingungen
integrated_data_contrast <- integrated_data %>%
  mutate(
    alone_vs_together = ifelse(comm == "Alone", 0, 1),
    no_comm_vs_comm = case_when(
      comm %in% c("Alone", "Together_None") ~ 0,
      comm %in% c("Together_Chat", "Together_Jitsi") ~ 1
    ),
    chat_vs_jitsi = case_when(
      comm == "Together_Chat" ~ 0,
      comm == "Together_Jitsi" ~ 1,
      TRUE ~ NA_real_
    )
  )

# Kontrast 1: Alone vs. Together
contrast1 <- lmer(flow_score ~ alone_vs_together + (1|participant.code) + (1|round), 
                 data = integrated_data_contrast)
print("\n1. Alone vs. Together (alle):")
print(summary(contrast1)$coefficients)

# Kontrast 2: Keine Kommunikation vs. Kommunikation
contrast2 <- lmer(flow_score ~ no_comm_vs_comm + (1|participant.code) + (1|round), 
                 data = integrated_data_contrast)
print("\n2. Keine Kommunikation vs. Kommunikation:")
print(summary(contrast2)$coefficients)

# Kontrast 3: Chat vs. Jitsi
contrast3 <- lmer(flow_score ~ chat_vs_jitsi + (1|participant.code) + (1|round), 
                 data = integrated_data_contrast %>% 
                   filter(comm %in% c("Together_Chat", "Together_Jitsi")))
print("\n3. Chat vs. Jitsi:")
print(summary(contrast3)$coefficients)

# ================================================================================
# SCHLUSSNOTIZEN
# ================================================================================

print("\n\n=== ANALYSEN ABGESCHLOSSEN ===")
print("1. Datensätze erfolgreich integriert")
print("2. Repeated Measures Korrelationen für alle Bedingungen berechnet")
print("3. Linear Mixed Models für erweiterten Datensatz erstellt")
print("4. Visualisierungen der Unterschiede zwischen allen vier Bedingungen")
print("5. Post-hoc Kontraste zur Untersuchung spezifischer Hypothesen")

# Speichere integrierten Datensatz für weitere Analysen
# write.csv(integrated_data, "integrated_mediation_data.csv", row.names = FALSE)
```

Structural differences between the communication treatments

```{r}
# ================================================================================
# STRUKTURELLE UNTERSCHIEDE ZWISCHEN KOMMUNIKATIONSFORMEN
# Umfassende Analyse aller Einflussfaktoren
# ================================================================================

library(dplyr)
library(tidyr)
library(ggplot2)
library(lme4)
library(lmerTest)
library(car)
library(emmeans)
library(effectsize)
library(corrplot)
library(RColorBrewer)
library(gridExtra)
library(broom)
library(broom.mixed)
library(ggpubr)
library(scales)

# ================================================================================
# SCHRITT 1: DATENAUFBEREITUNG UND ÜBERSICHT
# ================================================================================

print("=== SCHRITT 1: ANGEPASSTE DATENAUFBEREITUNG ===")

# ÄNDERUNG 1: Definiere getrennte Variablenlisten
rundenweise_vars <- c(
  "flow_score", "stress_value", "individual_motivation_value",
  "valence_value", "arousal_value", "information_sharing_value", 
  "synchronization_value"
)

team_factor_vars <- c(
  "team_composition_value", "team_motivation_value", "interdependence_value", 
  "common_goal_value", "means_coordination_value",
  # Erweiterte Team-Faktoren
  "group_size_value", "group_diversity_value", "group_skill_value",
  "communication_required_value", "work_independence_value", "social_presence_value", "perceived_task_complexity_value"
)

# Kombiniere für Gesamtanalyse
all_vars <- c(rundenweise_vars, team_factor_vars)

# ÄNDERUNG 2: Bereite beide Datensätze vor
# Für rundenweise Analysen
analysis_data_rounds <- integrated_data %>%
  mutate(
    comm = factor(comm, levels = c("Alone", "Together_None", "Together_Chat", "Together_Jitsi")),
    difficulty = factor(difficulty),
    participant.code = factor(participant.code)
  ) %>%
  filter(rowSums(is.na(select(., all_of(rundenweise_vars)))) <= 3)  # Max 50% fehlende Werte

# Für Team-Faktoren Analysen  
analysis_data_team <- integrated_data_team_factors %>%
  mutate(
    comm = factor(comm, levels = c("Alone", "Together_None", "Together_Chat", "Together_Jitsi")),
    participant.code = factor(participant.code)
  ) %>%
  filter(rowSums(is.na(select(., all_of(team_factor_vars)))) <= 5)  # Max 50% fehlende Werte

print(paste("Rundenweise Analysedaten:", nrow(analysis_data_rounds), "Beobachtungen"))
print(paste("Team-Faktoren Analysedaten:", nrow(analysis_data_team), "Beobachtungen"))

# ================================================================================
# SCHRITT 2: DESKRIPTIVE STATISTIKEN
# ================================================================================

# ÄNDERUNG 3: Getrennte deskriptive Statistiken

# Rundenweise Variablen
descriptive_stats_rounds <- analysis_data_rounds %>%
  group_by(comm) %>%
  summarise(
    across(all_of(rundenweise_vars), 
           list(
             mean = ~ mean(.x, na.rm = TRUE),
             sd = ~ sd(.x, na.rm = TRUE),
             n = ~ sum(!is.na(.x))
           ),
           .names = "{.col}_{.fn}"),
    .groups = "drop"
  )

# Team-Faktoren
descriptive_stats_team <- analysis_data_team %>%
  group_by(comm) %>%
  summarise(
    across(all_of(team_factor_vars), 
           list(
             mean = ~ mean(.x, na.rm = TRUE),
             sd = ~ sd(.x, na.rm = TRUE),
             n = ~ sum(!is.na(.x))
           ),
           .names = "{.col}_{.fn}"),
    .groups = "drop"
  )

print("Deskriptive Statistiken - Rundenweise Variablen:")
print(descriptive_stats_rounds)

print("\nDeskriptive Statistiken - Team-Faktoren:")
print(descriptive_stats_team)

# ================================================================================
# SCHRITT 3: MIXED-EFFECTS ANOVA FÜR JEDE VARIABLE
# ================================================================================

print("\n=== SCHRITT 3: ANGEPASSTE ANOVA-ANALYSEN ===")

# ÄNDERUNG 4: Getrennte ANOVA-Funktionen

# Funktion für rundenweise Variablen (Mixed-Effects)
analyze_round_variable <- function(var_name, data) {
  cat("\n", paste(rep("=", 60), collapse=""), "\n")
  cat("RUNDENWEISE ANALYSE FÜR:", toupper(var_name), "\n")
  cat(paste(rep("=", 60), collapse=""), "\n")
  
  var_data <- data %>%
    filter(!is.na(!!sym(var_name))) %>%
    mutate(comm = droplevels(comm))
  
  comm_counts <- var_data %>%
    group_by(comm) %>%
    summarise(n = n(), .groups = "drop")
  
  if(nrow(comm_counts) >= 2 && all(comm_counts$n >= 3)) {
    tryCatch({
      # Mixed-Effects ANOVA
      model <- lmer(as.formula(paste(var_name, "~ comm + (1|participant.code)")), 
                    data = var_data)
      
      anova_result <- anova(model)
      print(anova_result)
      
      # Effektgröße
      f_stat <- anova_result$`F value`[1]
      df1 <- anova_result$NumDF[1] 
      df2 <- anova_result$DenDF[1]
      eta_squared <- f_stat * df1 / (f_stat * df1 + df2)
      
      cat("Partielle η² =", round(eta_squared, 3), "\n")
      
      # Post-hoc Tests
      if(anova_result$`Pr(>F)`[1] < 0.05) {
        cat("\n🔍 SIGNIFIKANTER EFFEKT!\n")
        emm <- emmeans(model, "comm")
        pairwise <- pairs(emm, adjust = "bonferroni")
        
        print("Estimated Marginal Means:")
        print(emm)
        print("\nPaarweise Vergleiche:")
        print(pairwise)
        
        return(list(model = model, anova = anova_result, emmeans = emm, 
                   pairwise = pairwise, eta_squared = eta_squared, significant = TRUE))
      }
      
      return(list(model = model, anova = anova_result, eta_squared = eta_squared, significant = FALSE))
      
    }, error = function(e) {
      cat("❌ Fehler bei Mixed-Effects Modell:", e$message, "\n")
      return(NULL)
    })
  } else {
    cat("⚠️ Nicht genügend Daten\n")
    return(NULL)
  }
}

# Funktion für Team-Faktoren (einfache ANOVA)
analyze_team_variable <- function(var_name, data) {
  cat("\n", paste(rep("=", 60), collapse=""), "\n")
  cat("TEAM-FAKTOREN ANALYSE FÜR:", toupper(var_name), "\n")
  cat(paste(rep("=", 60), collapse=""), "\n")
  
  var_data <- data %>%
    filter(!is.na(!!sym(var_name))) %>%
    mutate(comm = droplevels(comm))
  
  comm_counts <- var_data %>%
    group_by(comm) %>%
    summarise(n = n(), .groups = "drop")
  
  if(nrow(comm_counts) >= 2 && all(comm_counts$n >= 3)) {
    tryCatch({
      # Einfache ANOVA (da nur eine Messung pro Person)
      model <- aov(as.formula(paste(var_name, "~ comm")), data = var_data)
      
      anova_result <- summary(model)
      print(anova_result)
      
      # Effektgröße
      if(length(anova_result) > 0 && nrow(anova_result[[1]]) > 0) {
        f_stat <- anova_result[[1]]$`F value`[1]
        df1 <- anova_result[[1]]$Df[1]
        df2 <- anova_result[[1]]$Df[2]
        
        if(!is.na(f_stat) && !is.na(df1) && !is.na(df2)) {
          eta_squared <- f_stat * df1 / (f_stat * df1 + df2)
          cat("Partielle η² =", round(eta_squared, 3), "\n")
          
          # Post-hoc Tests
          if(anova_result[[1]]$`Pr(>F)`[1] < 0.05) {
            cat("\n🔍 SIGNIFIKANTER EFFEKT!\n")
            posthoc <- TukeyHSD(model)
            print(posthoc)
            
            return(list(model = model, anova = anova_result, posthoc = posthoc, 
                       eta_squared = eta_squared, significant = TRUE))
          }
          
          return(list(model = model, anova = anova_result, eta_squared = eta_squared, significant = FALSE))
        }
      }
      
    }, error = function(e) {
      cat("❌ Fehler bei ANOVA:", e$message, "\n")
      return(NULL)
    })
  } else {
    cat("⚠️ Nicht genügend Daten\n")
    return(NULL)
  }
}

# ÄNDERUNG 5: Führe getrennte Analysen durch

# Rundenweise Variablen analysieren
round_results <- list()
for(var in rundenweise_vars) {
  result <- analyze_round_variable(var, analysis_data_rounds)
  if(!is.null(result)) {
    round_results[[var]] <- result
  }
}

# Team-Faktoren analysieren
team_results <- list()
for(var in team_factor_vars) {
  result <- analyze_team_variable(var, analysis_data_team)
  if(!is.null(result)) {
    team_results[[var]] <- result
  }
}

# ================================================================================
# SCHRITT 4: ZUSAMMENFASSUNG DER ERGEBNISSE
# ================================================================================

print("\n=== SCHRITT 4: ANGEPASSTE ZUSAMMENFASSUNG ===")

# ÄNDERUNG 6: Getrennte Zusammenfassungen

# Sammle signifikante Variablen
significant_round_vars <- names(round_results)[sapply(round_results, function(x) x$significant)]
significant_team_vars <- names(team_results)[sapply(team_results, function(x) x$significant)]

cat("📊 SIGNIFIKANTE RUNDENWEISE VARIABLEN:\n")
if(length(significant_round_vars) > 0) {
  for(var in significant_round_vars) {
    eta_sq <- round_results[[var]]$eta_squared
    cat("✅", toupper(var), "- η² =", round(eta_sq, 3), "\n")
  }
} else {
  cat("❌ Keine signifikanten rundenweisen Unterschiede\n")
}

cat("\n📊 SIGNIFIKANTE TEAM-FAKTOREN:\n")
if(length(significant_team_vars) > 0) {
  for(var in significant_team_vars) {
    eta_sq <- team_results[[var]]$eta_squared
    cat("✅", toupper(var), "- η² =", round(eta_sq, 3), "\n")
  }
} else {
  cat("❌ Keine signifikanten Team-Faktoren Unterschiede\n")
}

# ================================================================================
# SCHRITT 5: VISUALISIERUNGEN
# ================================================================================

print("\n=== SCHRITT 5: ANGEPASSTE VISUALISIERUNGEN ===")

# ÄNDERUNG 7: Erweiterte Variablenlabels für alle Team-Faktoren

create_variable_labels <- function() {
  c(
    # Rundenweise
    "flow_score" = "Flow Score",
    "stress_value" = "Stress",
    "individual_motivation_value" = "Individual Motivation",
    "valence_value" = "Valence",
    "arousal_value" = "Arousal",
    "information_sharing_value" = "Information Sharing",
    "synchronization_value" = "Synchronization",
    # Original Team-Faktoren
    "team_composition_value" = "Team Composition",
    "team_motivation_value" = "Team Motivation",
    "interdependence_value" = "Interdependence",
    "common_goal_value" = "Common Goal",
    "means_coordination_value" = "Means for Coordination",
    # Erweiterte Team-Faktoren
    "group_size_value" = "Group Size",
    "group_diversity_value" = "Group Diversity",
    "group_skill_value" = "Group Skill",
    "communication_required_value" = "Communication Required",
    "work_independence_value" = "Work Independence",
    "social_presence_value" = "Social Presence",
    "perceived_task_complexity_value" = "Perceived Task Complexity"
  )
}

variable_labels <- create_variable_labels()

# ÄNDERUNG 8: Kombinierte Visualisierung für alle Faktoren

# Bereite kombinierte Plot-Daten vor
prepare_combined_plot_data <- function() {
  # Rundenweise Daten (aggregiert pro Person)
  round_plot_data <- analysis_data_rounds %>%
    group_by(participant.code, comm) %>%
    summarise(across(all_of(rundenweise_vars), ~ mean(.x, na.rm = TRUE)), .groups = "drop") %>%
    pivot_longer(cols = all_of(rundenweise_vars), names_to = "variable", values_to = "value") %>%
    filter(!is.na(value)) %>%
    mutate(type = "Rundenweise")
  
  # Team-Faktoren Daten
  team_plot_data <- analysis_data_team %>%
    select(participant.code, comm, all_of(team_factor_vars)) %>%
    pivot_longer(cols = all_of(team_factor_vars), names_to = "variable", values_to = "value") %>%
    filter(!is.na(value)) %>%
    mutate(type = "Team-Faktoren")
  
  # Kombiniere beide
  combined_data <- bind_rows(round_plot_data, team_plot_data) %>%
    mutate(
      variable_clean = variable_labels[variable],
      variable_clean = ifelse(is.na(variable_clean), variable, variable_clean),
      comm_clean = case_when(
        comm == "Alone" ~ "Alone",
        comm == "Together_None" ~ "Together\n(No Comm)",
        comm == "Together_Chat" ~ "Together\n(Chat)",
        comm == "Together_Jitsi" ~ "Together\n(Video/Audio)",
        TRUE ~ as.character(comm)
      )
    )
  
  return(combined_data)
}

plot_data_combined <- prepare_combined_plot_data()

# Erstelle erweiterte Boxplots für alle Variablen
create_extended_boxplot <- function(var_name, data) {
  var_data <- data %>% filter(variable == var_name)
  if(nrow(var_data) == 0) return(NULL)
  
  var_label <- unique(var_data$variable_clean)[1]
  var_type <- unique(var_data$type)[1]
  
  # Unterschiedliche Farbpaletten für verschiedene Typen
  colors <- if(var_type == "Rundenweise") {
    RColorBrewer::brewer.pal(4, "Set2")
  } else {
    RColorBrewer::brewer.pal(4, "Set1")
  }
  
  ggplot(var_data, aes(x = comm_clean, y = value, fill = comm_clean)) +
    geom_boxplot(alpha = 0.7, outlier.size = 1.5) +
    geom_jitter(width = 0.2, alpha = 0.4, size = 1) +
    scale_fill_manual(values = colors) +
    labs(
      title = paste(var_label, paste0("(", var_type, ")")),
      x = "Communication Form",
      y = "Value"
    ) +
    theme_minimal() +
    theme(
      plot.title = element_text(size = 11, face = "bold", hjust = 0.5),
      axis.text.x = element_text(size = 9),
      axis.text.y = element_text(size = 9),
      legend.position = "none"
    )
}

# ÄNDERUNG 9: Erstelle Boxplots für alle erweiterten Variablen
print("Erstelle erweiterte Boxplots...")

extended_boxplots <- list()
for(var in all_vars) {
  if(var %in% unique(plot_data_combined$variable)) {
    cat("Erstelle Boxplot für:", var, "\n")
    plot <- create_extended_boxplot(var, plot_data_combined)
    if(!is.null(plot)) {
      extended_boxplots[[var]] <- plot
    }
  }
}

# Zeige alle Plots in größerem Grid (6x3 für 18 Variablen)
if(length(extended_boxplots) > 0) {
  # Berechne optimale Grid-Dimensionen
  n_plots <- length(extended_boxplots)
  ncol <- min(6, ceiling(sqrt(n_plots)))
  nrow <- ceiling(n_plots / ncol)
  
  grid.arrange(grobs = extended_boxplots, ncol = ncol, nrow = nrow,
               top = "Extended Team Factors Analysis: All Communication Forms")
}

print("\n=== SPEZIELLE TEAM-FAKTOREN VISUALISIERUNG ===")

# ÄNDERUNG 10: Erstelle Grafik im Stil deiner Beispielgrafik

create_team_factors_profile_plot <- function(data) {
  # Bereite Daten für Profil-Plot vor
  profile_data <- data %>%
    group_by(comm) %>%
    summarise(
      across(all_of(team_factor_vars), ~ mean(.x, na.rm = TRUE)),
      .groups = "drop"
    ) %>%
    pivot_longer(cols = all_of(team_factor_vars), names_to = "factor", values_to = "score") %>%
    mutate(
      factor_clean = variable_labels[factor],
      factor_clean = ifelse(is.na(factor_clean), factor, factor_clean),
      comm_clean = case_when(
        comm == "Alone" ~ "Alone",
        comm == "Together_None" ~ "Together (No Comm)",
        comm == "Together_Chat" ~ "Together (Chat)", 
        comm == "Together_Jitsi" ~ "Together (Video/Audio)",
        TRUE ~ as.character(comm)
      )
    )
  
  # Erstelle den Profil-Plot
  ggplot(profile_data, aes(x = factor_clean, y = score, fill = comm_clean)) +
    geom_col(position = "dodge", alpha = 0.8, color = "black", size = 0.3) +
    geom_text(aes(label = round(score, 2)), 
              position = position_dodge(width = 0.9), 
              vjust = -0.5, size = 3, fontweight = "bold") +
    scale_fill_brewer(type = "qual", palette = "Set2") +
    labs(
      title = "Team Factors Profile by Communication Condition",
      subtitle = "Mean scores across all team perception dimensions",
      x = "Team Factor",
      y = "Mean Score",
      fill = "Communication\nCondition"
    ) +
    theme_minimal() +
    theme(
      axis.text.x = element_text(angle = 45, hjust = 1, size = 10),
      plot.title = element_text(size = 14, face = "bold"),
      legend.position = "bottom"
    )
}

if(nrow(analysis_data_team) > 0) {
  team_profile_plot <- create_team_factors_profile_plot(analysis_data_team)
  print(team_profile_plot)
}

# ================================================================================
# SCHRITT 6: KORRELATIONSANALYSE
# ================================================================================

# Kombiniere beide Datensätze für Korrelationsanalyse
combined_cor_data <- analysis_data_rounds %>%
  group_by(participant.code, comm) %>%
  summarise(across(all_of(rundenweise_vars), ~ mean(.x, na.rm = TRUE)), .groups = "drop") %>%
  left_join(
    analysis_data_team %>% select(participant.code, comm, all_of(team_factor_vars)),
    by = c("participant.code", "comm")
  ) %>%
  select(all_of(all_vars)) %>%
  select(where(~ sum(!is.na(.)) > 10))  # Nur Variablen mit genügend Daten

if(ncol(combined_cor_data) >= 2) {
  cor_matrix <- cor(combined_cor_data, use = "pairwise.complete.obs")
  
  # Korrelations-Heatmap
  corrplot(cor_matrix, 
           method = "color",
           type = "upper",
           order = "hclust",
           tl.cex = 0.8,
           tl.col = "black",
           title = "Korrelationen zwischen allen Einflussfaktoren",
           mar = c(0,0,2,0))
}

# ================================================================================
# SCHRITT 7: BOX-PLOTS
# ================================================================================

# Bereite kombinierte Plot-Daten vor (genau wie im anderen reparierten Code)
prepare_corrected_boxplot_data <- function() {
  
  # Rundenweise Daten (aggregiert pro Person für Boxplots)
  round_plot_data <- analysis_data_rounds %>%
    group_by(participant.code, comm) %>%
    summarise(across(all_of(rundenweise_vars), ~ mean(.x, na.rm = TRUE)), .groups = "drop") %>%
    pivot_longer(cols = all_of(rundenweise_vars), names_to = "variable", values_to = "value") %>%
    filter(!is.na(value)) %>%
    mutate(type = "Rundenweise")
  
  # Team-Faktoren Daten
  team_plot_data <- analysis_data_team %>%
    select(participant.code, comm, all_of(team_factor_vars)) %>%
    pivot_longer(cols = all_of(team_factor_vars), names_to = "variable", values_to = "value") %>%
    filter(!is.na(value)) %>%
    mutate(type = "Team-Faktoren")
  
  # Kombiniere beide
  combined_data <- bind_rows(round_plot_data, team_plot_data) %>%
    mutate(
      # Verwende die erweiterten Variablenlabels
      variable_clean = variable_labels[variable],
      variable_clean = ifelse(is.na(variable_clean), variable, variable_clean),
      comm_clean = case_when(
        comm == "Alone" ~ "Alone",
        comm == "Together_None" ~ "Together\n(No Comm)",
        comm == "Together_Chat" ~ "Together\n(Chat)",
        comm == "Together_Jitsi" ~ "Together\n(Video/Audio)",
        TRUE ~ as.character(comm)
      )
    )
  
  return(combined_data)
}

# Erstelle korrigierte Plot-Daten
corrected_plot_data <- prepare_corrected_boxplot_data()

print(paste("Korrigierte Plot-Daten erstellt:", nrow(corrected_plot_data), "Datenpunkte"))
print(paste("Verfügbare Variablen:", length(unique(corrected_plot_data$variable))))

# Zeige verfügbare Variablen
available_vars <- unique(corrected_plot_data$variable)
cat("Verfügbare Variablen für Boxplots:\n")
for(var in available_vars) {
  var_label <- unique(corrected_plot_data$variable_clean[corrected_plot_data$variable == var])[1]
  var_type <- unique(corrected_plot_data$type[corrected_plot_data$variable == var])[1]
  n_points <- sum(corrected_plot_data$variable == var & !is.na(corrected_plot_data$value))
  cat("  -", var, ":", var_label, "(", var_type, ") - n =", n_points, "\n")
}

# Erstelle korrigierte Boxplot-Funktion
create_corrected_boxplot <- function(var_name, data = corrected_plot_data) {
  var_data <- data %>% filter(variable == var_name)
  
  if(nrow(var_data) == 0) {
    cat("⚠️ Keine Daten für Variable:", var_name, "\n")
    return(NULL)
  }
  
  var_label <- unique(var_data$variable_clean)[1]
  var_type <- unique(var_data$type)[1]
  
  # Unterschiedliche Farbpaletten für verschiedene Typen
  colors <- if(var_type == "Rundenweise") {
    RColorBrewer::brewer.pal(4, "Set2")
  } else {
    RColorBrewer::brewer.pal(4, "Set1")
  }
  
  ggplot(var_data, aes(x = comm_clean, y = value, fill = comm_clean)) +
    geom_boxplot(alpha = 0.7, outlier.size = 1.5) +
    geom_jitter(width = 0.2, alpha = 0.4, size = 1) +
    scale_fill_manual(values = colors) +
    labs(
      title = paste(var_label, paste0("(", var_type, ")")),
      x = "Communication Form",
      y = "Value"
    ) +
    theme_minimal() +
    theme(
      plot.title = element_text(size = 11, face = "bold", hjust = 0.5),
      axis.text.x = element_text(size = 9),
      axis.text.y = element_text(size = 9),
      legend.position = "none"
    )
}


print("\nErstelle korrigierte Boxplots für alle Variablen...")

# Erstelle Boxplots für ALLE verfügbaren Variablen
corrected_boxplots <- list()
successful_plots <- 0

for(var in all_vars) {
  if(var %in% available_vars) {
    cat("Erstelle Boxplot für:", var, "\n")
    plot <- create_corrected_boxplot(var, corrected_plot_data)
    if(!is.null(plot)) {
      corrected_boxplots[[var]] <- plot
      successful_plots <- successful_plots + 1
    }
  } else {
    cat("⚠️ Variable nicht in Daten verfügbar:", var, "\n")
  }
}

cat("Erfolgreich erstellte Boxplots:", successful_plots, "von", length(all_vars), "\n")

if(length(corrected_boxplots) > 0) {
  
  print("\n=== ZEIGE KORRIGIERTE BOXPLOTS ===")
  
  # Berechne optimale Grid-Dimensionen für alle Plots
  n_plots <- length(corrected_boxplots)
  if(n_plots <= 12) {
    ncol <- 4
    nrow <- 3
  } else if(n_plots <= 18) {
    ncol <- 6
    nrow <- 3
  } else {
    ncol <- 6
    nrow <- ceiling(n_plots / 6)
  }
  
  print(paste("Zeige", n_plots, "Boxplots in einem", ncol, "x", nrow, "Grid"))
  
  # Zeige alle Plots in einem Grid
  grid.arrange(grobs = corrected_boxplots, ncol = ncol, nrow = nrow,
               top = "Corrected Communication Analysis: All Variables")
  
  
  print("\n=== SEPARATE GRIDS NACH TYP ===")
  
  # Rundenweise Boxplots
  round_boxplots <- corrected_boxplots[names(corrected_boxplots) %in% rundenweise_vars]
  if(length(round_boxplots) > 0) {
    print(paste("Rundenweise Variablen:", length(round_boxplots), "Plots"))
    
    ncol_round <- min(4, length(round_boxplots))
    nrow_round <- ceiling(length(round_boxplots) / ncol_round)
    
    grid.arrange(grobs = round_boxplots, ncol = ncol_round, nrow = nrow_round,
                 top = "Rundenweise Mediatoren (Aggregiert pro Person)")
  }
  
  # Team-Faktoren Boxplots  
  team_boxplots <- corrected_boxplots[names(corrected_boxplots) %in% team_factor_vars]
  if(length(team_boxplots) > 0) {
    print(paste("Team-Faktoren:", length(team_boxplots), "Plots"))
    
    ncol_team <- min(4, length(team_boxplots))
    nrow_team <- ceiling(length(team_boxplots) / ncol_team)
    
    grid.arrange(grobs = team_boxplots, ncol = ncol_team, nrow = nrow_team,
                 top = "Team-Faktoren (Post-Runden Messungen)")
  }
  
  cat("\n=== EINZELNE KORRIGIERTE BOXPLOTS ===\n")
  
  # Gruppiere nach Typ für bessere Organisation
  cat("RUNDENWEISE VARIABLEN:\n")
  for(var in names(round_boxplots)) {
    cat("Zeige Boxplot für:", var, "\n")
    print(round_boxplots[[var]])
  }
  
  cat("\nTEAM-FAKTOREN:\n")
  for(var in names(team_boxplots)) {
    cat("Zeige Boxplot für:", var, "\n")
    print(team_boxplots[[var]])
  }
  
} else {
  cat("❌ Keine Boxplots erstellt - prüfe Datenaufbereitung!\n")
}

print("\n=== DIAGNOSTIK ===")

# Prüfe Datenverfügbarkeit
cat("Datenverfügbarkeit pro Variablentyp:\n")

round_availability <- corrected_plot_data %>%
  filter(type == "Rundenweise") %>%
  group_by(variable) %>%
  summarise(n_points = sum(!is.na(value)), .groups = "drop")

team_availability <- corrected_plot_data %>%
  filter(type == "Team-Faktoren") %>%
  group_by(variable) %>%
  summarise(n_points = sum(!is.na(value)), .groups = "drop")

cat("Rundenweise Variablen:\n")
print(round_availability)

cat("\nTeam-Faktoren:\n")
print(team_availability)

# Prüfe Kommunikationsformen-Verteilung
comm_distribution <- corrected_plot_data %>%
  group_by(type, comm) %>%
  summarise(n_participants = n_distinct(participant.code), .groups = "drop")

cat("\nTeilnehmer pro Kommunikationsform:\n")
print(comm_distribution)


# ================================================================================
# FINALE EMPFEHLUNGEN
# ================================================================================

cat("\n", rep("=",80), "\n")
cat("EMPFEHLUNGEN FÜR WEITERE ANALYSEN\n")
cat(rep("=",80), "\n")

print("Analyse abgeschlossen! 🎉")

# ================================================================================
# UNTERSUCHUNG DER EFFEKTGRÖSSEN-ANOMALIE BEI KOMMUNIKATIONSMEDIEN
# Warum haben nicht-signifikante Kommunikations-Variablen hohe Effektgrößen?
# ================================================================================

print("=== UNTERSUCHUNG DER KOMMUNIKATIONS-EFFEKTGRÖSSEN-ANOMALIE ===")

# ================================================================================
# 1. DATENVERFÜGBARKEIT PRO VARIABLE UND KOMMUNIKATIONSFORM PRÜFEN
# ================================================================================

print("\n1. DATENVERFÜGBARKEIT PRO VARIABLE UND KOMMUNIKATIONSFORM:")

# Analysiere Datenverfügbarkeit für ALLE Variablen (rundenweise + Team-Faktoren)

# Rundenweise Variablen
round_availability <- analysis_data_rounds %>%
  group_by(participant.code, comm) %>%
  summarise(across(all_of(rundenweise_vars), ~ mean(.x, na.rm = TRUE)), .groups = "drop") %>%
  select(comm, all_of(rundenweise_vars)) %>%
  pivot_longer(cols = all_of(rundenweise_vars), names_to = "variable", values_to = "value") %>%
  group_by(variable, comm) %>%
  summarise(
    n_available = sum(!is.na(value)),
    n_missing = sum(is.na(value)),
    pct_available = round(100 * sum(!is.na(value)) / n(), 1),
    .groups = "drop"
  ) %>%
  mutate(type = "Rundenweise")

# Team-Faktoren Verfügbarkeit
team_availability <- analysis_data_team %>%
  select(comm, all_of(team_factor_vars)) %>%
  pivot_longer(cols = all_of(team_factor_vars), names_to = "variable", values_to = "value") %>%
  group_by(variable, comm) %>%
  summarise(
    n_available = sum(!is.na(value)),
    n_missing = sum(is.na(value)),
    pct_available = round(100 * sum(!is.na(value)) / n(), 1),
    .groups = "drop"
  ) %>%
  mutate(type = "Team-Faktoren")

# Kombiniere beide
all_availability <- bind_rows(round_availability, team_availability) %>%
  pivot_wider(names_from = comm, values_from = c(n_available, n_missing, pct_available)) %>%
  mutate(
    total_available = rowSums(select(., starts_with("n_available_")), na.rm = TRUE),
    variable_clean = variable_labels[variable],
    variable_clean = ifelse(is.na(variable_clean), variable, variable_clean)
  ) %>%
  arrange(type, total_available)

print("REPARIERTE Datenverfügbarkeit pro Variable und Kommunikationsform:")
available_cols <- names(all_availability)[grepl("n_available_", names(all_availability))]

print(all_availability %>% 
      select(variable_clean, type, all_of(available_cols), total_available))

# ================================================================================
# 2. KORRIGIERTE KOMMUNIKATIONS-EFFEKTGRÖSSEN-BERECHNUNG
# ================================================================================

# Kombiniere Ergebnisse aus rundenweisen und Team-Faktoren Analysen
create_combined_effect_analysis <- function() {
  
  all_effect_results <- list()
  
  # Rundenweise Ergebnisse hinzufügen
  for(var in names(round_results)) {
    all_effect_results[[var]] <- list(
      type = "Rundenweise",
      significant = round_results[[var]]$significant,
      eta_squared = round_results[[var]]$eta_squared,
      anova = round_results[[var]]$anova,
      data_source = "analysis_data_rounds"
    )
  }
  
  # Team-Faktoren Ergebnisse hinzufügen
  for(var in names(team_results)) {
    all_effect_results[[var]] <- list(
      type = "Team-Faktoren",
      significant = team_results[[var]]$significant,
      eta_squared = team_results[[var]]$eta_squared,
      anova = team_results[[var]]$anova,
      data_source = "analysis_data_team"
    )
  }
  
  return(all_effect_results)
}

# Erstelle kombinierte Analyse
combined_effect_results <- create_combined_effect_analysis()

# Analysiere Stichprobengrößen für alle Variablen
analyze_sample_sizes <- function() {
  sample_info <- list()
  
  # Rundenweise Variablen
  for(var in rundenweise_vars) {
    if(var %in% names(round_results)) {
      var_data <- analysis_data_rounds %>%
        filter(!is.na(!!sym(var))) %>%
        group_by(comm) %>%
        summarise(n = n(), .groups = "drop")
      
      sample_info[[var]] <- var_data
    }
  }
  
  # Team-Faktoren
  for(var in team_factor_vars) {
    if(var %in% names(team_results)) {
      var_data <- analysis_data_team %>%
        filter(!is.na(!!sym(var))) %>%
        group_by(comm) %>%
        summarise(n = n(), .groups = "drop")
      
      sample_info[[var]] <- var_data
    }
  }
  
  return(sample_info)
}

combined_sample_sizes <- analyze_sample_sizes()

# Erstelle reparierte Ergebnistabelle
create_repaired_results_table <- function() {
  
  results_df <- data.frame(
    Variable = all_vars,
    stringsAsFactors = FALSE
  )
  
  # Füge Typ hinzu
  results_df$Type <- ifelse(results_df$Variable %in% rundenweise_vars, "Rundenweise", "Team-Faktoren")
  
  # Initialisiere Spalten
  results_df$N_total <- 0
  results_df$N_groups <- 0
  results_df$Eta_squared <- NA_real_
  results_df$P_value <- NA_real_
  results_df$F_value <- NA_real_
  results_df$Signifikant <- FALSE
  results_df$Analysis_Type <- NA_character_
  
  # Fülle Informationen für alle Variablen
  for(var in all_vars) {
    idx <- which(results_df$Variable == var)
    
    if(var %in% names(combined_effect_results)) {
      result <- combined_effect_results[[var]]
      
      results_df$Signifikant[idx] <- result$significant
      results_df$Eta_squared[idx] <- round(result$eta_squared, 3)
      results_df$Analysis_Type[idx] <- ifelse(result$type == "Rundenweise", 
                                             "Mixed-Effects ANOVA", "Simple ANOVA")
      
      # Extrahiere P- und F-Werte
      if(!is.null(result$anova)) {
        tryCatch({
          if(result$type == "Rundenweise") {
            results_df$P_value[idx] <- round(result$anova$`Pr(>F)`[1], 4)
            results_df$F_value[idx] <- round(result$anova$`F value`[1], 3)
          } else {
            results_df$P_value[idx] <- round(result$anova[[1]]$`Pr(>F)`[1], 4)
            results_df$F_value[idx] <- round(result$anova[[1]]$`F value`[1], 3)
          }
        }, error = function(e) {
          cat("⚠️ Konnte P/F-Werte für", var, "nicht extrahieren\n")
        })
      }
    }
    
    # Stichprobengrößen
    if(var %in% names(combined_sample_sizes)) {
      sample_data <- combined_sample_sizes[[var]]
      results_df$N_total[idx] <- sum(sample_data$n)
      results_df$N_groups[idx] <- nrow(sample_data)
    }
  }
  
  # Füge schöne Labels hinzu
  results_df$Variable_Clean <- variable_labels[results_df$Variable]
  results_df$Variable_Clean <- ifelse(is.na(results_df$Variable_Clean), 
                                     results_df$Variable, results_df$Variable_Clean)
  
  # Zuverlässigkeits-Check
  results_df$Reliable <- results_df$N_total >= 20 & 
                         !is.na(results_df$Eta_squared) &
                         results_df$Eta_squared < 0.9
  
  # Sortiere
  results_df <- results_df %>%
    arrange(Type, desc(Signifikant), desc(Eta_squared))
  
  return(results_df)
}

# Erstelle und zeige reparierte Ergebnistabelle
repaired_results <- create_repaired_results_table()

print("REPARIERTE KOMBINIERTE ERGEBNISTABELLE:")
print(repaired_results %>% 
      select(Variable_Clean, Type, Signifikant, P_value, F_value, Eta_squared, N_total, Analysis_Type))

# Zusammenfassung
total_vars <- nrow(repaired_results)
significant_vars <- sum(repaired_results$Signifikant, na.rm = TRUE)
reliable_vars <- sum(repaired_results$Reliable, na.rm = TRUE)

cat("\n=== REPARIERTE ZUSAMMENFASSUNG ===\n")
cat("📊 GESAMTÜBERSICHT:\n")
cat("- Gesamte Variablen:", total_vars, "\n")
cat("- Signifikante Variablen:", significant_vars, "(", round(100*significant_vars/total_vars, 1), "%)\n")
cat("- Zuverlässige Variablen:", reliable_vars, "(", round(100*reliable_vars/total_vars, 1), "%)\n")

# Zeige problematische Variablen
problematic_vars <- repaired_results$Variable[!repaired_results$Reliable & !is.na(repaired_results$Eta_squared)]
if(length(problematic_vars) > 0) {
  cat("\n⚠️ PROBLEMATISCHE VARIABLEN (zu wenig Daten oder überschätzte Effektgrößen):\n")
  for(var in problematic_vars) {
    row <- repaired_results[repaired_results$Variable == var, ]
    cat("  -", row$Variable_Clean, ": n=", row$N_total, ", η²=", row$Eta_squared, "\n")
  }
}

# ================================================================================
# 4. INTERPRETATION DER KOMMUNIKATIONS-EFFEKTGRÖSSEN-ANOMALIE
# ================================================================================

# ================================================================================
# KORREKTUR: ERSETZE FEHLENDE comm_corrected_results DURCH repaired_results
# ================================================================================

# Das Problem: comm_corrected_results existiert nicht
# Lösung: Verwende repaired_results (die korrekte Variable)

cat("\n", paste(rep("=", 80), collapse=""), "\n")
cat("INTERPRETATION DER KOMMUNIKATIONS-EFFEKTGRÖSSEN-ANOMALIE\n")
cat(paste(rep("=", 80), collapse=""), "\n")

# KORRIGIERT: Verwende repaired_results statt comm_corrected_results
reliable_comm_vars <- repaired_results$Variable[repaired_results$Reliable & !is.na(repaired_results$Reliable)]
unreliable_comm_vars <- repaired_results$Variable[!repaired_results$Reliable & !is.na(repaired_results$Reliable)]

cat("🔍 ERKLÄRUNG DER KOMMUNIKATIONS-EFFEKTGRÖSSEN-ANOMALIE:\n\n")
cat("Die hohen Effektgrößen (>0.8) bei nicht-signifikanten Kommunikations-Effekten entstehen durch:\n")
cat("1. 📊 UNBALANCIERTE GRUPPEN: Manche Kommunikationsformen haben sehr wenige Teilnehmer\n")
cat("2. 🎯 FEHLENDE DATEN: Nicht alle Kommunikationsformen haben Daten für alle Variablen\n")
cat("3. 🔋 NIEDRIGE POWER: Bei 4 Gruppen braucht man mehr Teilnehmer für ausreichende Power\n")
cat("4. 📐 ZWISCHEN-GRUPPEN VARIANZ: Große Unterschiede zwischen wenigen Datenpunkten\n\n")

if(length(reliable_comm_vars) > 0) {
  cat("✅ ZUVERLÄSSIGE KOMMUNIKATIONS-ERGEBNISSE:\n")
  for(var in reliable_comm_vars) {
    row <- repaired_results[repaired_results$Variable == var, ]
    cat("  -", row$Variable_Clean, ": n=", row$N_total, ", Gruppen=", row$N_groups, 
        ", η²=", row$Eta_squared, ", p=", row$P_value, "\n")
  }
  cat("\n")
}

if(length(unreliable_comm_vars) > 0) {
  cat("⚠️ UNZUVERLÄSSIGE KOMMUNIKATIONS-ERGEBNISSE:\n")
  for(var in unreliable_comm_vars) {
    row <- repaired_results[repaired_results$Variable == var, ]
    problem <- ""
    if(row$N_total < 40) problem <- paste(problem, "KLEINE STICHPROBE")
    if(row$N_groups < 3) problem <- paste(problem, "FEHLENDE GRUPPEN")
    if(!is.na(row$Eta_squared) && row$Eta_squared > 0.8) problem <- paste(problem, "ÜBERSCHÄTZTE EFFEKTGRÖSSE")
    
    cat("  -", row$Variable_Clean, ": n=", row$N_total, ", η²=", row$Eta_squared, 
        " →", problem, "\n")
  }
  cat("\n")
}

cat("💡 EMPFEHLUNGEN FÜR KOMMUNIKATIONS-ANALYSE:\n")
cat("1. 🎯 Fokussiere nur auf Variablen mit n≥40 und mindestens 3 Kommunikationsformen\n")
cat("2. 📊 Verwende Omega² statt η² (konservativer bei kleinen Stichproben)\n")
cat("3. 🔍 Prüfe Balancierung der Kommunikationsgruppen\n")
cat("4. 📈 Sammle mehr Daten für unterrepräsentierte Kommunikationsformen\n")
cat("5. 🎨 Erstelle nur Boxplots für zuverlässige Variablen\n")
cat("6. 🔄 Erwäge Zusammenfassung ähnlicher Kommunikationsformen\n\n")

# Zeige problematische Gruppierungen
cat("📊 STICHPROBENVERTEILUNG PRO KOMMUNIKATIONSFORM:\n")
for(var in names(combined_sample_sizes)) {
  if(var %in% unreliable_comm_vars) {
    cat("⚠️", var, ":\n")
    print(combined_sample_sizes[[var]])
    cat("\n")
  }
}

print("Kommunikations-Effektgrößen-Untersuchung abgeschlossen! 🔍")
```

Structural differences between the task types

```{r}
# ================================================================================
# ERWEITERTE STRUKTURELLE UNTERSCHIEDE: MATH VS HP TASK
# Analyse mit neuer Datenstruktur und allen Team-Faktoren (Chat und Jitsi)
# ================================================================================

library(dplyr)
library(tidyr)
library(ggplot2)
library(lme4)
library(lmerTest)
library(car)
library(emmeans)
library(effectsize)
library(gridExtra)
library(broom)
library(broom.mixed)
library(RColorBrewer)

# ================================================================================
# SCHRITT 1: ERWEITERTE DATENAUFBEREITUNG FÜR TASK-VERGLEICH
# ================================================================================

print("=== SCHRITT 1: ERWEITERTE DATENAUFBEREITUNG FÜR TASK-VERGLEICH ===")

# ÄNDERUNG 1: Definiere getrennte Variablenlisten (wie bei Kommunikations-Analyse)
rundenweise_vars <- c(
  "flow_score", "stress_value", "individual_motivation_value",
  "valence_value", "arousal_value", "information_sharing_value", 
  "synchronization_value"
)

team_factor_vars <- c(
  "team_composition_value", "team_motivation_value", "interdependence_value", 
  "common_goal_value", "means_coordination_value",
  # Erweiterte Team-Faktoren
  "group_size_value", "group_diversity_value", "group_skill_value",
  "communication_required_value", "work_independence_value", "social_presence_value", "perceived_task_complexity_value"
)

# Kombiniere für Gesamtanalyse
all_vars <- c(rundenweise_vars, team_factor_vars)

# ÄNDERUNG 2: Erstelle erweiterte Datensätze für Task-Vergleich

# Für rundenweise Analysen (normale Runden, beide Tasks)
task_analysis_data_rounds <- integrated_data_full %>%
  filter(comm %in% c("Together_Chat", "Together_Jitsi"), round != "Post") %>%
  mutate(
    task = factor(task, levels = c("Math", "HP")),
    comm = factor(comm, levels = c("Together_Chat", "Together_Jitsi")),
    participant.code = factor(participant.code),
    round = as.numeric(round)
  ) %>%
  filter(rowSums(is.na(select(., all_of(rundenweise_vars)))) <= 3)  # Max 50% fehlende Werte

# ÄNDERUNG 3: Für Team-Faktoren Analysen (Post-Runden, beide Tasks)
task_analysis_data_team <- integrated_data_full %>%
  filter(comm %in% c("Together_Chat", "Together_Jitsi"), round == "Post") %>%
  mutate(
    task = factor(task, levels = c("Math", "HP")),
    comm = factor(comm, levels = c("Together_Chat", "Together_Jitsi")),
    participant.code = factor(participant.code)
  ) %>%
  filter(rowSums(is.na(select(., all_of(team_factor_vars)))) <= 5)  # Max 50% fehlende Werte

print(paste("Task-Analysedaten (rundenweise):", nrow(task_analysis_data_rounds), "Beobachtungen"))
print(paste("Task-Analysedaten (Team-Faktoren):", nrow(task_analysis_data_team), "Beobachtungen"))

# Übersicht der Stichprobengrößen
task_sample_overview_rounds <- task_analysis_data_rounds %>%
  group_by(task, comm) %>%
  summarise(
    n_participants = n_distinct(participant.code),
    n_observations = n(),
    .groups = "drop"
  )

task_sample_overview_team <- task_analysis_data_team %>%
  group_by(task, comm) %>%
  summarise(
    n_participants = n_distinct(participant.code),
    n_observations = n(),
    .groups = "drop"
  )

print("Stichprobengrößen (rundenweise):")
print(task_sample_overview_rounds)

print("\nStichprobengrößen (Team-Faktoren):")
print(task_sample_overview_team)

# ================================================================================
# SCHRITT 2: ERWEITERTE DESKRIPTIVE STATISTIKEN
# ================================================================================

print("\n=== SCHRITT 2: ERWEITERTE DESKRIPTIVE STATISTIKEN NACH TASK ===")

# ÄNDERUNG 4: Getrennte deskriptive Statistiken

# Rundenweise Variablen (aggregiert pro Person)
task_descriptive_rounds <- task_analysis_data_rounds %>%
  group_by(participant.code, task, comm) %>%
  summarise(across(all_of(rundenweise_vars), ~ mean(.x, na.rm = TRUE)), .groups = "drop") %>%
  group_by(task) %>%
  summarise(
    across(all_of(rundenweise_vars), 
           list(
             mean = ~ mean(.x, na.rm = TRUE),
             sd = ~ sd(.x, na.rm = TRUE),
             n = ~ sum(!is.na(.x))
           ),
           .names = "{.col}_{.fn}"),
    .groups = "drop"
  )

# Team-Faktoren
task_descriptive_team <- task_analysis_data_team %>%
  group_by(task) %>%
  summarise(
    across(all_of(team_factor_vars), 
           list(
             mean = ~ mean(.x, na.rm = TRUE),
             sd = ~ sd(.x, na.rm = TRUE),
             n = ~ sum(!is.na(.x))
           ),
           .names = "{.col}_{.fn}"),
    .groups = "drop"
  )

print("Deskriptive Statistiken pro Task (rundenweise):")
print(task_descriptive_rounds)

print("\nDeskriptive Statistiken pro Task (Team-Faktoren):")
print(task_descriptive_team)

# ================================================================================
# SCHRITT 3: ERWEITERTE ANOVA-ANALYSEN FÜR TASK-VERGLEICH
# ================================================================================

print("\n=== SCHRITT 3: ERWEITERTE ANOVA-ANALYSEN (TASK-EFFEKTE) ===")

# ÄNDERUNG 5: Getrennte ANOVA-Funktionen für Task-Vergleich

# Funktion für rundenweise Variablen (Mixed-Effects)
analyze_task_round_variable <- function(var_name, data) {
  cat("\n", paste(rep("=", 60), collapse=""), "\n")
  cat("TASK-VERGLEICH (RUNDENWEISE) FÜR:", toupper(var_name), "\n")
  cat(paste(rep("=", 60), collapse=""), "\n")
  
  var_data <- data %>%
    filter(!is.na(!!sym(var_name))) %>%
    mutate(
      task = droplevels(task),
      comm = droplevels(comm)
    )
  
  task_counts <- var_data %>%
    group_by(task) %>%
    summarise(n = n(), .groups = "drop")
  
  if(nrow(task_counts) >= 2 && all(task_counts$n >= 3)) {
    tryCatch({
      # Mixed-Effects ANOVA mit Task als Hauptfaktor
      model <- lmer(as.formula(paste(var_name, "~ task + comm + (1|participant.code)")), 
                    data = var_data)
      
      anova_result <- anova(model)
      print(anova_result)
      
      # Effektgröße für Task-Effekt
      task_row <- which(rownames(anova_result) == "task")
      if(length(task_row) > 0) {
        f_stat <- anova_result$`F value`[task_row]
        df1 <- anova_result$NumDF[task_row] 
        df2 <- anova_result$DenDF[task_row]
        p_value <- anova_result$`Pr(>F)`[task_row]
        eta_squared <- f_stat * df1 / (f_stat * df1 + df2)
        
        cat("Task-Effekt - Partielle η² =", round(eta_squared, 3), "\n")
        
        # Post-hoc Tests
        if(p_value < 0.05) {
          cat("\n🔍 SIGNIFIKANTER TASK-EFFEKT!\n")
          emm_task <- emmeans(model, "task")
          pairwise_task <- pairs(emm_task, adjust = "bonferroni")
          
          print("Task-Vergleich:")
          print(pairwise_task)
          
          return(list(model = model, anova = anova_result, emmeans = emm_task,
                     pairwise = pairwise_task, eta_squared = eta_squared, significant = TRUE))
        }
        
        return(list(model = model, anova = anova_result, eta_squared = eta_squared, significant = FALSE))
      }
      
    }, error = function(e) {
      cat("❌ Fehler bei Mixed-Effects Modell:", e$message, "\n")
      return(NULL)
    })
  } else {
    cat("⚠️ Nicht genügend Daten\n")
    return(NULL)
  }
}

# Funktion für Team-Faktoren (einfache ANOVA)
analyze_task_team_variable <- function(var_name, data) {
  cat("\n", paste(rep("=", 60), collapse=""), "\n")
  cat("TASK-VERGLEICH (TEAM-FAKTOREN) FÜR:", toupper(var_name), "\n")
  cat(paste(rep("=", 60), collapse=""), "\n")
  
  var_data <- data %>%
    filter(!is.na(!!sym(var_name))) %>%
    mutate(
      task = droplevels(task),
      comm = droplevels(comm)
    )
  
  task_counts <- var_data %>%
    group_by(task) %>%
    summarise(n = n(), .groups = "drop")
  
  if(nrow(task_counts) >= 2 && all(task_counts$n >= 3)) {
    tryCatch({
      # Einfache ANOVA mit Task und Kommunikation
      model <- aov(as.formula(paste(var_name, "~ task + comm")), data = var_data)
      
      anova_result <- summary(model)
      print(anova_result)
      
      # Effektgröße für Task-Effekt
      if(length(anova_result) > 0 && nrow(anova_result[[1]]) > 0) {
        f_stat <- anova_result[[1]]$`F value`[1]  # Task ist erste Zeile
        df1 <- anova_result[[1]]$Df[1]
        df2 <- anova_result[[1]]$Df[length(anova_result[[1]]$Df)]  # Residuals
        p_value <- anova_result[[1]]$`Pr(>F)`[1]
        
        if(!is.na(f_stat) && !is.na(df1) && !is.na(df2)) {
          eta_squared <- f_stat * df1 / (f_stat * df1 + df2)
          cat("Task-Effekt - Partielle η² =", round(eta_squared, 3), "\n")
          
          # Post-hoc Tests
          if(p_value < 0.05) {
            cat("\n🔍 SIGNIFIKANTER TASK-EFFEKT!\n")
            posthoc <- TukeyHSD(model, "task")
            print(posthoc)
            
            return(list(model = model, anova = anova_result, posthoc = posthoc,
                       eta_squared = eta_squared, significant = TRUE))
          }
          
          return(list(model = model, anova = anova_result, eta_squared = eta_squared, significant = FALSE))
        }
      }
      
    }, error = function(e) {
      cat("❌ Fehler bei ANOVA:", e$message, "\n")
      return(NULL)
    })
  } else {
    cat("⚠️ Nicht genügend Daten\n")
    return(NULL)
  }
}

# ÄNDERUNG 6: Führe getrennte Task-Analysen durch

# Rundenweise Variablen analysieren
task_round_results <- list()
for(var in rundenweise_vars) {
  result <- analyze_task_round_variable(var, task_analysis_data_rounds)
  if(!is.null(result)) {
    task_round_results[[var]] <- result
  }
}

# Team-Faktoren analysieren
task_team_results <- list()
for(var in team_factor_vars) {
  result <- analyze_task_team_variable(var, task_analysis_data_team)
  if(!is.null(result)) {
    task_team_results[[var]] <- result
  }
}

# ================================================================================
# SCHRITT 4: ERWEITERTE ZUSAMMENFASSUNG DER TASK-UNTERSCHIEDE
# ================================================================================

print("\n=== SCHRITT 4: ERWEITERTE ZUSAMMENFASSUNG DER TASK-UNTERSCHIEDE ===")

# Sammle signifikante Variablen
task_significant_round_vars <- names(task_round_results)[sapply(task_round_results, function(x) x$significant)]
task_significant_team_vars <- names(task_team_results)[sapply(task_team_results, function(x) x$significant)]

cat("📊 SIGNIFIKANTE TASK-UNTERSCHIEDE (RUNDENWEISE):\n")
if(length(task_significant_round_vars) > 0) {
  for(var in task_significant_round_vars) {
    eta_sq <- task_round_results[[var]]$eta_squared
    cat("✅", toupper(var), "- η² =", round(eta_sq, 3), "\n")
  }
} else {
  cat("❌ Keine signifikanten rundenweisen Task-Unterschiede\n")
}

cat("\n📊 SIGNIFIKANTE TASK-UNTERSCHIEDE (TEAM-FAKTOREN):\n")
if(length(task_significant_team_vars) > 0) {
  for(var in task_significant_team_vars) {
    eta_sq <- task_team_results[[var]]$eta_squared
    cat("✅", toupper(var), "- η² =", round(eta_sq, 3), "\n")
  }
} else {
  cat("❌ Keine signifikanten Team-Faktoren Task-Unterschiede\n")
}

# Erstelle erweiterte Ergebnistabelle
create_task_results_table <- function() {
  results_df <- data.frame(
    Variable = all_vars,
    Type = ifelse(all_vars %in% rundenweise_vars, "Rundenweise", "Team-Faktoren"),
    stringsAsFactors = FALSE
  )
  
  # Initialisiere Spalten
  results_df$Signifikant <- FALSE
  results_df$Eta_squared <- NA_real_
  results_df$P_value <- NA_real_
  results_df$N_total <- 0
  
  # Rundenweise Ergebnisse
  for(var in names(task_round_results)) {
    idx <- which(results_df$Variable == var)
    result <- task_round_results[[var]]
    
    results_df$Signifikant[idx] <- result$significant
    results_df$Eta_squared[idx] <- round(result$eta_squared, 3)
    
    # P-Wert extrahieren
    task_row <- which(rownames(result$anova) == "task")
    if(length(task_row) > 0) {
      results_df$P_value[idx] <- round(result$anova$`Pr(>F)`[task_row], 4)
    }
    
    # Stichprobengröße
    var_data <- task_analysis_data_rounds %>% filter(!is.na(!!sym(var)))
    results_df$N_total[idx] <- nrow(var_data)
  }
  
  # Team-Faktoren Ergebnisse
  for(var in names(task_team_results)) {
    idx <- which(results_df$Variable == var)
    result <- task_team_results[[var]]
    
    results_df$Signifikant[idx] <- result$significant
    results_df$Eta_squared[idx] <- round(result$eta_squared, 3)
    
    # P-Wert extrahieren
    if(length(result$anova) > 0 && nrow(result$anova[[1]]) > 0) {
      results_df$P_value[idx] <- round(result$anova[[1]]$`Pr(>F)`[1], 4)
    }
    
    # Stichprobengröße
    var_data <- task_analysis_data_team %>% filter(!is.na(!!sym(var)))
    results_df$N_total[idx] <- nrow(var_data)
  }
  
  # Variable Labels hinzufügen
  results_df$Variable_Clean <- variable_labels[results_df$Variable]
  results_df$Variable_Clean <- ifelse(is.na(results_df$Variable_Clean), 
                                     results_df$Variable, results_df$Variable_Clean)
  
  # Sortiere
  results_df <- results_df %>%
    arrange(Type, desc(Signifikant), desc(Eta_squared))
  
  return(results_df)
}

task_results_extended <- create_task_results_table()

print("ERWEITERTE TASK-VERGLEICH ERGEBNISÜBERSICHT:")
print(task_results_extended %>% 
      select(Variable_Clean, Type, Signifikant, P_value, Eta_squared, N_total))

# ================================================================================
# SCHRITT 5: ERWEITERTE BOXPLOTS FÜR TASK-VERGLEICH
# ================================================================================

print("\n=== SCHRITT 5: ERWEITERTE BOXPLOTS FÜR TASK-VERGLEICH ===")

# ÄNDERUNG 7: Bereite erweiterte Plot-Daten vor
prepare_task_plot_data <- function() {
  
  # Rundenweise Daten (aggregiert pro Person)
  round_task_data <- task_analysis_data_rounds %>%
    group_by(participant.code, task, comm) %>%
    summarise(across(all_of(rundenweise_vars), ~ mean(.x, na.rm = TRUE)), .groups = "drop") %>%
    pivot_longer(cols = all_of(rundenweise_vars), names_to = "variable", values_to = "value") %>%
    filter(!is.na(value)) %>%
    mutate(type = "Rundenweise")
  
  # Team-Faktoren Daten
  team_task_data <- task_analysis_data_team %>%
    select(participant.code, task, comm, all_of(team_factor_vars)) %>%
    pivot_longer(cols = all_of(team_factor_vars), names_to = "variable", values_to = "value") %>%
    filter(!is.na(value)) %>%
    mutate(type = "Team-Faktoren")
  
  # Kombiniere beide
  combined_task_data <- bind_rows(round_task_data, team_task_data) %>%
    mutate(
      variable_clean = variable_labels[variable],
      variable_clean = ifelse(is.na(variable_clean), variable, variable_clean)
    )
  
  return(combined_task_data)
}

task_plot_data_extended <- prepare_task_plot_data()

# Erstelle erweiterte Task-Boxplots
create_extended_task_boxplot <- function(var_name, data = task_plot_data_extended) {
  var_data <- data %>% filter(variable == var_name)
  
  if(nrow(var_data) == 0) return(NULL)
  
  var_label <- unique(var_data$variable_clean)[1]
  var_type <- unique(var_data$type)[1]
  
  # Verschiedene Farben für Task-Vergleich
  colors <- c("Math" = "#4A90E2", "HP" = "#E24A4A")
  
  ggplot(var_data, aes(x = task, y = value, fill = task)) +
    geom_boxplot(alpha = 0.7, outlier.size = 1.5) +
    geom_jitter(width = 0.2, alpha = 0.4, size = 1) +
    scale_fill_manual(values = colors) +
    labs(
      title = paste(var_label, paste0("(", var_type, ")")),
      x = "Task Type",
      y = "Value"
    ) +
    theme_minimal() +
    theme(
      plot.title = element_text(size = 11, face = "bold", hjust = 0.5),
      axis.text.x = element_text(size = 11),
      axis.text.y = element_text(size = 10),
      legend.position = "none"
    )
}

# Erstelle alle erweiterten Task-Boxplots
extended_task_boxplots <- list()
for(var in all_vars) {
  if(var %in% unique(task_plot_data_extended$variable)) {
    cat("Erstelle erweiterten Task-Boxplot für:", var, "\n")
    plot <- create_extended_task_boxplot(var, task_plot_data_extended)
    if(!is.null(plot)) {
      extended_task_boxplots[[var]] <- plot
    }
  }
}

# Zeige alle Plots
if(length(extended_task_boxplots) > 0) {
  n_plots <- length(extended_task_boxplots)
  ncol <- min(6, ceiling(sqrt(n_plots)))
  nrow <- ceiling(n_plots / ncol)
  
  grid.arrange(grobs = extended_task_boxplots, ncol = ncol, nrow = nrow,
               top = "Extended Task Comparison: Math vs Hidden Profile (All Variables)")
}

# ================================================================================
# SCHRITT 6: TEAM-FAKTOREN PROFIL-PLOT MIT BOXPLOTS (WIE IN DEINEM BILD)
# ================================================================================
print("\n=== SCHRITT 6: TEAM-FAKTOREN PROFIL-PLOT ===")

create_task_team_profile_plot <- function(data) {
  
  # Bereite Daten für Boxplot vor (ohne Aggregation - wir brauchen alle Einzelwerte)
  profile_data <- data %>%
    pivot_longer(cols = all_of(team_factor_vars), names_to = "factor", values_to = "score") %>%
    filter(!is.na(score)) %>%
    mutate(
      factor_clean = variable_labels[factor],
      factor_clean = ifelse(is.na(factor_clean), factor, factor_clean),
      # Gruppiere Faktoren nach Kategorien (wie in deinem Bild)
      category = case_when(
        factor %in% c("interdependence_value", "common_goal_value", "means_coordination_value") ~ "Flow Pre-Conditions\n(in Teams)",
        factor %in% c("group_size_value", "group_diversity_value", "group_skill_value", "team_composition_value") ~ "Team Composition",
        factor %in% c("communication_required_value", "work_independence_value", "social_presence_value", "perceived_task_complexity_value") ~ "Team Interaction\nExperience",
        TRUE ~ "Other"
      ),
      # Kürze die Faktornamen für bessere Lesbarkeit
      factor_clean = case_when(
        factor_clean == "Clear Goal &\nProcess" ~ "Clear Goal &\nProcess",
        factor_clean == "Coordination\nPossible" ~ "Coordination\nPossible", 
        factor_clean == "Mutual\nDependence" ~ "Mutual\nDependence",
        factor_clean == "Group Size\nJust Right" ~ "Group Size\nJust Right",
        factor_clean == "Adequate Perspective\nDiversity" ~ "Adequate Perspective\nDiversity",
        factor_clean == "Complementary\nSkills" ~ "Complementary\nSkills",
        factor_clean == "Communication\nRequired" ~ "Communication\nRequired",
        factor_clean == "Social\nPresence" ~ "Social\nPresence",
        TRUE ~ factor_clean
      )
    ) %>%
    filter(category != "Other")  # Entferne nicht kategorisierte Faktoren
  
  # Berechne Mittelwerte für die Beschriftung
  mean_data <- profile_data %>%
    group_by(factor_clean, task, category) %>%
    summarise(mean_score = mean(score, na.rm = TRUE), .groups = "drop")
  
  # Erstelle den Boxplot im Stil deines Bildes
  ggplot(profile_data, aes(x = factor_clean, y = score, fill = task)) +
    geom_boxplot(position = position_dodge(width = 0.6), 
                 alpha = 0.7, 
                 outlier.shape = 16,
                 outlier.size = 1.5,
                 width = 0.6) +
    # Füge Mittelwerte als Text hinzu (feste Position über den Boxplots)
    geom_text(data = mean_data, 
              aes(x = factor_clean, y = mean_score, label = round(mean_score, 1)),
              position = position_dodge(width = 0.6), 
              vjust = 0.5, 
              size = 2.0, 
              fontface = "bold",
              color = "black") +
    facet_wrap(~ category, scales = "free_x", ncol = 3, labeller = label_wrap_gen(width = 20)) +
    scale_fill_manual(values = c("Math" = "#2E86AB", "HP" = "#A23B72"),
                      labels = c("Math Task", "Hidden Profile Task")) +
    scale_y_continuous(limits = c(1, 7), breaks = 1:7) +
    labs(
      title = "Perceptions of the group task",
      x = "Self-Reported Construct",
      y = "Response (7Pt-Likert)",
      fill = "Task Type",
      caption = "Figure 12: Perceptions of the task format. Crosshairs and numbers show mean averages."
    ) +
    theme_minimal() +
    theme(
      # Schräge x-Achsen-Labels zur Vermeidung von Überlappungen
      axis.text.x = element_text(angle = 45, hjust = 1, size = 7, lineheight = 0.9),
      axis.text.y = element_text(size = 8),
      axis.title.x = element_text(size = 9, face = "bold", margin = margin(t = 8)),
      axis.title.y = element_text(size = 9, face = "bold"),
      
      # Facet-Styling mit kleinerer Schrift
      strip.text = element_text(size = 8, face = "bold", margin = margin(4,4,4,4)),
      strip.background = element_rect(fill = "gray90", color = "black", size = 0.5),
      
      # Plot-Titel und Caption
      plot.title = element_text(size = 11, face = "bold", hjust = 0.5, margin = margin(b = 8)),
      plot.caption = element_text(size = 7, hjust = 0.5, face = "italic", margin = margin(t = 8)),
      
      # Legende mit kleinerer Schrift
      legend.position = "bottom",
      legend.title = element_text(size = 8, face = "bold"),
      legend.text = element_text(size = 7),
      legend.margin = margin(t = 10),
      
      # Grid-Linien
      panel.grid.minor = element_blank(),
      panel.grid.major.x = element_blank(),
      panel.grid.major.y = element_line(color = "gray90", size = 0.3),
      
      # Gesamt-Layout
      plot.margin = margin(10, 10, 10, 10),
      panel.spacing = unit(1, "lines")  # Mehr Platz zwischen Facets
    )
}

# Erstelle den Team-Faktoren Profil-Plot
if(nrow(task_analysis_data_team) > 0) {
  team_profile_plot <- create_task_team_profile_plot(task_analysis_data_team)
  
  # Optional: Speichere den Plot in höherer Auflösung
  ggsave("team_profile_boxplot.png", team_profile_plot, 
         width = 14, height = 8, dpi = 300, bg = "white")
  
  print(team_profile_plot)
}
# ================================================================================
# SCHRITT 7: FINALE EMPFEHLUNGEN FÜR ERWEITERTE TASK-UNTERSCHIEDE
# ================================================================================

cat("\n", paste(rep("=", 80), collapse=""), "\n")
cat("EMPFEHLUNGEN FÜR ERWEITERTE TASK-UNTERSCHIEDE ANALYSE\n")
cat(paste(rep("=", 80), collapse=""), "\n")

total_significant <- length(task_significant_round_vars) + length(task_significant_team_vars)

if(total_significant > 0) {
  cat("✅ Du hast", total_significant, "signifikante Task-Unterschiede gefunden!\n\n")
  cat("Interpretation:\n")
  cat("• Math und HP Tasks unterscheiden sich in wichtigen Aspekten\n")
  cat("• Diese Unterschiede zeigen sich sowohl in rundenweisen als auch Team-Faktoren\n")
  cat("• Task-spezifische Mediationen sind wahrscheinlich\n\n")
  cat("Nächste Schritte:\n")
  cat("1. 🎯 Fokussiere auf die", total_significant, "signifikanten Variablen für Mediationsanalysen\n")
  cat("2. 📊 Führe separate Analysen pro Task durch\n") 
  cat("3. 🔍 Prüfe Task × Communication Interaktionen\n")
  cat("4. 📈 Verwende Task als Moderator in deinen Modellen\n")
} else {
  cat("ℹ️ Keine signifikanten Task-Unterschiede in den erweiterten Variablen gefunden.\n\n")
  cat("Interpretation:\n")
  cat("• Math und HP Tasks wirken ähnlich auf diese Faktoren\n")
  cat("• Kommunikationseffekte sind vermutlich task-unabhängig\n")
  cat("• Focus kann auf Kommunikationsformen gelegt werden\n\n")
  cat("Empfehlungen:\n")
  cat("1. 🎯 Kombiniere beide Tasks für mehr statistische Power\n")
  cat("2. 📈 Fokussiere primär auf Kommunikationseffekte\n")
  cat("3. 🔍 Prüfe ob kleine Task-Unterschiede praktisch relevant sind\n")
}

cat("\n📊 VERFÜGBARE ERWEITERTE VARIABLEN:\n")
cat("Rundenweise (", length(rundenweise_vars), "):", paste(rundenweise_vars, collapse=", "), "\n")
cat("Team-Faktoren (", length(team_factor_vars), "):", paste(team_factor_vars, collapse=", "), "\n")

print("🎯 Erweiterte Task-Analyse abgeschlossen!")

# ================================================================================
# 1. DATENVERFÜGBARKEIT PRO VARIABLE PRÜFEN (KORRIGIERT)
# ================================================================================

print("\n1. DATENVERFÜGBARKEIT PRO VARIABLE (KORRIGIERT):")

# Kombiniere rundenweise und Team-Daten für Verfügbarkeitsanalyse
prepare_combined_availability_data <- function() {
  
  # Rundenweise Daten (aggregiert pro Person für Konsistenz)
  round_availability <- task_analysis_data_rounds %>%
    group_by(participant.code, task, comm) %>%
    summarise(across(all_of(rundenweise_vars), ~ mean(.x, na.rm = TRUE)), .groups = "drop") %>%
    mutate(data_source = "rounds")
  
  # Team-Faktoren Daten
  team_availability <- task_analysis_data_team %>%
    select(participant.code, task, comm, all_of(team_factor_vars)) %>%
    mutate(data_source = "team")
  
  # Kombiniere für Verfügbarkeitsanalyse
  combined_data <- bind_rows(
    round_availability %>% select(participant.code, task, comm, all_of(rundenweise_vars), data_source),
    team_availability %>% select(participant.code, task, comm, all_of(team_factor_vars), data_source)
  )
  
  return(combined_data)
}

# Analysiere Datenverfügbarkeit für alle erweiterten Variablen
analyze_data_availability <- function() {
  
  # Rundenweise Verfügbarkeit (ALLE Beobachtungen, nicht aggregiert)
  round_availability <- task_analysis_data_rounds %>%
    select(task, all_of(rundenweise_vars)) %>%
    pivot_longer(cols = all_of(rundenweise_vars), names_to = "variable", values_to = "value") %>%
    group_by(variable, task) %>%
    summarise(
      n_available = sum(!is.na(value)),
      n_missing = sum(is.na(value)),
      pct_available = round(100 * sum(!is.na(value)) / n(), 1),
      data_type = "Rundenweise",
      .groups = "drop"
    )
  
  # Team-Faktoren Verfügbarkeit
  team_availability <- task_analysis_data_team %>%
    select(task, all_of(team_factor_vars)) %>%
    pivot_longer(cols = all_of(team_factor_vars), names_to = "variable", values_to = "value") %>%
    group_by(variable, task) %>%
    summarise(
      n_available = sum(!is.na(value)),
      n_missing = sum(is.na(value)),
      pct_available = round(100 * sum(!is.na(value)) / n(), 1),
      data_type = "Team-Faktoren",
      .groups = "drop"
    )
  
  # Kombiniere beide
  combined_availability <- bind_rows(round_availability, team_availability) %>%
    pivot_wider(names_from = task, values_from = c(n_available, n_missing, pct_available)) %>%
    mutate(
      total_available = n_available_Math + n_available_HP,
      variable_clean = variable_labels[variable],
      variable_clean = ifelse(is.na(variable_clean), variable, variable_clean)
    ) %>%
    arrange(data_type, desc(total_available))
  
  return(combined_availability)
}

data_availability_extended <- analyze_data_availability()

print("Erweiterte Datenverfügbarkeit pro Variable:")
print(data_availability_extended %>% 
      select(variable_clean, data_type, n_available_Math, n_available_HP, 
             total_available, pct_available_Math, pct_available_HP))

# ================================================================================
# 2. KORRIGIERTE EFFEKTGRÖSSEN-BERECHNUNG FÜR ALLE VARIABLEN
# ================================================================================

print("\n2. KORRIGIERTE EFFEKTGRÖSSEN-BERECHNUNG FÜR ALLE VARIABLEN:")

# Funktion für Effektgrößenberechnung (rundenweise Variablen)
calculate_round_effect_sizes <- function(var, data = task_analysis_data_rounds) {
  
  cat("\n--- ANALYSE FÜR (RUNDENWEISE):", var, "---\n")
  
  # Verwende ALLE Einzelbeobachtungen (wie in ursprünglicher Analyse)
  var_data <- data %>%
    filter(!is.na(!!sym(var))) %>%
    mutate(
      task = droplevels(task),
      comm = droplevels(comm),
      value = !!sym(var)  # Direkte Verwendung der Variable
    )
  
  # Prüfe Stichprobengröße
  task_counts <- var_data %>%
    group_by(task) %>%
    summarise(n = n(), .groups = "drop")
  
  cat("Stichprobengrößen:\n")
  print(task_counts)
  
  if(nrow(task_counts) >= 2 && all(task_counts$n >= 3)) {
    
    tryCatch({
      # Mixed-Effects Modell
      model <- lmer(value ~ task + comm + (1|participant.code), data = var_data)
      
      anova_result <- anova(model)
      
      # Finde Task-Effekt
      task_row <- which(rownames(anova_result) == "task")
      
      if(length(task_row) > 0) {
        f_stat <- anova_result$`F value`[task_row]
        df1 <- anova_result$NumDF[task_row] 
        df2 <- anova_result$DenDF[task_row]
        p_value <- anova_result$`Pr(>F)`[task_row]
        
        # Partielle Eta-Quadrat
        eta_squared <- f_stat * df1 / (f_stat * df1 + df2)
        
        # Cohen's d
        means_by_task <- var_data %>%
          group_by(task) %>%
          summarise(mean_val = mean(value, na.rm = TRUE),
                   sd_val = sd(value, na.rm = TRUE),
                   n = n(), .groups = "drop")
        
        if(nrow(means_by_task) == 2) {
          pooled_sd <- sqrt(((means_by_task$n[1] - 1) * means_by_task$sd_val[1]^2 + 
                            (means_by_task$n[2] - 1) * means_by_task$sd_val[2]^2) / 
                           (means_by_task$n[1] + means_by_task$n[2] - 2))
          
          cohens_d <- abs(means_by_task$mean_val[1] - means_by_task$mean_val[2]) / pooled_sd
        } else {
          cohens_d <- NA
        }
        
        cat("F-Statistik:", round(f_stat, 3), "\n")
        cat("p-Wert:", round(p_value, 4), "\n") 
        cat("Partielle η²:", round(eta_squared, 3), "\n")
        cat("Cohen's d:", round(cohens_d, 3), "\n")
        cat("Gesamt-n:", sum(task_counts$n), "\n")
        
        if(p_value < 0.05) {
          cat("✅ SIGNIFIKANT\n")
        } else {
          cat("❌ NICHT SIGNIFIKANT\n")
        }
        
        return(list(
          eta_squared = eta_squared,
          cohens_d = cohens_d,
          f_stat = f_stat,
          p_value = p_value,
          total_n = sum(task_counts$n),
          data_type = "Rundenweise"
        ))
      }
      
    }, error = function(e) {
      cat("❌ Fehler bei Modell:", e$message, "\n")
      return(NULL)
    })
  } else {
    cat("⚠️ ZU WENIG DATEN\n")
    return(NULL)
  }
}

# Funktion für Effektgrößenberechnung (Team-Faktoren)
calculate_team_effect_sizes <- function(var, data = task_analysis_data_team) {
  
  cat("\n--- ANALYSE FÜR (TEAM-FAKTOREN):", var, "---\n")
  
  var_data <- data %>%
    filter(!is.na(!!sym(var))) %>%
    mutate(
      task = droplevels(task),
      comm = droplevels(comm)
    )
  
  # Prüfe Stichprobengröße
  task_counts <- var_data %>%
    group_by(task) %>%
    summarise(n = n(), .groups = "drop")
  
  cat("Stichprobengrößen:\n")
  print(task_counts)
  
  if(nrow(task_counts) >= 2 && all(task_counts$n >= 3)) {
    
    tryCatch({
      # Einfache ANOVA
      model <- aov(as.formula(paste(var, "~ task + comm")), data = var_data)
      
      anova_result <- summary(model)
      
      if(length(anova_result) > 0 && nrow(anova_result[[1]]) > 0) {
        f_stat <- anova_result[[1]]$`F value`[1]  # Task ist erste Zeile
        df1 <- anova_result[[1]]$Df[1]
        df2 <- anova_result[[1]]$Df[length(anova_result[[1]]$Df)]  # Residuals
        p_value <- anova_result[[1]]$`Pr(>F)`[1]
        
        if(!is.na(f_stat) && !is.na(df1) && !is.na(df2)) {
          # Partielle Eta-Quadrat
          eta_squared <- f_stat * df1 / (f_stat * df1 + df2)
          
          # Cohen's d
          means_by_task <- var_data %>%
            group_by(task) %>%
            summarise(mean_val = mean(!!sym(var), na.rm = TRUE),
                     sd_val = sd(!!sym(var), na.rm = TRUE),
                     n = n(), .groups = "drop")
          
          if(nrow(means_by_task) == 2) {
            pooled_sd <- sqrt(((means_by_task$n[1] - 1) * means_by_task$sd_val[1]^2 + 
                              (means_by_task$n[2] - 1) * means_by_task$sd_val[2]^2) / 
                             (means_by_task$n[1] + means_by_task$n[2] - 2))
            
            cohens_d <- abs(means_by_task$mean_val[1] - means_by_task$mean_val[2]) / pooled_sd
          } else {
            cohens_d <- NA
          }
          
          cat("F-Statistik:", round(f_stat, 3), "\n")
          cat("p-Wert:", round(p_value, 4), "\n") 
          cat("Partielle η²:", round(eta_squared, 3), "\n")
          cat("Cohen's d:", round(cohens_d, 3), "\n")
          cat("Gesamt-n:", sum(task_counts$n), "\n")
          
          if(p_value < 0.05) {
            cat("✅ SIGNIFIKANT\n")
          } else {
            cat("❌ NICHT SIGNIFIKANT\n")
          }
          
          return(list(
            eta_squared = eta_squared,
            cohens_d = cohens_d,
            f_stat = f_stat,
            p_value = p_value,
            total_n = sum(task_counts$n),
            data_type = "Team-Faktoren"
          ))
        }
      }
      
    }, error = function(e) {
      cat("❌ Fehler bei Modell:", e$message, "\n")
      return(NULL)
    })
  } else {
    cat("⚠️ ZU WENIG DATEN\n")
    return(NULL)
  }
}

# Berechne Effektgrößen für alle erweiterten Variablen
extended_effect_sizes <- list()

# Rundenweise Variablen
for(var in rundenweise_vars) {
  result <- calculate_round_effect_sizes(var)
  if(!is.null(result)) {
    extended_effect_sizes[[var]] <- result
  }
}

# Team-Faktoren
for(var in team_factor_vars) {
  result <- calculate_team_effect_sizes(var)
  if(!is.null(result)) {
    extended_effect_sizes[[var]] <- result
  }
}

# ================================================================================
# 3. ERWEITERTE ZUSAMMENFASSUNG UND KORREKTUR
# ================================================================================

print("\n3. ERWEITERTE ZUSAMMENFASSUNG UND KORREKTUR:")

# Erstelle erweiterte korrigierte Ergebnistabelle
create_extended_results_table <- function() {
  
  extended_results <- data.frame(
    Variable = all_vars,
    stringsAsFactors = FALSE
  )
  
  # Datentyp hinzufügen
  extended_results$Data_Type <- ifelse(extended_results$Variable %in% rundenweise_vars, 
                                      "Rundenweise", "Team-Faktoren")
  
  # Initialisiere Spalten
  extended_results$N_total <- 0
  extended_results$Eta_squared <- NA_real_
  extended_results$Cohens_d <- NA_real_
  extended_results$P_value <- NA_real_
  extended_results$F_stat <- NA_real_
  
  # Fülle Ergebnisse
  for(var in names(extended_effect_sizes)) {
    idx <- which(extended_results$Variable == var)
    result <- extended_effect_sizes[[var]]
    
    extended_results$N_total[idx] <- result$total_n
    extended_results$Eta_squared[idx] <- round(result$eta_squared, 3)
    extended_results$Cohens_d[idx] <- round(result$cohens_d, 3)
    extended_results$P_value[idx] <- round(result$p_value, 4)
    extended_results$F_stat[idx] <- round(result$f_stat, 3)
  }
  
  # Berechne Zuverlässigkeitsindikatoren
  extended_results$Signifikant <- extended_results$P_value < 0.05 & !is.na(extended_results$P_value)
  extended_results$Reliable <- extended_results$N_total >= 20 & 
                               (extended_results$Eta_squared < 0.9 | is.na(extended_results$Eta_squared))
  
  # Variable Labels hinzufügen
  extended_results$Variable_Clean <- variable_labels[extended_results$Variable]
  extended_results$Variable_Clean <- ifelse(is.na(extended_results$Variable_Clean), 
                                           extended_results$Variable, 
                                           extended_results$Variable_Clean)
  
  # Sortiere nach Typ, Zuverlässigkeit und Effektgröße
  extended_results <- extended_results %>%
    arrange(Data_Type, desc(Reliable), desc(Signifikant), desc(Eta_squared))
  
  return(extended_results)
}

extended_corrected_results <- create_extended_results_table()

print("ERWEITERTE KORRIGIERTE ERGEBNISTABELLE:")
print(extended_corrected_results %>%
      select(Variable_Clean, Data_Type, N_total, Signifikant, P_value, 
             Eta_squared, Cohens_d, Reliable))

# ================================================================================
# 4. ERWEITERTE INTERPRETATION UND EMPFEHLUNGEN
# ================================================================================

cat("\n", paste(rep("=", 80), collapse=""), "\n")
cat("ERWEITERTE INTERPRETATION DER EFFEKTGRÖSSEN\n")
cat(paste(rep("=", 80), collapse=""), "\n")

# Kategorisiere Ergebnisse
reliable_round_vars <- extended_corrected_results$Variable[
  extended_corrected_results$Data_Type == "Rundenweise" & 
  extended_corrected_results$Reliable & 
  !is.na(extended_corrected_results$Reliable)]

reliable_team_vars <- extended_corrected_results$Variable[
  extended_corrected_results$Data_Type == "Team-Faktoren" & 
  extended_corrected_results$Reliable & 
  !is.na(extended_corrected_results$Reliable)]

significant_vars <- extended_corrected_results$Variable[
  extended_corrected_results$Signifikant & 
  !is.na(extended_corrected_results$Signifikant)]

unreliable_vars <- extended_corrected_results$Variable[
  !extended_corrected_results$Reliable & 
  !is.na(extended_corrected_results$Reliable)]

cat("📊 ÜBERSICHT ALLER ERWEITERTEN VARIABLEN:\n")
cat("- Rundenweise Variablen:", length(rundenweise_vars), "\n")
cat("- Team-Faktoren:", length(team_factor_vars), "\n")
cat("- Gesamt analysiert:", length(extended_effect_sizes), "\n\n")

if(length(reliable_round_vars) > 0) {
  cat("✅ ZUVERLÄSSIGE RUNDENWEISE ERGEBNISSE:\n")
  for(var in reliable_round_vars) {
    row <- extended_corrected_results[extended_corrected_results$Variable == var, ]
    sig_marker <- ifelse(row$Signifikant, "***", "")
    cat("  -", row$Variable_Clean, ": η²=", row$Eta_squared, ", d=", row$Cohens_d, 
        ", p=", row$P_value, sig_marker, "\n")
  }
  cat("\n")
}

if(length(reliable_team_vars) > 0) {
  cat("✅ ZUVERLÄSSIGE TEAM-FAKTOREN ERGEBNISSE:\n")
  for(var in reliable_team_vars) {
    row <- extended_corrected_results[extended_corrected_results$Variable == var, ]
    sig_marker <- ifelse(row$Signifikant, "***", "")
    cat("  -", row$Variable_Clean, ": η²=", row$Eta_squared, ", d=", row$Cohens_d, 
        ", p=", row$P_value, sig_marker, "\n")
  }
  cat("\n")
}

if(length(significant_vars) > 0) {
  cat("🎯 SIGNIFIKANTE TASK-UNTERSCHIEDE (alle Typen):\n")
  for(var in significant_vars) {
    row <- extended_corrected_results[extended_corrected_results$Variable == var, ]
    cat("  -", row$Variable_Clean, "(", row$Data_Type, "): p=", row$P_value, "\n")
  }
  cat("\n")
}

if(length(unreliable_vars) > 0) {
  cat("⚠️ UNZUVERLÄSSIGE ERGEBNISSE (zu wenig Daten oder extreme Effektgrößen):\n")
  for(var in unreliable_vars) {
    row <- extended_corrected_results[extended_corrected_results$Variable == var, ]
    cat("  -", row$Variable_Clean, ": n=", row$N_total, ", η²=", row$Eta_squared, "\n")
  }
  cat("\n")
}

cat("💡 AKTUALISIERTE EMPFEHLUNGEN:\n")
cat("1. 🎯 Fokussiere auf", length(c(reliable_round_vars, reliable_team_vars)), "zuverlässige Variablen\n")
cat("2. 📈 Verwende", length(significant_vars), "signifikante Variablen für Mediationsanalysen\n")
cat("3. 🔍 Sammle mehr Daten für", length(unreliable_vars), "unzuverlässige Variablen\n")
cat("4. 📊 Getrennte Analysen für rundenweise vs. Team-Faktoren durchführen\n")
cat("5. 🎨 Visualisierungen nur für zuverlässige Ergebnisse erstellen\n\n")

print("Erweiterte Effektgrößen-Analyse abgeschlossen! 🔍")
```

Mixed Design Analysis - HP/Video vs. HP/Chat vs. Math/Video vs. Math/Chat

```{r}
# ================================================================================
# 4-TREATMENT MIXED-DESIGN ANALYSE: HP-Video, HP-Chat, Math-Video, Math-Chat
# Mixed Design: Communication (Between-Subjects) × Task (Within-Subjects)
# Nur Team-Faktoren aus dem zweiten Experiment
# ================================================================================

library(dplyr)
library(tidyr)
library(ggplot2)
library(lme4)
library(lmerTest)
library(car)
library(emmeans)
library(effectsize)
library(gridExtra)
library(broom)
library(broom.mixed)
library(RColorBrewer)

# ================================================================================
# SCHRITT 1: DATENAUFBEREITUNG FÜR MIXED-DESIGN ANALYSE
# ================================================================================

print("=== SCHRITT 1: MIXED-DESIGN DATENAUFBEREITUNG (NUR TEAM-FAKTOREN) ===")

# Definiere nur Team-Faktoren (keine rundenweisen Variablen)
team_factor_vars <- c(
  "team_composition_value", "team_motivation_value", "interdependence_value", 
  "common_goal_value", "means_coordination_value",
  "group_size_value", "group_diversity_value", "group_skill_value",
  "communication_required_value", "work_independence_value", "social_presence_value", "perceived_task_complexity_value"
)

# Variable Labels für schönere Plots
variable_labels <- c(
  "team_composition_value" = "Team Composition",
  "team_motivation_value" = "Team Motivation",
  "interdependence_value" = "Mutual Dependence",
  "common_goal_value" = "Clear Goal Process",
  "means_coordination_value" = "Coordination Possible",
  "group_size_value" = "Group Size Just Right",
  "group_diversity_value" = "Adequate Perspective Diversity",
  "group_skill_value" = "Complementary Skills",
  "communication_required_value" = "Communication Required",
  "work_independence_value" = "Work Independence",
  "social_presence_value" = "Social Presence",
  "perceived_task_complexity_value" = "Perceived Task Complexity"
)

# DATENFILTERUNG: Nur zweites Experiment (Team-Faktoren, Post-Round)
mixed_design_data <- integrated_data_full %>%
  filter(
    !is.na(perceived_task_complexity_value),  # Nur zweites Experiment
    round == "Post",  # Nur Post-Runden für Team-Faktoren
    comm %in% c("Together_Chat", "Together_Jitsi"),  # Nur relevante Kommunikationsformen
    task %in% c("Math", "HP")  # Beide Tasks
  ) %>%
  mutate(
    task = factor(task, levels = c("Math", "HP")),
    comm = factor(comm, levels = c("Together_Chat", "Together_Jitsi"), 
                  labels = c("Chat", "Video")),  # Schönere Labels
    # Erstelle 4-Treatment Variable für Visualisierung
    treatment = factor(paste(task, comm, sep = "-"),
                      levels = c("Math-Chat", "Math-Video", "HP-Chat", "HP-Video")),
    participant.code = factor(participant.code)
  ) %>%
  filter(rowSums(is.na(select(., all_of(team_factor_vars)))) <= 5)  # Max 50% fehlende Werte

print(paste("Mixed-Design Daten:", nrow(mixed_design_data), "Beobachtungen"))

# Prüfe das Design: Within-Subjects (Task) und Between-Subjects (Communication)
design_check <- mixed_design_data %>%
  group_by(participant.code) %>%
  summarise(
    n_tasks = n_distinct(task),
    n_comms = n_distinct(comm),
    comm_type = first(comm),
    .groups = "drop"
  )

cat("DESIGN VALIDATION:\n")
cat("- Personen mit beiden Tasks (Within-Subjects):", sum(design_check$n_tasks == 2), "\n")
cat("- Personen mit nur einem Task:", sum(design_check$n_tasks == 1), "\n")
cat("- Personen mit beiden Comm-Formen (sollte 0 sein):", sum(design_check$n_comms == 2), "\n")

comm_distribution <- table(design_check$comm_type)
cat("- Between-Subjects Verteilung:\n")
print(comm_distribution)

# Übersicht der 4 Treatments
treatment_overview <- mixed_design_data %>%
  group_by(treatment, task, comm) %>%
  summarise(
    n_participants = n_distinct(participant.code),
    n_observations = n(),
    .groups = "drop"
  )

print("\n4-Treatment Übersicht (Mixed-Design):")
print(treatment_overview)

# ================================================================================
# SCHRITT 2: MIXED-EFFECTS 2x2 ANOVA FÜR JEDE TEAM-FAKTOR VARIABLE
# ================================================================================

print("\n=== SCHRITT 2: MIXED-EFFECTS 2x2 ANOVA ANALYSE ===")

analyze_mixed_design_variable <- function(var_name, data) {
  cat("\n", paste(rep("=", 60), collapse=""), "\n")
  cat("MIXED-DESIGN 2x2 ANOVA FÜR:", toupper(var_name), "\n")
  cat(paste(rep("=", 60), collapse=""), "\n")
  
  var_data <- data %>%
    filter(!is.na(!!sym(var_name))) %>%
    mutate(
      treatment = droplevels(treatment),
      task = droplevels(task),
      comm = droplevels(comm)
    )
  
  # Prüfe Stichprobengrößen pro Treatment
  treatment_counts <- var_data %>%
    group_by(treatment) %>%
    summarise(n = n(), .groups = "drop")
  
  cat("Stichprobengrößen pro Treatment:\n")
  print(treatment_counts)
  
  # Prüfe ob genügend Daten für alle Treatments
  if(nrow(treatment_counts) >= 4 && all(treatment_counts$n >= 3)) {
    tryCatch({
      # Mixed-Effects ANOVA: Communication (Between) × Task (Within) + Random Effect
      model <- lmer(as.formula(paste(var_name, "~ task * comm + (1|participant.code)")), 
                    data = var_data)
      
      anova_result <- anova(model)
      print(anova_result)
      
      # Erstelle Effekte-Zusammenfassung
      effects_summary <- data.frame(
        Effect = rownames(anova_result),
        F_value = round(anova_result$`F value`, 3),
        NumDF = anova_result$NumDF,
        DenDF = round(anova_result$DenDF, 1),
        p_value = round(anova_result$`Pr(>F)`, 4),
        stringsAsFactors = FALSE
      )
      
      # Berechne partielle η² für jeden Effekt
      effects_summary$eta_squared <- NA
      for(i in 1:nrow(effects_summary)) {
        f_stat <- anova_result$`F value`[i]
        df1 <- anova_result$NumDF[i] 
        df2 <- anova_result$DenDF[i]
        
        if(!is.na(f_stat) && !is.na(df1) && !is.na(df2)) {
          eta_squared <- f_stat * df1 / (f_stat * df1 + df2)
          effects_summary$eta_squared[i] <- round(eta_squared, 3)
        }
      }
      
      cat("\nEFFEKTGRÖSSEN:\n")
      print(effects_summary)
      
      # Klassifiziere Effektgrößen
      for(i in 1:nrow(effects_summary)) {
        effect_name <- effects_summary$Effect[i]
        eta2 <- effects_summary$eta_squared[i]
        p_val <- effects_summary$p_value[i]
        
        significance <- ifelse(p_val < 0.001, "***", 
                              ifelse(p_val < 0.01, "**", 
                                    ifelse(p_val < 0.05, "*", "ns")))
        
        effect_size <- ifelse(is.na(eta2), "NA",
                             ifelse(eta2 < 0.01, "trivial",
                                   ifelse(eta2 < 0.06, "small", 
                                         ifelse(eta2 < 0.14, "medium", "large"))))
        
        cat("  ", effect_name, ": η² =", eta2, "(", effect_size, "),", 
            "p =", p_val, significance, "\n")
      }
      
      # Post-hoc Tests wenn signifikant
      significant_effects <- effects_summary$Effect[effects_summary$p_value < 0.05]
      
      if(length(significant_effects) > 0) {
        cat("\n🔍 SIGNIFIKANTE EFFEKTE:", paste(significant_effects, collapse = ", "), "\n")
        
        # Estimated Marginal Means für alle Treatments
        emm_treatment <- emmeans(model, ~ task * comm)
        
        cat("\nEstimated Marginal Means:\n")
        print(emm_treatment)
        
        # Paarweise Vergleiche zwischen allen 4 Treatments
        pairwise_treatment <- pairs(emm_treatment, adjust = "bonferroni")
        
        cat("\nPaarweise Treatment-Vergleiche (Bonferroni-korrigiert):\n")
        print(pairwise_treatment)
        
        # Haupteffekt-Vergleiche wenn signifikant
        if("task" %in% significant_effects) {
          emm_task <- emmeans(model, "task")
          cat("\nTask-Haupteffekt:\n")
          print(pairs(emm_task))
        }
        
        if("comm" %in% significant_effects) {
          emm_comm <- emmeans(model, "comm")
          cat("\nCommunication-Haupteffekt:\n")
          print(pairs(emm_comm))
        }
        
        return(list(
          model = model, 
          anova = anova_result, 
          effects_summary = effects_summary,
          emmeans = emm_treatment,
          pairwise = pairwise_treatment, 
          significant = TRUE,
          significant_effects = significant_effects
        ))
      }
      
      return(list(
        model = model, 
        anova = anova_result, 
        effects_summary = effects_summary,
        significant = FALSE,
        significant_effects = c()
      ))
      
    }, error = function(e) {
      cat("❌ Fehler bei Mixed-Effects ANOVA:", e$message, "\n")
      
      # Fallback: Einfache ANOVA wenn Mixed-Effects fehlschlägt
      tryCatch({
        cat("Versuche einfache ANOVA als Fallback...\n")
        simple_model <- aov(as.formula(paste(var_name, "~ task * comm")), data = var_data)
        simple_anova <- summary(simple_model)
        print(simple_anova)
        
        return(list(
          model = simple_model,
          anova = simple_anova,
          fallback = TRUE,
          significant = FALSE
        ))
      }, error = function(e2) {
        cat("❌ Auch einfache ANOVA fehlgeschlagen:", e2$message, "\n")
        return(NULL)
      })
    })
  } else {
    cat("⚠️ Nicht genügend Daten für alle 4 Treatments\n")
    print(treatment_counts)
    return(NULL)
  }
}

# Führe Mixed-Design Analysen für alle Team-Faktoren durch
mixed_design_results <- list()
for(var in team_factor_vars) {
  result <- analyze_mixed_design_variable(var, mixed_design_data)
  if(!is.null(result)) {
    mixed_design_results[[var]] <- result
  }
}

# ================================================================================
# SCHRITT 3: ERGEBNISTABELLE ERSTELLEN
# ================================================================================

print("\n=== SCHRITT 3: MIXED-DESIGN ERGEBNISTABELLE ===")

create_mixed_design_results_table <- function() {
  
  results_df <- data.frame(
    Variable = team_factor_vars,
    stringsAsFactors = FALSE
  )
  
  # Initialisiere Spalten für alle Effekte
  results_df$N_total <- 0
  results_df$N_treatments <- 0
  results_df$Task_F <- NA_real_
  results_df$Task_eta2 <- NA_real_
  results_df$Task_p <- NA_real_
  results_df$Comm_F <- NA_real_
  results_df$Comm_eta2 <- NA_real_
  results_df$Comm_p <- NA_real_
  results_df$Interaction_F <- NA_real_
  results_df$Interaction_eta2 <- NA_real_
  results_df$Interaction_p <- NA_real_
  results_df$Any_Significant <- FALSE
  results_df$Analysis_Type <- "Mixed-Effects ANOVA"
  
  # Fülle Ergebnisse für jede Variable
  for(var in names(mixed_design_results)) {
    idx <- which(results_df$Variable == var)
    result <- mixed_design_results[[var]]
    
    if(!is.null(result$effects_summary) && !is.null(result$fallback)) {
      # Fallback auf einfache ANOVA
      results_df$Analysis_Type[idx] <- "Simple ANOVA (Fallback)"
    }
    
    if(!is.null(result$effects_summary)) {
      effects <- result$effects_summary
      
      # Task Effekt
      task_row <- which(effects$Effect == "task")
      if(length(task_row) > 0) {
        results_df$Task_F[idx] <- effects$F_value[task_row]
        results_df$Task_eta2[idx] <- effects$eta_squared[task_row]
        results_df$Task_p[idx] <- effects$p_value[task_row]
      }
      
      # Communication Effekt
      comm_row <- which(effects$Effect == "comm")
      if(length(comm_row) > 0) {
        results_df$Comm_F[idx] <- effects$F_value[comm_row]
        results_df$Comm_eta2[idx] <- effects$eta_squared[comm_row]
        results_df$Comm_p[idx] <- effects$p_value[comm_row]
      }
      
      # Interaktion
      int_row <- which(effects$Effect == "task:comm")
      if(length(int_row) > 0) {
        results_df$Interaction_F[idx] <- effects$F_value[int_row]
        results_df$Interaction_eta2[idx] <- effects$eta_squared[int_row]
        results_df$Interaction_p[idx] <- effects$p_value[int_row]
      }
      
      results_df$Any_Significant[idx] <- result$significant
    }
    
    # Stichprobengrößen
    var_data <- mixed_design_data %>% filter(!is.na(!!sym(var)))
    results_df$N_total[idx] <- nrow(var_data)
    results_df$N_treatments[idx] <- var_data %>% 
      summarise(n_treatments = n_distinct(treatment)) %>% 
      pull(n_treatments)
  }
  
  # Variable Labels
  results_df$Variable_Clean <- variable_labels[results_df$Variable]
  results_df$Variable_Clean <- ifelse(is.na(results_df$Variable_Clean), 
                                     results_df$Variable, results_df$Variable_Clean)
  
  # Sortiere nach Signifikanz und Task-Effektgröße
  results_df <- results_df %>%
    arrange(desc(Any_Significant), desc(Task_eta2))
  
  return(results_df)
}

mixed_design_results_table <- create_mixed_design_results_table()

print("MIXED-DESIGN FACTORIAL ERGEBNISTABELLE:")
print(mixed_design_results_table %>%
      select(Variable_Clean, N_total, Any_Significant, Analysis_Type,
             Task_p, Task_eta2, Comm_p, Comm_eta2, 
             Interaction_p, Interaction_eta2))

# ================================================================================
# SCHRITT 4: 4-TREATMENT BOXPLOTS
# ================================================================================

print("\n=== SCHRITT 4: 4-TREATMENT BOXPLOTS (MIXED-DESIGN) ===")

# Bereite Plot-Daten vor
prepare_mixed_design_plot_data <- function() {
  
  plot_data <- mixed_design_data %>%
    select(participant.code, treatment, task, comm, all_of(team_factor_vars)) %>%
    pivot_longer(cols = all_of(team_factor_vars), names_to = "variable", values_to = "value") %>%
    filter(!is.na(value)) %>%
    mutate(
      variable_clean = variable_labels[variable],
      variable_clean = ifelse(is.na(variable_clean), variable, variable_clean)
    )
  
  return(plot_data)
}

mixed_design_plot_data <- prepare_mixed_design_plot_data()

# Erstelle 4-Treatment Boxplot Funktion
create_mixed_design_boxplot <- function(var_name, data = mixed_design_plot_data) {
  var_data <- data %>% filter(variable == var_name)
  
  if(nrow(var_data) == 0) return(NULL)
  
  var_label <- unique(var_data$variable_clean)[1]
  
  # Gruppiere nach Task, mit Communication nebeneinander
  # 2 Farben für Tasks, verschiedene Transparenz/Muster für Communication
  colors <- c("Math-Chat" = "#1F78B4", "Math-Video" = "#1F78B4", 
              "HP-Chat" = "#E31A1C", "HP-Video" = "#E31A1C")
  
  # Berechne Stichprobengrößen für jedes Treatment
  sample_sizes <- var_data %>%
    group_by(treatment) %>%
    summarise(n = n(), .groups = "drop")
  
  ggplot(var_data, aes(x = task, y = value, fill = treatment)) +
    geom_boxplot(aes(alpha = comm), 
                 position = position_dodge(width = 0.8), 
                 outlier.size = 1.5, 
                 width = 0.7) +
    geom_jitter(aes(color = treatment), 
                position = position_jitterdodge(dodge.width = 0.8, jitter.width = 0.2), 
                alpha = 0.5, size = 1.2) +
    # Füge Text-Labels direkt unter die Boxplots hinzu
    geom_text(data = data.frame(
                task = c("Math", "Math", "HP", "HP"),
                comm = c("Chat", "Video", "Chat", "Video"),
                treatment = c("Math-Chat", "Math-Video", "HP-Chat", "HP-Video"),
                y_pos = 0.7
              ),
              aes(x = task, y = y_pos, label = comm, fill = treatment),
              position = position_dodge(width = 0.8),
              size = 3, fontface = "bold", color = "black",
              inherit.aes = FALSE) +
    scale_fill_manual(values = colors, guide = "none") +
    scale_color_manual(values = colors, guide = "none") +
    scale_alpha_manual(values = c("Chat" = 0.6, "Video" = 1.0), guide = "none") +
    scale_y_continuous(limits = c(0.5, 7), breaks = 1:7) +
    labs(
      title = var_label,
      subtitle = "Mixed-Design: Communication (Between) × Task (Within)",
      x = "Task Type",
      y = "Response (7-Point Likert)",
      caption = paste("Sample sizes - Math-Chat:", 
                     sample_sizes$n[sample_sizes$treatment == "Math-Chat"],
                     ", Math-Video:", 
                     sample_sizes$n[sample_sizes$treatment == "Math-Video"],
                     ", HP-Chat:", 
                     sample_sizes$n[sample_sizes$treatment == "HP-Chat"],
                     ", HP-Video:", 
                     sample_sizes$n[sample_sizes$treatment == "HP-Video"])
    ) +
    theme_minimal() +
    theme(
      plot.title = element_text(size = 12, face = "bold", hjust = 0.5),
      plot.subtitle = element_text(size = 9, hjust = 0.5, color = "gray50"),
      plot.caption = element_text(size = 8, hjust = 0.5, color = "gray60"),
      axis.text.x = element_text(size = 10, face = "bold"),
      axis.text.y = element_text(size = 9),
      axis.title = element_text(size = 10, face = "bold"),
      legend.position = "none",  # Keine Legende mehr
      panel.grid.major.x = element_blank(),
      panel.grid.minor = element_blank()
    )
}

# Erstelle alle 4-Treatment Boxplots
mixed_design_boxplots <- list()
for(var in team_factor_vars) {
  if(var %in% unique(mixed_design_plot_data$variable)) {
    cat("Erstelle Mixed-Design Boxplot für:", var, "\n")
    plot <- create_mixed_design_boxplot(var, mixed_design_plot_data)
    if(!is.null(plot)) {
      mixed_design_boxplots[[var]] <- plot
    }
  }
}

# Zeige alle Plots einzeln
if(length(mixed_design_boxplots) > 0) {
  cat("\n=== EINZELNE 4-TREATMENT BOXPLOTS ===\n")
  
  for(var in names(mixed_design_boxplots)) {
    var_label <- variable_labels[var]
    var_label <- ifelse(is.na(var_label), var, var_label)
    
    cat("Zeige Mixed-Design Boxplot für:", var_label, "\n")
    print(mixed_design_boxplots[[var]])
  }
  
  cat("\nAlle", length(mixed_design_boxplots), "Mixed-Design Boxplots angezeigt.\n")
}

# ================================================================================
# SCHRITT 5: ZUSAMMENFASSUNG UND INTERPRETATION
# ================================================================================

cat("\n", paste(rep("=", 80), collapse=""), "\n")
cat("MIXED-DESIGN FACTORIAL ANALYSE ZUSAMMENFASSUNG\n")
cat(paste(rep("=", 80), collapse=""), "\n")

# Zähle signifikante Effekte
significant_vars <- mixed_design_results_table$Variable[mixed_design_results_table$Any_Significant]
task_effects <- sum(mixed_design_results_table$Task_p < 0.05, na.rm = TRUE)
comm_effects <- sum(mixed_design_results_table$Comm_p < 0.05, na.rm = TRUE)
interaction_effects <- sum(mixed_design_results_table$Interaction_p < 0.05, na.rm = TRUE)

cat("📊 MIXED-DESIGN ERGEBNISÜBERSICHT:\n")
cat("- Analysierte Team-Faktoren:", nrow(mixed_design_results_table), "\n")
cat("- Variablen mit signifikanten Effekten:", length(significant_vars), "\n")
cat("- Task-Haupteffekte (Within-Subjects):", task_effects, "\n")
cat("- Communication-Haupteffekte (Between-Subjects):", comm_effects, "\n")
cat("- Task × Communication Interaktionen:", interaction_effects, "\n\n")

if(length(significant_vars) > 0) {
  cat("✅ TEAM-FAKTOREN MIT SIGNIFIKANTEN EFFEKTEN:\n")
  for(var in significant_vars) {
    row <- mixed_design_results_table[mixed_design_results_table$Variable == var, ]
    
    effects <- c()
    if(!is.na(row$Task_p) && row$Task_p < 0.05) {
      effect_size <- ifelse(row$Task_eta2 < 0.06, "small", 
                           ifelse(row$Task_eta2 < 0.14, "medium", "large"))
      effects <- c(effects, paste("Task (η²=", row$Task_eta2, effect_size, ")"))
    }
    if(!is.na(row$Comm_p) && row$Comm_p < 0.05) {
      effect_size <- ifelse(row$Comm_eta2 < 0.06, "small", 
                           ifelse(row$Comm_eta2 < 0.14, "medium", "large"))
      effects <- c(effects, paste("Comm (η²=", row$Comm_eta2, effect_size, ")"))
    }
    if(!is.na(row$Interaction_p) && row$Interaction_p < 0.05) {
      effect_size <- ifelse(row$Interaction_eta2 < 0.06, "small", 
                           ifelse(row$Interaction_eta2 < 0.14, "medium", "large"))
      effects <- c(effects, paste("Interaction (η²=", row$Interaction_eta2, effect_size, ")"))
    }
    
    cat("  -", row$Variable_Clean, ":", paste(effects, collapse = ", "), "\n")
  }
  cat("\n")
} else {
  cat("❌ Keine signifikanten Effekte in den Team-Faktoren gefunden.\n\n")
}

cat("💡 MIXED-DESIGN INTERPRETATION:\n")
if(task_effects > 0) {
  cat("✅ Task-Effekte (Within-Subjects): Math und HP Tasks unterscheiden sich strukturell\n")
  cat("   → Personen bewerten die Tasks unterschiedlich (hohe statistische Power)\n")
}
if(comm_effects > 0) {
  cat("✅ Communication-Effekte (Between-Subjects): Chat und Video wirken unterschiedlich\n")
  cat("   → Kommunikationsmedium beeinflusst Team-Wahrnehmung\n")
}
if(interaction_effects > 0) {
  cat("✅ Interaktions-Effekte: Task und Communication beeinflussen sich gegenseitig\n")
  cat("   → Der Kommunikationseffekt hängt vom Task ab (oder umgekehrt)\n")
}

if(task_effects == 0 && comm_effects == 0 && interaction_effects == 0) {
  cat("ℹ️ Keine signifikanten Unterschiede zwischen den 4 Treatments gefunden.\n")
  cat("   Mögliche Erklärungen:\n")
  cat("   - Team-Faktoren sind robust gegenüber Task- und Kommunikations-Variationen\n")
  cat("   - Effekte sind zu klein für die aktuelle Stichprobengröße\n")
  cat("   - Andere Faktoren (individuelle Unterschiede) überlagern Treatment-Effekte\n")
}

# Design-Validierung Zusammenfassung
total_participants <- mixed_design_data %>% 
  summarise(n_unique = n_distinct(participant.code)) %>% 
  pull(n_unique)

within_subjects_complete <- sum(design_check$n_tasks == 2)
between_subjects_clean <- sum(design_check$n_comms == 1)

cat("\n📋 DESIGN-VALIDIERUNG:\n")
cat("- Gesamte Teilnehmer:", total_participants, "\n")
cat("- Vollständige Within-Subjects Daten (beide Tasks):", within_subjects_complete, 
    "(", round(100*within_subjects_complete/total_participants, 1), "%)\n")
cat("- Saubere Between-Subjects Zuordnung (eine Comm-Form):", between_subjects_clean,
    "(", round(100*between_subjects_clean/total_participants, 1), "%)\n")

if(within_subjects_complete == total_participants && between_subjects_clean == total_participants) {
  cat("✅ Perfektes Mixed-Design: Alle Teilnehmer haben beide Tasks und nur eine Kommunikationsform\n")
} else {
  cat("⚠️ Unvollständiges Mixed-Design: Prüfe Datenqualität\n")
}

print("\nMixed-Design Factorial Analyse abgeschlossen! 🎯")
```

Regression of flow on familiarity scores

```{r}
# --- 1. Korrelationsanalysen für Familiarity-Variablen ----------------------

# Math Jitsi
math_jitsi_fam <- data %>%
  select(starts_with("mathJitsi.6.player.fam")) %>%
  select(contains("lightcoral"), contains("lightgreen"), contains("lightblue"))

cor_math_jitsi <- cor(math_jitsi_fam, use = "pairwise.complete.obs")
print("Correlation Matrix - Math Jitsi:")
print(round(cor_math_jitsi, 3))

# Math Chat
math_chat_fam <- data %>%
  select(starts_with("mathChat.6.player.fam")) %>%
  select(contains("lightcoral"), contains("lightgreen"), contains("lightblue"))

cor_math_chat <- cor(math_chat_fam, use = "pairwise.complete.obs")
print("\nCorrelation Matrix - Math Chat:")
print(round(cor_math_chat, 3))

# HP Jitsi
hp_jitsi_fam <- data %>%
  select(starts_with("HiddenProfile_Jitsi.3.player.fam")) %>%
  select(contains("lightcoral"), contains("lightgreen"), contains("lightblue"))

cor_hp_jitsi <- cor(hp_jitsi_fam, use = "pairwise.complete.obs")
print("\nCorrelation Matrix - HP Jitsi:")
print(round(cor_hp_jitsi, 3))

# HP Chat
hp_chat_fam <- data %>%
  select(starts_with("HiddenProfile_Chat.3.player.fam")) %>%
  select(contains("lightcoral"), contains("lightgreen"), contains("lightblue"))

cor_hp_chat <- cor(hp_chat_fam, use = "pairwise.complete.obs")
print("\nCorrelation Matrix - HP Chat:")
print(round(cor_hp_chat, 3))

# --- 2. Familiarity: Aggregation pro Farbe (fam1 & fam2 mitteln) ----------------------

data <- data %>%
  mutate(
    # Math – Jitsi
    fam_mathJitsi_coral = rowMeans(select(., mathJitsi.6.player.fam1_lightcoral, mathJitsi.6.player.fam2_lightcoral), na.rm = TRUE),
    fam_mathJitsi_green = rowMeans(select(., mathJitsi.6.player.fam1_lightgreen, mathJitsi.6.player.fam2_lightgreen), na.rm = TRUE),
    fam_mathJitsi_blue  = rowMeans(select(., mathJitsi.6.player.fam1_lightblue,  mathJitsi.6.player.fam2_lightblue),  na.rm = TRUE),
    
    # Math – Chat
    fam_mathChat_coral = rowMeans(select(., mathChat.6.player.fam1_lightcoral, mathChat.6.player.fam2_lightcoral), na.rm = TRUE),
    fam_mathChat_green = rowMeans(select(., mathChat.6.player.fam1_lightgreen, mathChat.6.player.fam2_lightgreen), na.rm = TRUE),
    fam_mathChat_blue  = rowMeans(select(., mathChat.6.player.fam1_lightblue,  mathChat.6.player.fam2_lightblue),  na.rm = TRUE),

    # HP – Jitsi
    fam_hpJitsi_coral = rowMeans(select(., HiddenProfile_Jitsi.3.player.fam1_lightcoral, HiddenProfile_Jitsi.3.player.fam2_lightcoral), na.rm = TRUE),
    fam_hpJitsi_green = rowMeans(select(., HiddenProfile_Jitsi.3.player.fam1_lightgreen, HiddenProfile_Jitsi.3.player.fam2_lightgreen), na.rm = TRUE),
    fam_hpJitsi_blue  = rowMeans(select(., HiddenProfile_Jitsi.3.player.fam1_lightblue,  HiddenProfile_Jitsi.3.player.fam2_lightblue),  na.rm = TRUE),

    # HP – Chat
    fam_hpChat_coral = rowMeans(select(., HiddenProfile_Chat.3.player.fam1_lightcoral, HiddenProfile_Chat.3.player.fam2_lightcoral), na.rm = TRUE),
    fam_hpChat_green = rowMeans(select(., HiddenProfile_Chat.3.player.fam1_lightgreen, HiddenProfile_Chat.3.player.fam2_lightgreen), na.rm = TRUE),
    fam_hpChat_blue  = rowMeans(select(., HiddenProfile_Chat.3.player.fam1_lightblue,  HiddenProfile_Chat.3.player.fam2_lightblue),  na.rm = TRUE)
  )

# --- 3. Familiarity: Aggregation pro Bedingung (über die zwei befüllten Farben) -------

data <- data %>%
  mutate(
    fam_mathJitsi = rowMeans(select(., fam_mathJitsi_coral, fam_mathJitsi_green, fam_mathJitsi_blue), na.rm = TRUE),
    fam_mathChat  = rowMeans(select(., fam_mathChat_coral, fam_mathChat_green, fam_mathChat_blue), na.rm = TRUE),
    fam_hpJitsi   = rowMeans(select(., fam_hpJitsi_coral, fam_hpJitsi_green, fam_hpJitsi_blue), na.rm = TRUE),
    fam_hpChat    = rowMeans(select(., fam_hpChat_coral, fam_hpChat_green, fam_hpChat_blue), na.rm = TRUE)
  )

# --- 4. Recognition: Kategorisierung für Analyse ---------------

data <- data %>%
  mutate(
    # Individual recognition scores
    rec_coral = Outro.1.player.rec_lightcoral,
    rec_green = Outro.1.player.rec_lightgreen,
    rec_blue  = Outro.1.player.rec_lightblue
  ) %>%
  mutate(
    # Mean recognition across teammates
    rec_mean = rowMeans(select(., rec_coral, rec_green, rec_blue), na.rm = TRUE),
    
    # Count how many teammates were known (>4 on 7-point scale)
    rec_count = rowSums(select(., rec_coral, rec_green, rec_blue) > 4, na.rm = TRUE),
    
    # Categorical variable
    rec_category = case_when(
      rec_count == 0 ~ "Nobody known",
      rec_count == 1 ~ "One person known",
      rec_count == 2 ~ "Both known",
      TRUE ~ NA_character_
    )
  )

# --- 5. Deskriptive Statistiken ---------------

# Recognition categories
print("\n--- Recognition Categories ---")
table(data$rec_category)

# Familiarity means by condition
print("\n--- Mean Familiarity by Condition ---")
data %>%
  summarise(
    MathJitsi = mean(fam_mathJitsi, na.rm = TRUE),
    MathChat = mean(fam_mathChat, na.rm = TRUE),
    HPJitsi = mean(fam_hpJitsi, na.rm = TRUE),
    HPChat = mean(fam_hpChat, na.rm = TRUE)
  ) %>%
  print()

# --- 6. Long format for regression analyses ---------------

# Da die Flow-Scores in einem separaten Dataframe sind, müssen wir anders vorgehen
# Erst aggregieren wir die Flow-Scores pro Bedingung (über alle Schwierigkeiten)

print("\n--- Aggregating flow scores ---")
flow_aggregated <- flow_clean %>%
  group_by(participant.code, task, comm) %>%
  summarise(
    flow_score = mean(flow_score, na.rm = TRUE),
    n_difficulties = n(),  # Anzahl der Schwierigkeitsstufen
    .groups = 'drop'
  )

print("Sample of aggregated flow scores:")
print(head(flow_aggregated))

# Erstelle das Long-Format für Familiarity
familiarity_long <- data %>%
  select(participant.code,
         fam_mathJitsi, fam_mathChat, fam_hpJitsi, fam_hpChat,
         rec_mean, rec_count, rec_category) %>%
  pivot_longer(
    cols = starts_with("fam_"),
    names_to = "condition",
    values_to = "familiarity"
  ) %>%
  mutate(
    task = case_when(
      str_detect(condition, "math") ~ "Math", 
      TRUE ~ "HP"  # HP wie in flow_clean
    ),
    comm = case_when(
      str_detect(condition, "Chat") ~ "Chat", 
      TRUE ~ "Jitsi"
    )
  )

# Merge mit Flow-Scores
familiarity_long <- familiarity_long %>%
  left_join(
    flow_aggregated %>% select(participant.code, task, comm, flow_score),
    by = c("participant.code", "task", "comm")
  ) %>%
  drop_na(flow_score)

# Check wie viele Zeilen wir haben
print(paste("\nRows in familiarity_long:", nrow(familiarity_long)))
print(paste("Unique participants:", n_distinct(familiarity_long$participant.code)))

# Überprüfe die Verteilung
print("\nDistribution by condition:")
print(table(familiarity_long$task, familiarity_long$comm))

# --- 7. Regression Models ---------------

print("\n--- Model A: Basic (Familiarity + Recognition) ---")
model_a <- lm(flow_score ~ familiarity + rec_mean, data = familiarity_long)
summary(model_a)

print("\n--- Model B: With Task and Communication ---")
model_b <- lm(flow_score ~ familiarity + rec_mean + task + comm, data = familiarity_long)
summary(model_b)

print("\n--- Model C: With Interactions ---")
model_c <- lm(flow_score ~ familiarity * comm + rec_mean * comm + task, data = familiarity_long)
summary(model_c)

print("\n--- Model D: Recognition Categories ---")
model_d <- lm(flow_score ~ familiarity + rec_category + task + comm, data = familiarity_long)
summary(model_d)

print("\n--- Model E: Non-linear Recognition Effect ---")
model_e <- lm(flow_score ~ familiarity + rec_count + I(rec_count^2) + task + comm, data = familiarity_long)
summary(model_e)

# --- 8. Visualizations ---------------

# Plot 1: Familiarity vs Flow by Communication Type
p1 <- ggplot(familiarity_long, aes(x = familiarity, y = flow_score, color = comm)) +
  geom_point(alpha = 0.6) +
  geom_smooth(method = "lm", se = TRUE) +
  facet_wrap(~ task) +
  labs(
    title = "Familiarity vs. Flow by Communication Type and Task",
    x = "Familiarity with Teammates (during task)",
    y = "Flow Score",
    color = "Communication"
  ) +
  theme_minimal()

print(p1)

# Plot 2: Recognition Categories and Flow
p2 <- ggplot(familiarity_long, aes(x = rec_category, y = flow_score, fill = rec_category)) +
  geom_boxplot(alpha = 0.7) +
  geom_jitter(width = 0.2, alpha = 0.3) +
  facet_grid(task ~ comm) +
  labs(
    title = "Flow by Prior Recognition of Teammates",
    x = "Prior Recognition",
    y = "Flow Score"
  ) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

print(p2)

# Plot 3: Recognition Mean vs Flow
p3 <- ggplot(familiarity_long, aes(x = rec_mean, y = flow_score)) +
  geom_point(alpha = 0.5) +
  geom_smooth(method = "lm", se = TRUE) +
  facet_grid(task ~ comm) +
  labs(
    title = "Mean Prior Recognition vs. Flow",
    x = "Mean Recognition Score",
    y = "Flow Score"
  ) +
  theme_minimal()

print(p3)

# --- 9. Additional Analyses ---------------

# Check if recognition effect differs by communication type
print("\n--- Model F: Recognition × Communication Interaction ---")
model_f <- lm(flow_score ~ familiarity + rec_mean * comm + task, data = familiarity_long)
summary(model_f)

# Correlation between familiarity and recognition
print("\n--- Correlation: Familiarity vs Recognition ---")
cor.test(familiarity_long$familiarity, familiarity_long$rec_mean)

# Mean flow by recognition categories
print("\n--- Mean Flow by Recognition Category ---")
familiarity_long %>%
  group_by(rec_category) %>%
  summarise(
    mean_flow = mean(flow_score, na.rm = TRUE),
    sd_flow = sd(flow_score, na.rm = TRUE),
    n = n()
  ) %>%
  print()

```

Regression of flow on gender distribution

```{r}
# Vereinfachte Gender Composition Analyse
# ================================================================================
# TEIL 1: GENDER COMPOSITION ZU FLOW_SCORES HINZUFÜGEN
# ================================================================================

# Team Gender Composition berechnen
team_gender_composition <- data %>%
  dplyr::select(participant.code, team_id, gender = Intro.1.player.gender) %>%
  filter(!is.na(gender), !is.na(team_id)) %>%
  group_by(team_id) %>%
  dplyr::summarise(
    n_members = n(),
    n_male = sum(gender == "Male", na.rm = TRUE),
    n_female = sum(gender == "Female", na.rm = TRUE),
    n_other = sum(!gender %in% c("Male", "Female"), na.rm = TRUE),
    unique_genders = n_distinct(gender),
    .groups = "drop"
  ) %>%
  mutate(
    gender_comp = case_when(
      n_male == n_members ~ "all_male",
      n_female == n_members ~ "all_female",
      n_male > 0 & n_female > 0 ~ "mixed",
      TRUE ~ "other"
    )
  )

print("Team Gender Composition erstellt:")
print(table(team_gender_composition$gender_comp))

# Gender composition zu flow_clean hinzufügen (sollte bereits existieren)
if(!"gender_comp" %in% names(flow_clean)) {
  flow_scores_gender <- flow_clean %>%
    left_join(team_gender_composition %>% dplyr::select(team_id, gender_comp), 
              by = "team_id")
} else {
  flow_scores_gender <- flow_clean
}

# Überprüfe Verteilung
print("Team Gender Composition Verteilung:")
print(table(flow_scores_gender$gender_comp, useNA = "ifany"))

# TEIL 2: DESKRIPTIVE STATISTIKEN
# ================================================================================

print("\n--- DESKRIPTIVE STATISTIKEN ---")

# Gesamtübersicht
gender_descriptives <- flow_scores_gender %>%
  group_by(gender_comp) %>%
  dplyr::summarise(
    n_observations = n(),
    n_participants = n_distinct(participant.code),
    n_teams = n_distinct(team_id),
    flow_mean = round(mean(flow_score, na.rm = TRUE), 3),
    flow_sd = round(sd(flow_score, na.rm = TRUE), 3),
    flow_min = round(min(flow_score, na.rm = TRUE), 3),
    flow_max = round(max(flow_score, na.rm = TRUE), 3),
    .groups = "drop"
  )

print("Übersicht nach Gender Composition:")
print(gender_descriptives)

# Nach Task aufgeschlüsselt
gender_task_descriptives <- flow_scores_gender %>%
  group_by(gender_comp, task) %>%
  dplyr::summarise(
    n = n(),
    flow_mean = round(mean(flow_score, na.rm = TRUE), 3),
    flow_sd = round(sd(flow_score, na.rm = TRUE), 3),
    .groups = "drop"
  )

print("\nFlow nach Gender Composition und Task:")
print(gender_task_descriptives)

# Nach Communication aufgeschlüsselt
gender_comm_descriptives <- flow_scores_gender %>%
  group_by(gender_comp, comm) %>%
  dplyr::summarise(
    n = n(),
    flow_mean = round(mean(flow_score, na.rm = TRUE), 3),
    flow_sd = round(sd(flow_score, na.rm = TRUE), 3),
    .groups = "drop"
  )

print("\nFlow nach Gender Composition und Communication:")
print(gender_comm_descriptives)

# TEIL 3: STATISTISCHE TESTS
# ================================================================================

print("\n--- STATISTISCHE TESTS ---")

# ANOVA für Haupteffekt
print("ANOVA: Gender Composition Haupteffekt")
anova_gender <- aov(flow_score ~ gender_comp, data = flow_scores_gender)
print(summary(anova_gender))

# Post-hoc Test falls signifikant
anova_p <- summary(anova_gender)[[1]][["Pr(>F)"]][1]
if(!is.na(anova_p) && anova_p < 0.05) {
  print("\nPost-hoc Test (Tukey HSD):")
  print(TukeyHSD(anova_gender))
}

# T-Test: all_male vs. mixed (falls beide vorhanden)
if("all_male" %in% flow_scores_gender$gender_comp && "mixed" %in% flow_scores_gender$gender_comp) {
  print("\nT-Test: all_male vs. mixed")
  t_test_result <- t.test(
    flow_score ~ gender_comp, 
    data = flow_scores_gender %>% filter(gender_comp %in% c("all_male", "mixed"))
  )
  print(t_test_result)
}

# TEIL 4: LINEARE MODELLE
# ================================================================================

print("\n--- LINEARE MODELLE ---")

# Basis-Modell
print("Model 1: Nur Gender Composition")
model1 <- lm(flow_score ~ gender_comp, data = flow_scores_gender)
print(summary(model1))

# Mit Task
print("\nModel 2: Gender Composition + Task")
model2 <- lm(flow_score ~ gender_comp + task, data = flow_scores_gender)
print(summary(model2))

# Mit Communication
print("\nModel 3: Gender Composition + Communication")
model3 <- lm(flow_score ~ gender_comp + comm, data = flow_scores_gender)
print(summary(model3))

# Mit Difficulty
print("\nModel 4: Gender Composition + Difficulty")
model4 <- lm(flow_score ~ gender_comp + difficulty, data = flow_scores_gender)
print(summary(model4))

# Volles Modell
print("\nModel 5: Vollmodell")
model5 <- lm(flow_score ~ gender_comp + task + comm + difficulty, data = flow_scores_gender)
print(summary(model5))

# Mit Interaktionen
print("\nModel 6: Mit Gender × Task Interaktion")
model6 <- lm(flow_score ~ gender_comp * task + comm + difficulty, data = flow_scores_gender)
print(summary(model6))

# TEIL 5: VISUALISIERUNGEN
# ================================================================================

print("\n--- VISUALISIERUNGEN ---")

# Einfacher Boxplot
p1 <- ggplot(flow_scores_gender, aes(x = gender_comp, y = flow_score, fill = gender_comp)) +
  geom_boxplot(alpha = 0.7) +
  geom_jitter(width = 0.2, alpha = 0.3, size = 0.5) +
  labs(
    title = "Flow Scores by Team Gender Composition",
    x = "Team Gender Composition",
    y = "Flow Score",
    fill = "Gender Composition"
  ) +
  theme_minimal() +
  scale_fill_brewer(palette = "Set2") +
  theme(legend.position = "none")

print(p1)

# Nach Task aufgeteilt
p2 <- ggplot(flow_scores_gender, aes(x = gender_comp, y = flow_score, fill = gender_comp)) +
  geom_boxplot(alpha = 0.7) +
  facet_wrap(~ task) +
  labs(
    title = "Flow Scores by Gender Composition and Task",
    x = "Team Gender Composition",
    y = "Flow Score",
    fill = "Gender Composition"
  ) +
  theme_minimal() +
  scale_fill_brewer(palette = "Set2") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

print(p2)

# Nach Communication aufgeteilt
p3 <- ggplot(flow_scores_gender, aes(x = gender_comp, y = flow_score, fill = gender_comp)) +
  geom_boxplot(alpha = 0.7) +
  facet_wrap(~ comm) +
  labs(
    title = "Flow Scores by Gender Composition and Communication",
    x = "Team Gender Composition",
    y = "Flow Score",
    fill = "Gender Composition"
  ) +
  theme_minimal() +
  scale_fill_brewer(palette = "Set2") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

print(p3)

# Interaction Plot: Gender × Task
if(require(emmeans, quietly = TRUE)) {
  print("\n--- INTERACTION PLOTS ---")
  
  # Gender × Task
  emmeans_gender_task <- emmeans(model6, ~ gender_comp | task)
  p4 <- plot(emmeans_gender_task) +
    labs(title = "Estimated Marginal Means: Gender Composition by Task") +
    theme_minimal()
  print(p4)
}

# TEIL 6: EFFEKTSTÄRKEN
# ================================================================================

print("\n--- EFFEKTSTÄRKEN ---")

# Eta-squared für Gender Composition
if(require(effectsize, quietly = TRUE)) {
  eta_gender <- eta_squared(anova_gender)
  print("Eta-squared für Gender Composition:")
  print(eta_gender)
}

# Cohen's d für paarweise Vergleiche (falls vorhanden)
if("all_male" %in% flow_scores_gender$gender_comp && "mixed" %in% flow_scores_gender$gender_comp) {
  if(require(effsize, quietly = TRUE)) {
    cohens_d <- cohen.d(
      flow_score ~ gender_comp, 
      data = flow_scores_gender %>% filter(gender_comp %in% c("all_male", "mixed"))
    )
    print("\nCohen's d (all_male vs. mixed):")
    print(cohens_d)
  }
}

# TEIL 7: ZUSAMMENFASSUNG UND INTERPRETATION
# ================================================================================

print("\n=== ZUSAMMENFASSUNG ===")

# Mittelwerte der wichtigsten Gruppen
summary_stats <- flow_scores_gender %>%
  group_by(gender_comp) %>%
  dplyr::summarise(
    mean_flow = round(mean(flow_score, na.rm = TRUE), 3),
    n = n(),
    .groups = "drop"
  ) %>%
  arrange(desc(mean_flow))

print("Ranking der Gender Compositions nach Flow (höchster zuerst):")
print(summary_stats)

# Signifikanz-Check
if(!is.na(anova_p)) {
  if(anova_p < 0.001) {
    significance <- "hochsignifikant (p < 0.001)"
  } else if(anova_p < 0.01) {
    significance <- "sehr signifikant (p < 0.01)"
  } else if(anova_p < 0.05) {
    significance <- "signifikant (p < 0.05)"
  } else {
    significance <- "nicht signifikant (p >= 0.05)"
  }
  
  print(paste("\nGender Composition Effekt ist", significance))
}

# Praktische Bedeutung
if(nrow(summary_stats) >= 2) {
  max_diff <- max(summary_stats$mean_flow) - min(summary_stats$mean_flow)
  print(paste("Maximaler Unterschied zwischen Gruppen:", round(max_diff, 3), "Flow-Punkte"))
}

print("\n=== GENDER COMPOSITION ANALYSE ABGESCHLOSSEN ===")
```

Regression of flow on emoji count

```{r}
library(stringr)

# TEIL 1: EMOJI-EXTRAKTION FUNKTIONEN
# ================================================================================

# Definiere die Text-Emojis, die wir suchen
emoji_patterns <- c(
  # Positive Emojis
  ":\\)", ";\\)", ":D", ";D", "[xX]D", "XD", "<3", ":P", ":p",
  # Negative/Neutrale Emojis  
  ":/", ":\\(", ":\\|", ":o", ":O",
  # Varianten mit Bindestrich
  ":-\\)", ";-\\)", ":-D", ";-D", ":-/", ":-\\(", ":-\\|", ":-[oO]", ":-[pP]"
)

# Funktion zum Extrahieren spezifischer Emoji-Typen
extract_emoji_types <- function(text) {
  if(is.na(text) || text == "") {
    return(list(
      positive = 0,
      negative = 0,
      neutral = 0,
      total = 0
    ))
  }
  
  # Positive Emojis
  positive_pattern <- "(:\\)|;\\)|:D|;D|[xX]D|XD|<3|:P|:p|:-\\)|;-\\)|:-D|;-D|:-[pP])"
  positive_count <- length(str_extract_all(text, positive_pattern)[[1]])
  
  # Negative Emojis
  negative_pattern <- "(:\\(|:-\\()"
  negative_count <- length(str_extract_all(text, negative_pattern)[[1]])
  
  # Neutrale Emojis
  neutral_pattern <- "(:/|:\\||:o|:O|:-/|:-\\||:-[oO])"
  neutral_count <- length(str_extract_all(text, neutral_pattern)[[1]])
  
  return(list(
    positive = positive_count,
    negative = negative_count,
    neutral = neutral_count,
    total = positive_count + negative_count + neutral_count
  ))
}

# TEIL 2: EMOJI-DATEN EXTRAHIEREN
# ================================================================================

print("--- EXTRAHIERE EMOJI-DATEN ---")

# Finde alle Chat-Log Spalten
chat_columns <- names(data)[grepl("chat_log$", names(data))]
print(paste("Gefundene Chat-Log Spalten:", length(chat_columns)))

# Extrahiere Emojis aus allen Chat-Logs
all_emoji_data <- data.frame()

for(col in chat_columns) {
  # Bestimme Task und Communication Type
  task_type <- case_when(
    grepl("mathChat", col) ~ "Math_Chat",
    grepl("mathJitsi", col) ~ "Math_Jitsi", 
    grepl("HiddenProfile_Chat", col) ~ "HP_Chat",
    grepl("HiddenProfile_Jitsi", col) ~ "HP_Jitsi",
    TRUE ~ "Unknown"
  )
  
  # Nur Chat-Logs (nicht Jitsi)
  if(grepl("Chat", task_type)) {
    round_num <- as.numeric(str_extract(col, "\\d+"))
    
    col_data <- data %>%
      dplyr::select(participant.code, team_id, chat_log = all_of(col)) %>%
      filter(!is.na(chat_log) & chat_log != "") %>%
      mutate(
        round = round_num,
        task = ifelse(grepl("Math", task_type), "Math", "HP"),
        comm = "Chat",
        chat_length = nchar(chat_log)
      )
    
    # Emojis extrahieren
    for(i in 1:nrow(col_data)) {
      emoji_result <- extract_emoji_types(col_data$chat_log[i])
      col_data$emoji_positive[i] <- emoji_result$positive
      col_data$emoji_negative[i] <- emoji_result$negative
      col_data$emoji_neutral[i] <- emoji_result$neutral
      col_data$emoji_total[i] <- emoji_result$total
    }
    
    all_emoji_data <- bind_rows(all_emoji_data, col_data)
  }
}

print(paste("Extrahierte Emoji-Daten:", nrow(all_emoji_data), "Chat-Nachrichten"))

# TEIL 3: AGGREGIERE EMOJI-DATEN PRO TEILNEHMER
# ================================================================================

# Pro Teilnehmer und Task
emoji_participant_summary <- all_emoji_data %>%
  group_by(participant.code, task) %>%
  dplyr::summarise(
    total_emojis = sum(emoji_total, na.rm = TRUE),
    positive_emojis = sum(emoji_positive, na.rm = TRUE),
    negative_emojis = sum(emoji_negative, na.rm = TRUE),
    neutral_emojis = sum(emoji_neutral, na.rm = TRUE),
    total_chat_length = sum(chat_length, na.rm = TRUE),
    emoji_messages = sum(emoji_total > 0),
    total_messages = n(),
    emoji_density = ifelse(total_chat_length > 0, total_emojis / total_chat_length * 100, 0),
    emoji_message_ratio = emoji_messages / total_messages,
    .groups = "drop"
  )

print("--- EMOJI-NUTZUNG ÜBERSICHT ---")
print(paste("Teilnehmer mit Emoji-Daten:", nrow(emoji_participant_summary)))

# TEIL 4: VERBINDE MIT FLOW-SCORES
# ================================================================================

# Flow-Scores für Chat-Bedingungen aggregieren
flow_chat_summary <- flow_clean %>%
  filter(comm == "Chat") %>%
  group_by(participant.code, task) %>%
  dplyr::summarise(
    mean_flow_score = mean(flow_score, na.rm = TRUE),
    n_flow_measurements = n(),
    .groups = "drop"
  )

# Verbinde Emoji- und Flow-Daten
emoji_flow_data <- emoji_participant_summary %>%
  left_join(flow_chat_summary, by = c("participant.code", "task")) %>%
  filter(!is.na(mean_flow_score))  # Nur Teilnehmer mit Flow-Daten

print(paste("Teilnehmer mit Emoji- und Flow-Daten:", nrow(emoji_flow_data)))

# TEIL 5: DESKRIPTIVE STATISTIKEN
# ================================================================================

print("\n--- DESKRIPTIVE STATISTIKEN ---")

# Gesamtübersicht
emoji_overview <- emoji_flow_data %>%
  group_by(task) %>%
  dplyr::summarise(
    n_participants = n(),
    emoji_users = sum(total_emojis > 0),
    emoji_user_percentage = round(emoji_users / n_participants * 100, 1),
    mean_emojis = round(mean(total_emojis), 2),
    median_emojis = median(total_emojis),
    max_emojis = max(total_emojis),
    mean_positive = round(mean(positive_emojis), 2),
    mean_negative = round(mean(negative_emojis), 2),
    mean_neutral = round(mean(neutral_emojis), 2),
    mean_emoji_density = round(mean(emoji_density), 3),
    .groups = "drop"
  )

print("Emoji-Nutzung nach Task:")
print(emoji_overview)

# Verteilung der Emoji-Nutzer vs. Nicht-Nutzer
emoji_usage_summary <- emoji_flow_data %>%
  mutate(
    emoji_user = total_emojis > 0,
    emoji_category = case_when(
      total_emojis == 0 ~ "Keine Emojis",
      total_emojis <= 2 ~ "Wenige (1-2)",
      total_emojis <= 5 ~ "Moderate (3-5)",
      TRUE ~ "Viele (6+)"
    )
  ) %>%
  group_by(task, emoji_category) %>%
  dplyr::summarise(
    n = n(),
    mean_flow = round(mean(mean_flow_score, na.rm = TRUE), 3),
    .groups = "drop"
  )

print("\nFlow nach Emoji-Nutzungskategorien:")
print(emoji_usage_summary)

# TEIL 6: KORRELATIONEN UND STATISTISCHE TESTS
# ================================================================================

print("\n--- KORRELATIONEN ---")

# Korrelationen pro Task
for(task_name in c("Math", "HP")) {
  task_data <- emoji_flow_data %>% filter(task == task_name)
  
  if(nrow(task_data) > 5) {
    cor_total <- cor(task_data$total_emojis, task_data$mean_flow_score, use = "complete.obs")
    cor_positive <- cor(task_data$positive_emojis, task_data$mean_flow_score, use = "complete.obs")
    cor_density <- cor(task_data$emoji_density, task_data$mean_flow_score, use = "complete.obs")
    
    cat(paste("\n", task_name, "Task:\n"))
    cat(paste("  Total Emojis - Flow:", round(cor_total, 3), "\n"))
    cat(paste("  Positive Emojis - Flow:", round(cor_positive, 3), "\n"))
    cat(paste("  Emoji Density - Flow:", round(cor_density, 3), "\n"))
  }
}

# TEIL 7: LINEARE MODELLE
# ================================================================================

print("\n--- LINEARE MODELLE ---")

# Modell 1: Emoji-Anzahl gesamt
model1 <- lm(mean_flow_score ~ total_emojis + task, data = emoji_flow_data)
print("Model 1: Total Emojis -> Flow")
print(summary(model1))

# Modell 2: Emoji-Typen
model2 <- lm(mean_flow_score ~ positive_emojis + negative_emojis + neutral_emojis + task, 
             data = emoji_flow_data)
print("\nModel 2: Emoji Types -> Flow")
print(summary(model2))

# Modell 3: Emoji-Density
model3 <- lm(mean_flow_score ~ emoji_density + task, data = emoji_flow_data)
print("\nModel 3: Emoji Density -> Flow")
print(summary(model3))

# Modell 4: Emoji vs. Non-Emoji Users
emoji_flow_data$emoji_user <- emoji_flow_data$total_emojis > 0
model4 <- lm(mean_flow_score ~ emoji_user + task, data = emoji_flow_data)
print("\nModel 4: Emoji User (Yes/No) -> Flow")
print(summary(model4))

# TEIL 8: TASK-SPEZIFISCHE ANALYSEN
# ================================================================================

print("\n--- TASK-SPEZIFISCHE ANALYSEN ---")

# Math Task
math_data <- emoji_flow_data %>% filter(task == "Math")
if(nrow(math_data) > 10) {
  math_model <- lm(mean_flow_score ~ total_emojis, data = math_data)
  print("Math Task - Emojis -> Flow:")
  print(summary(math_model))
}

# HP Task
hp_data <- emoji_flow_data %>% filter(task == "HP")
if(nrow(hp_data) > 10) {
  hp_model <- lm(mean_flow_score ~ total_emojis, data = hp_data)
  print("\nHP Task - Emojis -> Flow:")
  print(summary(hp_model))
}

# TEIL 9: VISUALISIERUNGEN
# ================================================================================

print("\n--- VISUALISIERUNGEN ---")

# Plot 1: Emoji-Anzahl vs Flow
p1 <- ggplot(emoji_flow_data, aes(x = total_emojis, y = mean_flow_score)) +
  geom_point(alpha = 0.6, size = 2) +
  geom_smooth(method = "lm", se = TRUE, color = "blue") +
  facet_wrap(~ task) +
  labs(
    title = "Emoji Usage vs. Flow Score",
    x = "Total Emojis Used",
    y = "Mean Flow Score"
  ) +
  theme_minimal()

print(p1)

# Plot 2: Emoji-Kategorien vs Flow
p2 <- emoji_flow_data %>%
  mutate(
    emoji_category = case_when(
      total_emojis == 0 ~ "Keine",
      total_emojis <= 2 ~ "Wenige (1-2)",
      total_emojis <= 5 ~ "Moderate (3-5)",
      TRUE ~ "Viele (6+)"
    )
  ) %>%
  ggplot(aes(x = emoji_category, y = mean_flow_score, fill = emoji_category)) +
  geom_boxplot(alpha = 0.7) +
  geom_jitter(width = 0.2, alpha = 0.5) +
  facet_wrap(~ task) +
  labs(
    title = "Flow Score by Emoji Usage Category",
    x = "Emoji Usage Category",
    y = "Mean Flow Score",
    fill = "Category"
  ) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1), legend.position = "none")

print(p2)

# Plot 3: Emoji-Typen Verteilung
p3 <- emoji_flow_data %>%
  dplyr::select(participant.code, task, positive_emojis, negative_emojis, neutral_emojis) %>%
  pivot_longer(cols = c(positive_emojis, negative_emojis, neutral_emojis),
               names_to = "emoji_type", values_to = "count") %>%
  mutate(emoji_type = str_replace(emoji_type, "_emojis", "")) %>%
  filter(count > 0) %>%
  ggplot(aes(x = emoji_type, y = count, fill = emoji_type)) +
  geom_boxplot(alpha = 0.7) +
  facet_wrap(~ task) +
  labs(
    title = "Distribution of Emoji Types (Only Users)",
    x = "Emoji Type",
    y = "Count"
  ) +
  theme_minimal() +
  scale_fill_brewer(palette = "Set2")

print(p3)

# TEIL 10: BEISPIELE UND ZUSAMMENFASSUNG
# ================================================================================

print("\n--- TOP EMOJI-NUTZER ---")

# Top 5 Emoji-Nutzer pro Task
top_emoji_users <- emoji_flow_data %>%
  group_by(task) %>%
  slice_max(total_emojis, n = 3) %>%
  dplyr::select(participant.code, task, total_emojis, positive_emojis, 
         negative_emojis, neutral_emojis, mean_flow_score)

print("Top 3 Emoji-Nutzer pro Task:")
print(as.data.frame(top_emoji_users))

# Zusammenfassung
print("\n--- ZUSAMMENFASSUNG ---")

overall_cor <- cor(emoji_flow_data$total_emojis, emoji_flow_data$mean_flow_score, 
                  use = "complete.obs")
emoji_users_pct <- sum(emoji_flow_data$total_emojis > 0) / nrow(emoji_flow_data) * 100

cat(paste("Gesamtkorrelation Emojis-Flow:", round(overall_cor, 3), "\n"))
cat(paste("Anteil Emoji-Nutzer:", round(emoji_users_pct, 1), "%\n"))
cat(paste("Durchschnittlich", round(mean(emoji_flow_data$total_emojis), 1), "Emojis pro Person\n"))
cat(paste("Maximum:", max(emoji_flow_data$total_emojis), "Emojis von einer Person\n"))

# Signifikanz-Test
if(abs(overall_cor) > 0.1) {
  cor_test <- cor.test(emoji_flow_data$total_emojis, emoji_flow_data$mean_flow_score)
  if(cor_test$p.value < 0.05) {
    cat("Korrelation ist statistisch signifikant (p < 0.05)\n")
  } else {
    cat("Korrelation ist nicht statistisch signifikant\n")
  }
}

print("\n=== EMOJI-ANALYSE ABGESCHLOSSEN ===")
```



